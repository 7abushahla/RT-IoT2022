{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc3b6944-3fa9-4ab9-b086-d427b54e3f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from micromlgen import port\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder, label_binarize\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8be052c-d0ce-4184-b031-ac07f3fc9193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# BATCHSIZE = 128  # Not used in Random Forest\n",
    "CLASSES = 13\n",
    "\n",
    "# INPUT_SIZE = 83  # Not used in Random Forest, but retained for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b230de81-dba0-450a-8bd8-63ede9873a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique classes: 13\n",
      "Class labels: ['ARP_poisioning' 'Alexa' 'DDOS_Slowloris' 'DOS_SYN_Hping' 'MQTT_Publish'\n",
      " 'Metasploit_Brute_Force_SSH' 'NMAP_FIN_SCAN' 'NMAP_OS_DETECTION'\n",
      " 'NMAP_TCP_scan' 'NMAP_UDP_SCAN' 'NMAP_XMAS_TREE_SCAN' 'Thing_Speak'\n",
      " 'Wipro_bulb']\n",
      "Training set size: (167967, 83)\n",
      "Test set size: (41992, 83)\n"
     ]
    }
   ],
   "source": [
    "def load_and_preprocess_data(filepath):\n",
    "    \"\"\"\n",
    "    Loads data from a CSV file, replaces placeholders, and separates features from target.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): Path to the CSV file.\n",
    "        \n",
    "    Returns:\n",
    "        data (pd.DataFrame): Feature dataframe.\n",
    "        target (pd.Series): Target labels.\n",
    "        feature_names (list): List of feature names.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(filepath)\n",
    "    \n",
    "    # Replace '-' with 'None' in categorical columns\n",
    "    data['service'] = data['service'].replace('-', 'None')\n",
    "    data['proto'] = data['proto'].replace('-', 'None')\n",
    "    \n",
    "    # Separate features and target\n",
    "    feature_names = data.drop(columns=['Attack_type']).columns.tolist()\n",
    "    target = data['Attack_type']\n",
    "    data = data.drop(columns=['Attack_type'])\n",
    "    \n",
    "    return data, target, feature_names\n",
    "\n",
    "# Load the dataset\n",
    "data, target, feature_names = load_and_preprocess_data('./FCNN/RT_IOT2022_new.csv')\n",
    "\n",
    "\n",
    "\n",
    "def encode_targets(target):\n",
    "    \"\"\"\n",
    "    Encodes categorical target labels into numerical codes.\n",
    "    \n",
    "    Args:\n",
    "        target (pd.Series): Categorical target labels.\n",
    "        \n",
    "    Returns:\n",
    "        target_encoded (np.ndarray): Encoded target labels.\n",
    "        class_labels (list): List of class names.\n",
    "        target_encoder (LabelEncoder): Fitted LabelEncoder instance.\n",
    "    \"\"\"\n",
    "    target_encoder = LabelEncoder()\n",
    "    target_encoded = target_encoder.fit_transform(target)\n",
    "    class_labels = target_encoder.classes_\n",
    "    return target_encoded, class_labels, target_encoder\n",
    "\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "\n",
    "# Encode target labels\n",
    "Y_encoded, class_labels, target_encoder = encode_targets(target)\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "print(f\"Number of unique classes: {len(class_labels)}\")\n",
    "print(f\"Class labels: {class_labels}\")\n",
    "\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    data, Y_encoded, test_size=0.2, random_state=SEED, stratify=Y_encoded\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")\n",
    "\n",
    "# Clean up to save memory\n",
    "del data\n",
    "del target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c2529dd-f363-4316-8e6c-c437943d58da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before preprocessing: X_test shape: (41992, 83)\n",
      "After preprocessing: X_test_transformed shape: (41992, 94)\n"
     ]
    }
   ],
   "source": [
    "# Load your best model (pipeline that includes preprocessing and classifier)\n",
    "best_model_path = \"./ML Models/best_svm_rbf_only_model_with_preproc__100.joblib\"\n",
    "best_model = joblib.load(best_model_path)\n",
    "\n",
    "\n",
    "preprocessor, classifier = joblib.load(best_model_path)   # ← this file is a tuple\n",
    "\n",
    "# 2) Wrap into a single Pipeline\n",
    "pipe = Pipeline([(\"preprocessor\", preprocessor), (\"clf\", classifier)])\n",
    "\n",
    "\n",
    "# Transform the test data\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "\n",
    "# Print the shape before and after preprocessing\n",
    "print(f\"Before preprocessing: X_test shape: {X_test.shape}\")\n",
    "print(f\"After preprocessing: X_test_transformed shape: {X_test_transformed.shape}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73103256-c415-4e8c-919a-cdc472c5645a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.compose._column_transformer.ColumnTransformer'> <class 'sklearn.svm._classes.SVC'>\n"
     ]
    }
   ],
   "source": [
    "print(type(preprocessor), type(classifier))\n",
    "n_features = X_test_transformed.shape[1]\n",
    "n_sv       = getattr(classifier, \"support_vectors_\", np.empty((0,0))).shape[0]\n",
    "n_classes  = len(classifier.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb2248b8-1d9a-4b64-9497-1a9ad59ce427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features=94, SVs=1980, approx float-bytes=752,452\n"
     ]
    }
   ],
   "source": [
    "# crude flash footprint estimate (floats only; ignores code/struct overhead)\n",
    "approx_bytes = n_sv * n_features * 4 + n_sv * 4 + n_classes * 4\n",
    "print(f\"Features={n_features}, SVs={n_sv}, approx float-bytes={approx_bytes:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "874a3bc2-4188-4c0c-9414-cac34163c1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote svm_model.h with classmap: {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: '10', 11: '11', 12: '12'}\n"
     ]
    }
   ],
   "source": [
    "# Make a clean index→label map (strings!)\n",
    "labels   = [str(l) for l in classifier.classes_.tolist()]\n",
    "classmap = {i: lbl for i, lbl in enumerate(labels)}\n",
    "\n",
    "c_code = port(classifier, classmap=classmap)   # emits predict(float*) API\n",
    "with open(\"./ML Models/svm_model.h\", \"w\") as f:\n",
    "    f.write(c_code)\n",
    "\n",
    "print(\"Wrote svm_model.h with classmap:\", classmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27efac32-0885-481b-8193-662912bf6031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn preds: [3 1 3 3 0]\n",
      "Classes order used in classmap: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12']\n"
     ]
    }
   ],
   "source": [
    "# 1) Sanity: predict on a few samples matches sklearn\n",
    "import numpy as np\n",
    "from micromlgen import port\n",
    "\n",
    "# Use your existing transform\n",
    "X0 = X_test[:5]\n",
    "X0_t = preprocessor.transform(X0)\n",
    "y0 = classifier.predict(X0_t)\n",
    "\n",
    "# Build a tiny pure-Python adapter from the generated header (optional):\n",
    "# micromlgen also supports a \"port\" to Python for quick parity checks if needed.\n",
    "\n",
    "print(\"Sklearn preds:\", y0)\n",
    "print(\"Classes order used in classmap:\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e48b44f0-58e8-4de4-9591-f2ed021d60ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sample index: 15795\n",
      "INPUT_DIM = 94\n",
      "Predicted class: 1\n",
      "static const float Xf[INPUT_DIM] = {\n",
      "  0.30141717f, -0.080645718f, 0.020115202f, 1.1857766f, 1.2068995f, 1.3959353f, 0.34605837f, -0.6197083f,\n",
      "  -0.61959982f, -0.61965555f, 0.78057432f, 1.1293296f, -0.0075954632f, -0.30413029f, 0.98806405f, 0.17217696f,\n",
      "  -0.045220543f, -0.38211912f, -1.0798947f, -0.97317886f, 1.4306349f, 0.41692045f, 1.234928f, -0.098205313f,\n",
      "  0.0f, -0.016975235f, -0.016449537f, -0.9566254f, 1.4877127f, 1.4213978f, 0.72330362f, 0.88266402f,\n",
      "  -0.26095688f, 1.4374388f, 0.25050029f, 0.601695f, 1.3703147f, -0.28127944f, 1.3950447f, 0.51172072f,\n",
      "  0.69229823f, 1.061035f, -0.010318507f, 0.16696407f, 0.020379305f, -0.068191603f, -0.05046995f, -0.016098274f,\n",
      "  -0.20680085f, -0.0024087375f, -0.05154267f, -0.091281354f, -0.022513881f, 0.16647471f, 0.020094311f, -0.098856926f,\n",
      "  -0.062487517f, -0.60359454f, 1.0326749f, 0.97062308f, 1.2568408f, 0.13227861f, 2.33863f, 0.031060431f,\n",
      "  2.3846581f, 0.094111674f, -0.064262345f, 0.0016773159f, 1.9062865f, 1.2615135f, 0.42300361f, 1.7042037f,\n",
      "  -0.13352387f, -0.21690595f, -0.21452676f, -0.028600182f, -0.21666253f, -0.034397677f, -0.21887954f, -0.11665949f,\n",
      "  0.36782974f, 0.0f, 1.0f, 0.0f, 1.0f, 0.0f, 0.0f, 0.0f,\n",
      "  0.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f\n",
      "};\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Pick a random sample index\n",
    "idx = np.random.randint(len(X_test))\n",
    "\n",
    "# Preprocess that sample\n",
    "x0 = preprocessor.transform(X_test[idx:idx+1]).astype(np.float32).ravel()\n",
    "D  = x0.size\n",
    "print(f\"Random sample index: {idx}\")\n",
    "print(\"INPUT_DIM =\", D)\n",
    "\n",
    "# Predict its class\n",
    "y_pred = classifier.predict(x0.reshape(1, -1))[0]\n",
    "print(f\"Predicted class: {y_pred}\")\n",
    "\n",
    "# Pretty-print as a C float array with '0.0f' and '1.0f' for integers\n",
    "def to_c_array(a, var='Xf', name_dim='INPUT_DIM', per_line=8):\n",
    "    def fmt(v):\n",
    "        # Format as float literal with 'f' suffix, forcing decimal point\n",
    "        if v == 0:\n",
    "            return \"0.0f\"\n",
    "        elif v == 1:\n",
    "            return \"1.0f\"\n",
    "        else:\n",
    "            return f\"{v:.8g}f\"\n",
    "    vals = [fmt(v) for v in a]\n",
    "    lines = [\", \".join(vals[i:i+per_line]) for i in range(0, len(vals), per_line)]\n",
    "    return f\"static const float {var}[{name_dim}] = {{\\n  \" + \",\\n  \".join(lines) + \"\\n};\"\n",
    "\n",
    "print(to_c_array(x0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "724baf94-f594-442c-8877-69ea966c339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import treelite\n",
    "from treelite.frontend import load_lightgbm_model\n",
    "import tl2cgen\n",
    "import os\n",
    "\n",
    "# --- Paths (everything under ./ML Models) ---\n",
    "BASE      = Path(\"./ML Models\")               # folder with a space - safe via Path\n",
    "BASE.mkdir(parents=True, exist_ok=True)\n",
    "BUILD     = BASE / \"build\"\n",
    "BUILD.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "JOBLIB    = BASE / \"best_lgbm_model_with_preproc__100.joblib\"\n",
    "TXT_MODEL = BASE / \"lgbm.txt\"\n",
    "PKG_ZIP   = BUILD / \"lgbm_src.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecb52a08-a9b0-4247-a353-bc0c5f187d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load (preprocessor, booster_str) from your joblib ---\n",
    "preprocessor, booster_str = joblib.load(JOBLIB)\n",
    "booster = lgb.Booster(model_str=booster_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e8b0890-8da7-4594-8bfd-87cd67b74d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LightGBM model to ML Models/lgbm.txt\n"
     ]
    }
   ],
   "source": [
    "booster.save_model(str(TXT_MODEL), num_iteration=-1)\n",
    "print(f\"Saved LightGBM model to {TXT_MODEL}\")\n",
    "\n",
    "# --- Treelite: load and export C/C++ sources ---\n",
    "model = treelite.frontend.load_lightgbm_model(TXT_MODEL)\n",
    "os.makedirs(\"./ML Models/build\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef52bd9a-b534-4d2c-ad4a-c7c848b72535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:06:24] /project/src/compiler/ast/split.cc:35: Parallel compilation enabled; member trees will be divided into 3 translation units.\n",
      "Wrote ML Models/build/lgbm_src.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:06:24] /tmp/tmpfk5q71dd/libbuild/_deps/treelite-src/src/serializer.cc:202: The model you are loading originated from a newer Treelite version; some functionalities may be unavailable.\n",
      "Currently running Treelite version 4.1.2\n",
      "The model checkpoint was generated from Treelite version 4.4.1\n"
     ]
    }
   ],
   "source": [
    "model = load_lightgbm_model(str(TXT_MODEL))\n",
    "\n",
    "\n",
    "tl2cgen.export_srcpkg(\n",
    "    model,\n",
    "    toolchain=\"gcc\",\n",
    "    pkgpath=str(PKG_ZIP),           # ZIP will be: ./ML Models/build/lgbm_src.zip\n",
    "    libname=\"lgbm\",\n",
    "    params={\n",
    "        \"quantize\": 0,              # you asked for NO quantization\n",
    "        \"parallel_comp\": 3          # split across files for easier Arduino builds\n",
    "    },\n",
    ")\n",
    "print(f\"Wrote {PKG_ZIP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c84660f-e0e3-4f33-841c-8a8cf2c0b4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8440c1e0-f780-449a-9c99-89bf651814ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from treelite.frontend import load_xgboost_model\n",
    "import xgboost as xgb\n",
    "import treelite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff3eb26d-acad-4789-bbd0-2c12cae6eac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Paths (everything inside ./ML Models) ---\n",
    "BASE      = Path(\"./ML Models\")\n",
    "BASE.mkdir(parents=True, exist_ok=True)\n",
    "BUILD     = BASE / \"build\"\n",
    "BUILD.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "JOBLIB    = BASE / \"best_xgb_model_100.joblib\"\n",
    "XGB_JSON  = BASE / \"xgb.json\"\n",
    "PKG_ZIP   = BUILD / \"xgb_src.zip\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e4d3651-1780-4007-b1a9-f40f745b111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load your pipeline and extract parts ---\n",
    "pipeline = joblib.load(JOBLIB)\n",
    "classifier = pipeline.named_steps[\"classifier\"]   # XGBClassifier\n",
    "preprocessor = pipeline.named_steps[\"preprocessor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbdac583-4a82-4011-baab-fdf9386a80e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved XGBoost model to ML Models/xgb.json\n"
     ]
    }
   ],
   "source": [
    "# --- Save Booster to JSON (Treelite prefers JSON) ---\n",
    "booster: xgb.Booster = classifier.get_booster()\n",
    "# If you trained with early-stopping, best_ntree_limit is embedded in the JSON metadata\n",
    "booster.save_model(str(XGB_JSON))\n",
    "print(f\"Saved XGBoost model to {XGB_JSON}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fdbc89f-b079-4ed9-8416-b50b30dbac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Treelite: load and export C/C++ sources ---\n",
    "model = load_xgboost_model(str(XGB_JSON))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2168c519-88e3-45d5-94ad-98058e18b76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:43:44] /project/src/compiler/ast/split.cc:35: Parallel compilation enabled; member trees will be divided into 3 translation units.\n",
      "Wrote ML Models/build/xgb_src.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:43:44] /tmp/tmpfk5q71dd/libbuild/_deps/treelite-src/src/serializer.cc:202: The model you are loading originated from a newer Treelite version; some functionalities may be unavailable.\n",
      "Currently running Treelite version 4.1.2\n",
      "The model checkpoint was generated from Treelite version 4.4.1\n"
     ]
    }
   ],
   "source": [
    "tl2cgen.export_srcpkg(\n",
    "    model,\n",
    "    toolchain=\"gcc\",\n",
    "    pkgpath=str(PKG_ZIP),     # => ./ML Models/build/xgb_src.zip\n",
    "    libname=\"xgb\",\n",
    "    params={\n",
    "        \"quantize\": 0,        # keep float thresholds (you preferred no quantization)\n",
    "        \"parallel_comp\": 3    # split into multiple .c files → easier Arduino builds\n",
    "    }\n",
    ")\n",
    "print(f\"Wrote {PKG_ZIP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5f50d85-adef-4c8e-b1c6-c1212b162d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PY idx: 0 pred: 3 label: 3\n",
      "top-3: [(3, 0.99997675), (10, 3.677209e-06), (8, 3.6407546e-06)]\n",
      "INPUT_DIM = 94\n",
      "static const float Xf[94] = {\n",
      "  -1.4116956f, -0.18476674f, -0.039243355f, -0.57866377f, -0.51474041f, -0.54112536f, -0.32181111f, 0.12058315f,\n",
      "  0.12065638f, 0.12062006f, 0.36582685f, -0.57956153f, -0.0058834325f, -0.30279472f, -0.44441816f, 0.172683f,\n",
      "  -0.044832811f, -0.38126367f, 0.35925177f, 0.59046739f, -0.55538052f, -0.49170452f, -0.55805647f, -0.098239638f,\n",
      "  0.0f, -0.016975235f, -0.016448833f, 1.0054787f, -0.65628535f, -0.59171414f, -0.18199365f, -0.62993717f,\n",
      "  -0.26037058f, -0.74278361f, -0.21096753f, -0.60074139f, -0.71686429f, -0.27978122f, -0.69918746f, -0.31448436f,\n",
      "  -0.55644727f, -0.54357797f, -0.01058036f, -0.26964867f, -0.039033215f, -0.10054152f, -0.16925305f, -0.016220458f,\n",
      "  -0.30149484f, -0.040323764f, -0.07476715f, -0.11610999f, -0.025493743f, -0.26883566f, -0.039261725f, -0.13477188f,\n",
      "  -0.16623086f, 0.13782649f, -0.57980216f, -0.46938577f, -0.61824411f, -0.16905496f, -0.59314102f, -0.15524092f,\n",
      "  -0.5248313f, -0.21597643f, -0.094163395f, -0.13695471f, -0.45558763f, -0.39895615f, -0.14466932f, -0.46870884f,\n",
      "  -0.13309336f, -0.21631862f, -0.21449991f, -0.026001193f, -0.21629414f, -0.034769282f, -0.54036176f, -0.42199826f,\n",
      "  -0.43852174f, 0.0f, 1.0f, 0.0f, 1.0f, 0.0f, 0.0f, 0.0f,\n",
      "  0.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f\n",
      "};\n"
     ]
    }
   ],
   "source": [
    "i = 0  # choose a fixed row index you will paste to the MCU\n",
    "x0 = preprocessor.transform(X_test[i:i+1]).astype(np.float32)\n",
    "proba = classifier.predict_proba(x0)[0]        # shape (K,)\n",
    "pred  = int(proba.argmax())\n",
    "print(\"PY idx:\", i, \"pred:\", pred, \"label:\", classifier.classes_[pred])\n",
    "print(\"top-3:\", sorted(enumerate(proba), key=lambda t:t[1], reverse=True)[:3])\n",
    "\n",
    "# Emit the exact C array to paste into Arduino:\n",
    "def to_c(a, var=\"Xf\", dim=None, per_line=8):\n",
    "    if dim is None: dim = a.size\n",
    "    def fmt(v): return \"0.0f\" if v == 0 else (\"1.0f\" if v == 1 else f\"{float(v):.8g}f\")\n",
    "    vals=[fmt(v) for v in a.ravel()]\n",
    "    lines=[\", \".join(vals[i:i+per_line]) for i in range(0,len(vals),per_line)]\n",
    "    return f\"static const float {var}[{dim}] = {{\\n  \" + \",\\n  \".join(lines) + \"\\n};\"\n",
    "print(\"INPUT_DIM =\", x0.size)\n",
    "print(to_c(x0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d412482-a13f-415b-90dd-4d8d9d72a1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote xgb_labels.h\n"
     ]
    }
   ],
   "source": [
    "labels = [str(x) for x in classifier.classes_.tolist()]\n",
    "with open(\"./ML Models/xgb_labels.h\", \"w\") as f:\n",
    "    f.write(\"#pragma once\\n\")\n",
    "    f.write(f\"static const int XGB_NUM_CLASSES = {len(labels)};\\n\")\n",
    "    f.write(\"static const char* XGB_LABELS[] = {\\n  \")\n",
    "    f.write(\",\\n  \".join(f\"\\\"{lbl}\\\"\" for lbl in labels))\n",
    "    f.write(\"\\n};\\n\")\n",
    "print(\"Wrote xgb_labels.h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d123ef79-d491-447b-8408-f8830daf4785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09264be3-c287-4fbe-bdb4-2e74e5291686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Paths (everything inside ./ML Models) ---\n",
    "BASE      = Path(\"./ML Models\")\n",
    "BASE.mkdir(parents=True, exist_ok=True)\n",
    "BUILD     = BASE / \"build\"\n",
    "BUILD.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "JOBLIB    = BASE / \"best_rf_model_100.joblib\"\n",
    "RF_JSON  = BASE / \"rf.json\"\n",
    "PKG_ZIP   = BUILD / \"rf_src.zip\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b26bde3-af76-4a32-b648-9610c2b987d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load your pipeline and extract parts ---\n",
    "pipeline = joblib.load(JOBLIB)\n",
    "classifier = pipeline.named_steps[\"classifier\"]   # XGBClassifier\n",
    "preprocessor = pipeline.named_steps[\"preprocessor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f676fb5e-a888-4974-8d71-dac85eccfddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = treelite.sklearn.import_model(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e6fefb8-f5a2-4f3a-a335-3516514b20e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:12:09] /tmp/tmpfk5q71dd/libbuild/_deps/treelite-src/src/serializer.cc:202: The model you are loading originated from a newer Treelite version; some functionalities may be unavailable.\n",
      "Currently running Treelite version 4.1.2\n",
      "The model checkpoint was generated from Treelite version 4.4.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:12:09] /project/src/compiler/ast/split.cc:35: Parallel compilation enabled; member trees will be divided into 3 translation units.\n",
      "Wrote RF C package to ML Models/build/rf_src.zip\n"
     ]
    }
   ],
   "source": [
    "# Export to C\n",
    "tl2cgen.export_srcpkg(\n",
    "    model,\n",
    "    toolchain=\"gcc\",\n",
    "    pkgpath=str(BUILD / \"rf_src.zip\"),\n",
    "    libname=\"rf\",\n",
    "    params={\"quantize\": 0, \"parallel_comp\": 3}\n",
    ")\n",
    "print(\"Wrote RF C package to\", BUILD / \"rf_src.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd6624ad-b503-4037-90b9-54ce56c1f02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ML Models/build/rf_labels.h\n"
     ]
    }
   ],
   "source": [
    "# (Optional) write labels for on-device printing\n",
    "labels = [str(x) for x in classifier.classes_.tolist()]\n",
    "with open(BUILD / \"rf_labels.h\", \"w\") as f:\n",
    "    f.write(\"#pragma once\\n\")\n",
    "    f.write(f\"static const int RF_NUM_CLASSES = {len(labels)};\\n\")\n",
    "    f.write(\"static const char* RF_LABELS[] = {\\n  \")\n",
    "    f.write(\",\\n  \".join(f\"\\\"{lbl}\\\"\" for lbl in labels))\n",
    "    f.write(\"\\n};\\n\")\n",
    "print(\"Wrote\", BUILD / \"rf_labels.h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d896a4-1046-42ea-a273-10fbb793ddb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tuninggpu310)",
   "language": "python",
   "name": "tuninggpu310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
