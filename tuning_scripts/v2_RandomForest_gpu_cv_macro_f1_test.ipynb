{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import gc # garbage collection\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1.0\n"
     ]
    }
   ],
   "source": [
    "print(optuna.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To fix TQDM Warning:\n",
    "# https://stackoverflow.com/questions/75349025/vs-code-jupyter-notebook-iprogress-not-found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gc.collect() # forces garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sklearn.exceptions\n",
    "'''\n",
    "During Optuna's Hyperparameter Optimization, we get this error:\n",
    " UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in\n",
    " labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "\n",
    "Even with Stratified KFold, because we calculate precision like:\n",
    "True Positive / Predicted Yes\n",
    "\n",
    "And if we predicted all our samples to be No\n",
    "\n",
    "Then Predicted Yes = 0, resulting in undefined precision -- possibly undefined F-score\n",
    "Link:\n",
    "https://stackoverflow.com/questions/35225369/scikit-learn-error-message-precision-and-f-score-are-ill-defined-and-being-set\n",
    "'''\n",
    "# warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "warnings.filterwarnings(\"ignore\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Seed at file level\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Experiment Configuration\n",
    "FILE_NAME = 'RandomForest_No_RFECV_No_PCA'\n",
    "N_FOLDS = 10\n",
    "CV_RESULT_DIR = \"./randomforest_cv_results\"\n",
    "TUNED_OR_NO = \"Tuned_Hyperparameters\"  # or \"Untuned_Hyperparameters\"\n",
    "N_REPEATS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure directories are created for results\n",
    "os.makedirs(f\"./{FILE_NAME}/{TUNED_OR_NO}/{CV_RESULT_DIR}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "url = './RT_IOT2022_new.csv'\n",
    "data = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '-' with 'None' in categorical columns\n",
    "data['service'] = data['service'].replace('-', 'None')\n",
    "data['proto'] = data['proto'].replace('-', 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the target column\n",
    "target = data['Attack_type']\n",
    "data = data.drop(columns = ['Attack_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, target, test_size= 0.2, random_state=SEED, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory-saving\n",
    "del data\n",
    "del target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_f1_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the macro F1 score for multiclass classification.\n",
    "    \n",
    "    Parameters:\n",
    "        y_true (array-like): True class labels.\n",
    "        y_pred (array-like): Predicted class labels.\n",
    "\n",
    "    Returns:\n",
    "        float: Macro F1 score.\n",
    "    \"\"\"\n",
    "    return f1_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define cross-validation strategy\n",
    "    rskf = RepeatedStratifiedKFold(n_splits=N_FOLDS, n_repeats=N_REPEATS, random_state=SEED)\n",
    "    \n",
    "    # Suggest hyperparameters for RandomForest\n",
    "    bootstrap = trial.suggest_categorical(\"bootstrap\", [True, False])\n",
    "    max_samples = trial.suggest_float(\"max_samples\", 0.2, 1.0) if bootstrap else None\n",
    "    \n",
    "    param = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 50),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 300),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 50),\n",
    "        \"max_features\": trial.suggest_categorical(\"max_features\", ['sqrt', 'log2']),\n",
    "        \"bootstrap\": bootstrap,\n",
    "        \"max_samples\": max_samples,\n",
    "        \"random_state\": SEED,\n",
    "        \"criterion\": trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "    \n",
    "    # Initialize the RandomForestClassifier with suggested hyperparameters\n",
    "    model = RandomForestClassifier(**param, n_estimators=1_500)\n",
    "    \n",
    "    # Lists to store metrics\n",
    "    trial_macro_f1_score = []\n",
    "    \n",
    "    # Iterate over each fold\n",
    "    for fold_idx, (train_idx, valid_idx) in enumerate(rskf.split(X_train, Y_train)):\n",
    "        fold_num = fold_idx + 1\n",
    "        \n",
    "        print(f\"Trial {trial.number}: Starting Fold {fold_num}/{N_FOLDS * N_REPEATS}\")\n",
    "        \n",
    "        # Split the raw data into training and validation sets for this fold\n",
    "        X_train_fold = X_train.iloc[train_idx].copy()\n",
    "        Y_train_fold = Y_train.iloc[train_idx].copy()\n",
    "        X_valid_fold = X_train.iloc[valid_idx].copy()\n",
    "        Y_valid_fold = Y_train.iloc[valid_idx].copy()\n",
    "        \n",
    "        # Preprocessing within the fold\n",
    "        # Reset index to ensure alignment\n",
    "        X_train_fold.reset_index(drop=True, inplace=True)\n",
    "        X_valid_fold.reset_index(drop=True, inplace=True)\n",
    "        Y_train_fold.reset_index(drop=True, inplace=True)\n",
    "        Y_valid_fold.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # Standardizing numerical features\n",
    "        num_cols = X_train_fold.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "        \n",
    "        # Initialize the scaler\n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        # Fit the scaler on the training data\n",
    "        X_train_fold[num_cols] = scaler.fit_transform(X_train_fold[num_cols])\n",
    "        \n",
    "        # Transform the validation data\n",
    "        X_valid_fold[num_cols] = scaler.transform(X_valid_fold[num_cols])\n",
    "        \n",
    "        # Encode the target variable (convert to integer labels)\n",
    "        Y_train_fold = Y_train_fold.astype('category').cat.codes\n",
    "        Y_valid_fold = Y_valid_fold.astype('category').cat.codes\n",
    "\n",
    "        # Identify categorical columns to encode\n",
    "        categorical_cols = ['proto', 'service']\n",
    "        \n",
    "        # Encoding categorical variables using OneHotEncoder\n",
    "        encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)  # Updated parameter\n",
    "        encoder.fit(X_train_fold[categorical_cols])\n",
    "        \n",
    "        # Transform both training and validation sets\n",
    "        X_train_encoded = encoder.transform(X_train_fold[categorical_cols])\n",
    "        X_valid_encoded = encoder.transform(X_valid_fold[categorical_cols])\n",
    "        \n",
    "        # Convert to DataFrame and reset index\n",
    "        X_train_encoded_df = pd.DataFrame(X_train_encoded, columns=encoder.get_feature_names_out())\n",
    "        X_valid_encoded_df = pd.DataFrame(X_valid_encoded, columns=encoder.get_feature_names_out())\n",
    "        \n",
    "        # Drop original categorical columns\n",
    "        X_train_fold = X_train_fold.drop(categorical_cols, axis=1)\n",
    "        X_valid_fold = X_valid_fold.drop(categorical_cols, axis=1)\n",
    "        \n",
    "        # Concatenate encoded features\n",
    "        X_train_fold = pd.concat([X_train_fold, X_train_encoded_df], axis=1)\n",
    "        X_valid_fold = pd.concat([X_valid_fold, X_valid_encoded_df], axis=1)\n",
    "        \n",
    "        # Cleanup to free memory\n",
    "        del X_train_encoded_df, X_valid_encoded_df, encoder\n",
    "        \n",
    "        # Train the RandomForest model\n",
    "        model.fit(X_train_fold, Y_train_fold)\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_pred = model.predict(X_valid_fold)\n",
    "        \n",
    "        # Compute metrics\n",
    "        macro_f1 = macro_f1_score(Y_valid_fold, y_pred)\n",
    "        trial_macro_f1_score.append(macro_f1)\n",
    "        \n",
    "        print(f\"Trial {trial.number}: Fold {fold_num} Macro F1 Score = {macro_f1:.4f}\")\n",
    "        \n",
    "        # Clean up to free memory\n",
    "        del X_train_fold, X_valid_fold, scaler, y_pred\n",
    "        gc.collect()\n",
    "    \n",
    "    del model\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    # Compute average metrics across all folds\n",
    "    mean_macro_f1 = np.mean(trial_macro_f1_score)\n",
    "\n",
    "    trial.report(mean_macro_f1, step=N_FOLDS * N_REPEATS)\n",
    "\n",
    "    # Check if trial should be pruned\n",
    "    if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "    \n",
    "    print(f\"Trial ({trial.number}) | Mean Macro F1 Score ± St. Dev. -- {mean_macro_f1:.4f} ± {np.std(trial_macro_f1_score):.4f}\")\n",
    "\n",
    "    \n",
    "    return mean_macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-04 09:45:43,502] Trial 69 finished with value: 0.9634334109101101 and parameters: {'bootstrap': False, 'max_depth': 25, 'min_samples_split': 19, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'criterion': 'entropy'}. Best is trial 60 with value: 0.9638293291917468.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial (69) | Mean Macro F1 Score ± St. Dev. -- 0.9634 ± 0.0220\n",
      "Study statistics: \n",
      "  Number of finished trials:  70\n",
      "  Number of pruned trials:  56\n",
      "  Number of complete trials:  14\n",
      "Best trial:\n",
      "  Value:  0.9638293291917468\n",
      "  Params: \n",
      "    bootstrap: False\n",
      "    max_depth: 44\n",
      "    min_samples_split: 14\n",
      "    min_samples_leaf: 1\n",
      "    max_features: log2\n",
      "    criterion: gini\n",
      "Best Parameters Saved:\n",
      "{'bootstrap': False, 'max_depth': 44, 'min_samples_split': 14, 'min_samples_leaf': 1, 'max_features': 'log2', 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    STORAGE = \"sqlite:///db.sqlite3\"\n",
    "    SAMPLER = optuna.samplers.TPESampler(seed=SEED, multivariate=True)\n",
    "    STUDY_NAME = \"randomforest-hyperparameter-tuning\"\n",
    "    \n",
    "    study = optuna.create_study(\n",
    "        storage=STORAGE, \n",
    "        sampler=SAMPLER,\n",
    "        study_name=STUDY_NAME, \n",
    "        direction=\"maximize\",\n",
    "        pruner=optuna.pruners.SuccessiveHalvingPruner(),\n",
    "        load_if_exists=True  # Change to False if starting fresh\n",
    "    )\n",
    "    \n",
    "    # Handle stale trials\n",
    "    optuna.storages.fail_stale_trials(study)\n",
    "    \n",
    "    # Optimize\n",
    "    study.optimize(objective, n_trials=35, n_jobs=1, gc_after_trial=True)\n",
    "\n",
    "    # Retrieve pruned and complete trials\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    # Print study statistics\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    # Print the best trial\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "    \n",
    "    # Save best parameters\n",
    "    best_params = study.best_params\n",
    "    with open(f\"./{FILE_NAME}/{TUNED_OR_NO}/{CV_RESULT_DIR}/best_params.txt\", \"w\") as f:\n",
    "        f.write(str(best_params))\n",
    "    print(\"Best Parameters Saved:\")\n",
    "    print(best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Param importance:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': np.float64(0.4622415477746472),\n",
       " 'min_samples_split': np.float64(0.3316206650904039),\n",
       " 'bootstrap': np.float64(0.06963054510153012),\n",
       " 'criterion': np.float64(0.06433677170255896),\n",
       " 'max_depth': np.float64(0.05158042963626872),\n",
       " 'max_features': np.float64(0.02059004069459127)}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"     Param importance:\")\n",
    "optuna.importance.get_param_importances(study,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('bootstrap', False), ('max_depth', 44), ('min_samples_split', 14), ('min_samples_leaf', 1), ('max_features', 'log2'), ('criterion', 'gini')])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial.params.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optuna.importance.get_param_importances(study,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect() # forces garbage collection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optunasec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
