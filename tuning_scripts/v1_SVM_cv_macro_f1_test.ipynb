{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import gc # garbage collection\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.svm import SVC\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/SDR/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1.0\n"
     ]
    }
   ],
   "source": [
    "print(optuna.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To fix TQDM Warning:\n",
    "# https://stackoverflow.com/questions/75349025/vs-code-jupyter-notebook-iprogress-not-found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gc.collect() # forces garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sklearn.exceptions\n",
    "'''\n",
    "During Optuna's Hyperparameter Optimization, we get this error:\n",
    " UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in\n",
    " labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "\n",
    "Even with Stratified KFold, because we calculate precision like:\n",
    "True Positive / Predicted Yes\n",
    "\n",
    "And if we predicted all our samples to be No\n",
    "\n",
    "Then Predicted Yes = 0, resulting in undefined precision -- possibly undefined F-score\n",
    "Link:\n",
    "https://stackoverflow.com/questions/35225369/scikit-learn-error-message-precision-and-f-score-are-ill-defined-and-being-set\n",
    "'''\n",
    "# warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "warnings.filterwarnings(\"ignore\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Seed at file level\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Experiment Configuration\n",
    "FILE_NAME = 'SVC_No_RFECV_No_PCA'\n",
    "N_FOLDS = 2\n",
    "CV_RESULT_DIR = \"./svm_cv_results\"\n",
    "TUNED_OR_NO = \"Tuned_Hyperparameters\"  # or \"Untuned_Hyperparameters\"\n",
    "N_REPEATS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure directories are created for results\n",
    "os.makedirs(f\"./{FILE_NAME}/{TUNED_OR_NO}/{CV_RESULT_DIR}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "url = './RT_IOT2022_new.csv'\n",
    "data = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '-' with 'None' in categorical columns\n",
    "data['service'] = data['service'].replace('-', 'None')\n",
    "data['proto'] = data['proto'].replace('-', 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the target column\n",
    "target = data['Attack_type']\n",
    "data = data.drop(columns = ['Attack_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, target, test_size= 0.2, random_state=SEED, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory-saving\n",
    "del data\n",
    "del target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_f1_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the macro F1 score for multiclass classification.\n",
    "    \n",
    "    Parameters:\n",
    "        y_true (array-like): True class labels.\n",
    "        y_pred (array-like): Predicted class labels.\n",
    "\n",
    "    Returns:\n",
    "        float: Macro F1 score.\n",
    "    \"\"\"\n",
    "    return f1_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define cross-validation strategy\n",
    "    rskf = RepeatedStratifiedKFold(n_splits=N_FOLDS, n_repeats=N_REPEATS, random_state=SEED)\n",
    "    \n",
    "    # Define hyperparameter space\n",
    "    C = trial.suggest_loguniform('C', 1e-10, 1e5)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf'])\n",
    "    degree = trial.suggest_int('degree', 1, 5) if kernel == 'poly' else 3\n",
    "    gamma = trial.suggest_loguniform('gamma', 1e-10, 1e5)\n",
    "    \n",
    "    # SVM model\n",
    "    model = SVC(C=C, kernel=kernel, degree=degree, gamma=gamma, random_state=42, max_iter=1_500)\n",
    "    \n",
    "    # Lists to store metrics\n",
    "    trial_macro_f1_score = []\n",
    "    \n",
    "    # Iterate over each fold\n",
    "    for fold_idx, (train_idx, valid_idx) in enumerate(rskf.split(X_train, Y_train)):\n",
    "        fold_num = fold_idx + 1\n",
    "        \n",
    "        print(f\"Trial {trial.number}: Starting Fold {fold_num}/{N_FOLDS * N_REPEATS}\")\n",
    "        \n",
    "        # Split the raw data into training and validation sets for this fold\n",
    "        X_train_fold = X_train.iloc[train_idx].copy()\n",
    "        Y_train_fold = Y_train.iloc[train_idx].copy()\n",
    "        X_valid_fold = X_train.iloc[valid_idx].copy()\n",
    "        Y_valid_fold = Y_train.iloc[valid_idx].copy()\n",
    "        \n",
    "        # Preprocessing within the fold\n",
    "        # Reset index to ensure alignment\n",
    "        X_train_fold.reset_index(drop=True, inplace=True)\n",
    "        X_valid_fold.reset_index(drop=True, inplace=True)\n",
    "        Y_train_fold.reset_index(drop=True, inplace=True)\n",
    "        Y_valid_fold.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # Standardizing numerical features\n",
    "        num_cols = X_train_fold.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "        \n",
    "        # Initialize the scaler\n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        # Fit the scaler on the training data\n",
    "        X_train_fold[num_cols] = scaler.fit_transform(X_train_fold[num_cols])\n",
    "        \n",
    "        # Transform the validation data\n",
    "        X_valid_fold[num_cols] = scaler.transform(X_valid_fold[num_cols])\n",
    "        \n",
    "        # Encode the target variable (convert to integer labels)\n",
    "        Y_train_fold = Y_train_fold.astype('category').cat.codes\n",
    "        Y_valid_fold = Y_valid_fold.astype('category').cat.codes\n",
    "\n",
    "        # Identify categorical columns to encode\n",
    "        categorical_cols = ['proto', 'service']\n",
    "        \n",
    "        # Encoding categorical variables using OneHotEncoder\n",
    "        encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)  # Updated parameter\n",
    "        encoder.fit(X_train_fold[categorical_cols])\n",
    "        \n",
    "        # Transform both training and validation sets\n",
    "        X_train_encoded = encoder.transform(X_train_fold[categorical_cols])\n",
    "        X_valid_encoded = encoder.transform(X_valid_fold[categorical_cols])\n",
    "        \n",
    "        # Convert to DataFrame and reset index\n",
    "        X_train_encoded_df = pd.DataFrame(X_train_encoded, columns=encoder.get_feature_names_out())\n",
    "        X_valid_encoded_df = pd.DataFrame(X_valid_encoded, columns=encoder.get_feature_names_out())\n",
    "        \n",
    "        # Drop original categorical columns\n",
    "        X_train_fold = X_train_fold.drop(categorical_cols, axis=1)\n",
    "        X_valid_fold = X_valid_fold.drop(categorical_cols, axis=1)\n",
    "        \n",
    "        # Concatenate encoded features\n",
    "        X_train_fold = pd.concat([X_train_fold, X_train_encoded_df], axis=1)\n",
    "        X_valid_fold = pd.concat([X_valid_fold, X_valid_encoded_df], axis=1)\n",
    "        \n",
    "        # Cleanup to free memory\n",
    "        del X_train_encoded_df, X_valid_encoded_df, encoder\n",
    "        \n",
    "        # Train the RandomForest model\n",
    "        model.fit(X_train_fold, Y_train_fold)\n",
    "        \n",
    "        # Predict on validation data\n",
    "        y_pred = model.predict(X_valid_fold)\n",
    "        \n",
    "        # Compute metrics\n",
    "        macro_f1 = macro_f1_score(Y_valid_fold, y_pred)\n",
    "        trial_macro_f1_score.append(macro_f1)\n",
    "        \n",
    "        print(f\"Trial {trial.number}: Fold {fold_num} Macro F1 Score = {macro_f1:.4f}\")\n",
    "        \n",
    "        # Clean up to free memory\n",
    "        del X_train_fold, X_valid_fold, scaler, y_pred\n",
    "        gc.collect()\n",
    "    \n",
    "    del model\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    # Compute average metrics across all folds\n",
    "    mean_macro_f1 = np.mean(trial_macro_f1_score)\n",
    "\n",
    "    trial.report(mean_macro_f1, step=N_FOLDS * N_REPEATS)\n",
    "\n",
    "    # Check if trial should be pruned\n",
    "    if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "    \n",
    "    print(f\"Trial ({trial.number}) | Mean Macro F1 Score ± St. Dev. -- {mean_macro_f1:.4f} ± {np.std(trial_macro_f1_score):.4f}\")\n",
    "\n",
    "    \n",
    "    return mean_macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-03 17:45:37,266] Trial 2 finished with value: 0.6293892824861566 and parameters: {'C': 35371.03617593232, 'kernel': 'linear', 'gamma': 5.637254575816134e-08}. Best is trial 2 with value: 0.6293892824861566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial (2) | Mean Macro F1 Score ± St. Dev. -- 0.6294 ± 0.0652\n",
      "Study statistics: \n",
      "  Number of finished trials:  3\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  3\n",
      "Best trial:\n",
      "  Value:  0.6293892824861566\n",
      "  Params: \n",
      "    C: 35371.03617593232\n",
      "    kernel: linear\n",
      "    gamma: 5.637254575816134e-08\n",
      "Best Parameters Saved:\n",
      "{'C': 35371.03617593232, 'kernel': 'linear', 'gamma': 5.637254575816134e-08}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    STORAGE = \"sqlite:///db.sqlite3\"\n",
    "    SAMPLER = optuna.samplers.TPESampler(seed=SEED, multivariate=True)\n",
    "    STUDY_NAME = \"svm-hyperparameter-tuning\"\n",
    "    \n",
    "    study = optuna.create_study(\n",
    "        storage=STORAGE, \n",
    "        sampler=SAMPLER,\n",
    "        study_name=STUDY_NAME, \n",
    "        direction=\"maximize\",\n",
    "        pruner=optuna.pruners.SuccessiveHalvingPruner(),\n",
    "        load_if_exists=True  # Change to False if starting fresh\n",
    "    )\n",
    "    \n",
    "    # Handle stale trials\n",
    "    optuna.storages.fail_stale_trials(study)\n",
    "    \n",
    "    # Optimize\n",
    "    study.optimize(objective, n_trials=30, n_jobs=1, gc_after_trial=True)\n",
    "\n",
    "    # Retrieve pruned and complete trials\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    # Print study statistics\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    # Print the best trial\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "    \n",
    "    # Save best parameters\n",
    "    best_params = study.best_params\n",
    "    with open(f\"./{FILE_NAME}/{TUNED_OR_NO}/{CV_RESULT_DIR}/best_params.txt\", \"w\") as f:\n",
    "        f.write(str(best_params))\n",
    "    print(\"Best Parameters Saved:\")\n",
    "    print(best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Param importance:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.3742687643896164,\n",
       " 'kernel': 0.32694250241801504,\n",
       " 'C': 0.29878873319236854}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"     Param importance:\")\n",
    "optuna.importance.get_param_importances(study,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('C', 35371.03617593232), ('kernel', 'linear'), ('gamma', 5.637254575816134e-08)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial.params.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optuna.importance.get_param_importances(study,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect() # forces garbage collection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
