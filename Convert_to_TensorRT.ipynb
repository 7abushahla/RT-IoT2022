{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3744a6c-f81b-4ffa-b7b3-dcf221208a2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-12 19:37:47.463080: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-12 19:37:47.463122: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-12 19:37:47.463174: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-12 19:37:47.471130: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import tflite_runtime.interpreter as tflite\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a81be400-6314-4c41-9379-2b866bc47f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import tensorrt as trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8849172-eda5-4970-a1aa-19e86d8e7522",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba2fe513-c814-400d-a85e-8d8bde614631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loaded from ./exported_test_set.csv\n",
      "X_test shape: (41992, 83)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 1. Load the Exported Test Set\n",
    "# ---------------------------\n",
    "\n",
    "# Set the path to the exported test set CSV\n",
    "TEST_CSV = './exported_test_set.csv'\n",
    "\n",
    "if not os.path.exists(TEST_CSV):\n",
    "    raise FileNotFoundError(f\"Test set CSV not found at {TEST_CSV}\")\n",
    "\n",
    "# Load the test set from CSV\n",
    "X_test_export = pd.read_csv(TEST_CSV)\n",
    "\n",
    "# Assume the target column is named \"target\"\n",
    "Y_test = X_test_export[\"target\"].values\n",
    "X_test = X_test_export.drop(columns=[\"target\"])\n",
    "\n",
    "print(f\"Test set loaded from {TEST_CSV}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62f28a93-31c1-4bc7-8d40-07e36d04c9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_transformed shape: (41992, 94)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 2. Define the Preprocessor\n",
    "# ---------------------------\n",
    "# Identify columns (you must know these from training)\n",
    "numerical_cols = X_test.select_dtypes(include=[\"int64\", \"float64\", \"float32\"]).columns.tolist()\n",
    "categorical_cols = [\"proto\", \"service\"]\n",
    "\n",
    "# Create new transformers\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit on test set (or a subset) and transform test data\n",
    "X_test_transformed = preprocessor.fit_transform(X_test)\n",
    "print(f\"X_test_transformed shape: {X_test_transformed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7356b85d-6d05-41f3-991a-3113ef27793e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a9c88f4-aa1f-4c14-8baa-3af390410f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-12 18:08:25.520676: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-12 18:08:25.520719: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-12 18:08:25.520756: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-12 18:08:25.527576: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/rteam8/anaconda3/envs/tuninggpu310/lib/python3.10/runpy.py:126: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2025-08-12 18:08:29.709476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79064 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:09:00.0, compute capability: 8.0\n",
      "2025-08-12 18:08:29.711141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 79064 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:46:00.0, compute capability: 8.0\n",
      "2025-08-12 18:08:29.712708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 72227 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:85:00.0, compute capability: 8.0\n",
      "2025-08-12 18:08:29.714263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 79064 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:c7:00.0, compute capability: 8.0\n",
      "2025-08-12 18:08:29,721 - INFO - Using tensorflow=2.14.1, onnx=1.17.0, tf2onnx=1.16.1/15c810\n",
      "2025-08-12 18:08:29,721 - INFO - Using opset <onnx, 13>\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "2025-08-12 18:08:29,736 - INFO - Optimizing ONNX model\n",
      "2025-08-12 18:08:29,751 - INFO - After optimization: Identity -1 (1->0), Transpose -2 (2->0)\n",
      "2025-08-12 18:08:29,752 - INFO - \n",
      "2025-08-12 18:08:29,752 - INFO - Successfully converted TensorFlow model ./DL Models/best_FCNN_model.tflite to ONNX\n",
      "2025-08-12 18:08:29,752 - INFO - Model inputs: ['serving_default_input_1:0']\n",
      "2025-08-12 18:08:29,752 - INFO - Model outputs: ['StatefulPartitionedCall:0']\n",
      "2025-08-12 18:08:29,753 - INFO - ONNX model is saved at ./DL Models/best_FCNN_model.onnx\n"
     ]
    }
   ],
   "source": [
    "# !python -m tf2onnx.convert --tflite \"./DL Models/best_FCNN_model.tflite\" --output \"./DL Models/best_FCNN_model.onnx\" --opset 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d909c172-e06e-4d0d-85ac-0afb495adaf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-12 18:09:23.166175: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-12 18:09:23.166217: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-12 18:09:23.166254: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-12 18:09:23.173284: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/rteam8/anaconda3/envs/tuninggpu310/lib/python3.10/runpy.py:126: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2025-08-12 18:09:27.655691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79064 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:09:00.0, compute capability: 8.0\n",
      "2025-08-12 18:09:27.657282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 79064 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:46:00.0, compute capability: 8.0\n",
      "2025-08-12 18:09:27.658769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 72227 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:85:00.0, compute capability: 8.0\n",
      "2025-08-12 18:09:27.660248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 79064 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:c7:00.0, compute capability: 8.0\n",
      "2025-08-12 18:09:27,668 - INFO - Using tensorflow=2.14.1, onnx=1.17.0, tf2onnx=1.16.1/15c810\n",
      "2025-08-12 18:09:27,668 - INFO - Using opset <onnx, 13>\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "2025-08-12 18:09:27,691 - INFO - Optimizing ONNX model\n",
      "2025-08-12 18:09:27,725 - INFO - After optimization: Identity -2 (2->0), Transpose -5 (5->0)\n",
      "2025-08-12 18:09:27,726 - INFO - \n",
      "2025-08-12 18:09:27,726 - INFO - Successfully converted TensorFlow model ./DL Models/best_AE_model.tflite to ONNX\n",
      "2025-08-12 18:09:27,726 - INFO - Model inputs: ['serving_default_encoder_input:0']\n",
      "2025-08-12 18:09:27,726 - INFO - Model outputs: ['StatefulPartitionedCall:0', 'StatefulPartitionedCall:1']\n",
      "2025-08-12 18:09:27,726 - INFO - ONNX model is saved at ./DL Models/best_AE_model.onnx\n"
     ]
    }
   ],
   "source": [
    "!python -m tf2onnx.convert --tflite \"./DL Models/best_AE_model.tflite\" --output \"./DL Models/best_AE_model.onnx\" --opset 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdd0f68d-5d3e-4f57-a4f9-bddf7b633e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./DL Models/best_FCNN_model_simp.onnx\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnxsim import simplify\n",
    "m = onnx.load(\"./DL Models/best_FCNN_model.onnx\")\n",
    "onnx.checker.check_model(m)\n",
    "m_simp, ok = simplify(m)\n",
    "assert ok\n",
    "onnx.save(m_simp, \"./DL Models/best_FCNN_model_simp.onnx\")\n",
    "print(\"Saved: ./DL Models/best_FCNN_model_simp.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea85e11-363b-4fc7-bbb3-3ac2ae13dbcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f8b04d8-33ea-4681-a751-2024d97197ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX inputs: [('serving_default_input_1:0', (-1, 94))]\n"
     ]
    }
   ],
   "source": [
    "import os, onnx, numpy as np\n",
    "import tensorrt as trt\n",
    "\n",
    "# ==== config ====\n",
    "onnx_path   = \"./DL Models/best_FCNN_model.onnx\"   # your float (non-quantized) ONNX\n",
    "engine_path = \"./DL Models/best_FCNN_model.trt\"    # will save here\n",
    "use_fp16    = False                                 # still float; faster if GPU supports FP16\n",
    "\n",
    "# ==== sanity check ONNX ====\n",
    "model = onnx.load(onnx_path)\n",
    "onnx.checker.check_model(model)\n",
    "\n",
    "# helper: read input name & shape (with -1 for dynamic)\n",
    "def get_onnx_inputs(m):\n",
    "    ins = []\n",
    "    for i, t in enumerate(m.graph.input):\n",
    "        shp = []\n",
    "        for d in t.type.tensor_type.shape.dim:\n",
    "            shp.append(d.dim_value if d.dim_value > 0 else -1)\n",
    "        ins.append((t.name, tuple(shp)))\n",
    "    return ins\n",
    "\n",
    "inputs = get_onnx_inputs(model)\n",
    "print(\"ONNX inputs:\", inputs)\n",
    "\n",
    "# ==== build TRT engine ====\n",
    "logger  = trt.Logger(trt.Logger.WARNING)\n",
    "builder = trt.Builder(logger)\n",
    "flags   = 1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "network = builder.create_network(flags)\n",
    "config  = builder.create_builder_config()\n",
    "config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 29)  # 512 MiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c31dbc52-c0de-4751-bd14-8478c9d843ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX checker: OK\n",
      "[08/12/2025-18:59:32] [TRT] [I] The logger passed into createInferBuilder differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.\n",
      "\n",
      "Tactic sources limited to cuBLAS/cuBLASLt.\n",
      "[08/12/2025-18:59:32] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 283, GPU 441 (MiB)\n",
      "[08/12/2025-18:59:32] [TRT] [V] Trying to load shared library libnvinfer_builder_resource.so.8.5.3\n",
      "[08/12/2025-18:59:32] [TRT] [V] Loaded shared library libnvinfer_builder_resource.so.8.5.3\n",
      "[08/12/2025-18:59:34] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +691, GPU +152, now: CPU 974, GPU 593 (MiB)\n",
      "[08/12/2025-18:59:34] [TRT] [V] CUDA lazy loading is enabled.\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::BatchedNMSDynamic_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::BatchedNMS_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::BatchTilePlugin_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::Clip_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::CoordConvAC version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::CropAndResizeDynamic version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::CropAndResize version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::DecodeBbox3DPlugin version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::DetectionLayer_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::EfficientNMS_Explicit_TF_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::EfficientNMS_Implicit_TF_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::EfficientNMS_ONNX_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::EfficientNMS_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::FlattenConcat_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::fMHA_V2 version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::fMHCA version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::GenerateDetection_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::GridAnchor_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::GridAnchorRect_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::GroupNorm version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::InstanceNormalization_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::InstanceNormalization_TRT version 2\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::LayerNorm version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::LReLU_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::MultilevelCropAndResize_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::MultilevelProposeROI_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::MultiscaleDeformableAttnPlugin_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::NMSDynamic_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::NMS_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::Normalize_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::PillarScatterPlugin version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::PriorBox_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::ProposalDynamic version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::ProposalLayer_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::Proposal version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::PyramidROIAlign_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::Region_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::Reorg_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::ResizeNearest_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::ROIAlign_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::RPROI_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::ScatterND version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::SeqLen2Spatial version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::SpecialSlice_TRT version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::SplitGeLU version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::Split version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registered plugin creator - ::VoxelGeneratorPlugin version 1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Adding network input: serving_default_input_1:0 with dtype: float32, dimensions: (-1, 94)\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registering tensor: serving_default_input_1:0 for ONNX tensor: serving_default_input_1:0\n",
      "[08/12/2025-18:59:34] [TRT] [V] Importing initializer: sequential/dense_1/BiasAdd/ReadVariableOp\n",
      "[08/12/2025-18:59:34] [TRT] [V] Importing initializer: sequential/batch_normalization/batchnorm/sub\n",
      "[08/12/2025-18:59:34] [TRT] [V] Importing initializer: const_fold_opt__14\n",
      "[08/12/2025-18:59:34] [TRT] [V] Importing initializer: const_fold_opt__13\n",
      "[08/12/2025-18:59:34] [TRT] [V] Parsing node: sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 [MatMul]\n",
      "[08/12/2025-18:59:34] [TRT] [V] Searching for input: serving_default_input_1:0\n",
      "[08/12/2025-18:59:34] [TRT] [V] Searching for input: const_fold_opt__13\n",
      "[08/12/2025-18:59:34] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 [MatMul] inputs: [serving_default_input_1:0 -> (-1, 94)[FLOAT]], [const_fold_opt__13 -> (94, 64)[FLOAT]], \n",
      "[08/12/2025-18:59:34] [TRT] [V] Registering layer: const_fold_opt__13 for ONNX node: const_fold_opt__13\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registering layer: sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 for ONNX node: sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registering tensor: sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 for ONNX tensor: sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1\n",
      "[08/12/2025-18:59:34] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 [MatMul] outputs: [sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 -> (-1, 64)[FLOAT]], \n",
      "[08/12/2025-18:59:34] [TRT] [V] Parsing node: Add__8 [Add]\n",
      "[08/12/2025-18:59:34] [TRT] [V] Searching for input: sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Searching for input: sequential/batch_normalization/batchnorm/sub\n",
      "[08/12/2025-18:59:34] [TRT] [V] Add__8 [Add] inputs: [sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 -> (-1, 64)[FLOAT]], [sequential/batch_normalization/batchnorm/sub -> (64)[FLOAT]], \n",
      "[08/12/2025-18:59:34] [TRT] [V] Registering layer: sequential/batch_normalization/batchnorm/sub for ONNX node: sequential/batch_normalization/batchnorm/sub\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registering layer: Add__8 for ONNX node: Add__8\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registering tensor: Add__8:0 for ONNX tensor: Add__8:0\n",
      "[08/12/2025-18:59:34] [TRT] [V] Add__8 [Add] outputs: [Add__8:0 -> (-1, 64)[FLOAT]], \n",
      "[08/12/2025-18:59:34] [TRT] [V] Parsing node: Relu__5 [Relu]\n",
      "[08/12/2025-18:59:34] [TRT] [V] Searching for input: Add__8:0\n",
      "[08/12/2025-18:59:34] [TRT] [V] Relu__5 [Relu] inputs: [Add__8:0 -> (-1, 64)[FLOAT]], \n",
      "[08/12/2025-18:59:34] [TRT] [V] Registering layer: Relu__5 for ONNX node: Relu__5\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registering tensor: Relu__5:0 for ONNX tensor: Relu__5:0\n",
      "[08/12/2025-18:59:34] [TRT] [V] Relu__5 [Relu] outputs: [Relu__5:0 -> (-1, 64)[FLOAT]], \n",
      "[08/12/2025-18:59:34] [TRT] [V] Parsing node: sequential/dense_1/MatMul;sequential/dense_1/BiasAdd [MatMul]\n",
      "[08/12/2025-18:59:34] [TRT] [V] Searching for input: Relu__5:0\n",
      "[08/12/2025-18:59:34] [TRT] [V] Searching for input: const_fold_opt__14\n",
      "[08/12/2025-18:59:34] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd [MatMul] inputs: [Relu__5:0 -> (-1, 64)[FLOAT]], [const_fold_opt__14 -> (64, 13)[FLOAT]], \n",
      "[08/12/2025-18:59:34] [TRT] [V] Registering layer: const_fold_opt__14 for ONNX node: const_fold_opt__14\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registering layer: sequential/dense_1/MatMul;sequential/dense_1/BiasAdd for ONNX node: sequential/dense_1/MatMul;sequential/dense_1/BiasAdd\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registering tensor: sequential/dense_1/MatMul;sequential/dense_1/BiasAdd for ONNX tensor: sequential/dense_1/MatMul;sequential/dense_1/BiasAdd\n",
      "[08/12/2025-18:59:34] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd [MatMul] outputs: [sequential/dense_1/MatMul;sequential/dense_1/BiasAdd -> (-1, 13)[FLOAT]], \n",
      "[08/12/2025-18:59:34] [TRT] [V] Parsing node: Add__11 [Add]\n",
      "[08/12/2025-18:59:34] [TRT] [V] Searching for input: sequential/dense_1/MatMul;sequential/dense_1/BiasAdd\n",
      "[08/12/2025-18:59:34] [TRT] [V] Searching for input: sequential/dense_1/BiasAdd/ReadVariableOp\n",
      "[08/12/2025-18:59:34] [TRT] [V] Add__11 [Add] inputs: [sequential/dense_1/MatMul;sequential/dense_1/BiasAdd -> (-1, 13)[FLOAT]], [sequential/dense_1/BiasAdd/ReadVariableOp -> (13)[FLOAT]], \n",
      "[08/12/2025-18:59:34] [TRT] [V] Registering layer: sequential/dense_1/BiasAdd/ReadVariableOp for ONNX node: sequential/dense_1/BiasAdd/ReadVariableOp\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registering layer: Add__11 for ONNX node: Add__11\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registering tensor: Add__11:0 for ONNX tensor: Add__11:0\n",
      "[08/12/2025-18:59:34] [TRT] [V] Add__11 [Add] outputs: [Add__11:0 -> (-1, 13)[FLOAT]], \n",
      "[08/12/2025-18:59:34] [TRT] [V] Parsing node: StatefulPartitionedCall:0 [Softmax]\n",
      "[08/12/2025-18:59:34] [TRT] [V] Searching for input: Add__11:0\n",
      "[08/12/2025-18:59:34] [TRT] [V] StatefulPartitionedCall:0 [Softmax] inputs: [Add__11:0 -> (-1, 13)[FLOAT]], \n",
      "[08/12/2025-18:59:34] [TRT] [V] Registering layer: StatefulPartitionedCall:0 for ONNX node: StatefulPartitionedCall:0\n",
      "[08/12/2025-18:59:34] [TRT] [V] Registering tensor: StatefulPartitionedCall:0_0 for ONNX tensor: StatefulPartitionedCall:0\n",
      "[08/12/2025-18:59:34] [TRT] [V] StatefulPartitionedCall:0 [Softmax] outputs: [StatefulPartitionedCall:0 -> (-1, 13)[FLOAT]], \n",
      "[08/12/2025-18:59:34] [TRT] [V] Marking StatefulPartitionedCall:0_0 as output: StatefulPartitionedCall:0\n",
      "Network inputs:\n",
      "  0: name='serving_default_input_1:0', shape=[-1, 94], dtype=DataType.FLOAT\n",
      "Profile for 'serving_default_input_1:0': min=[1, 94], opt=[4, 94], max=[8, 94]\n",
      "[08/12/2025-18:59:34] [TRT] [V] Original: 13 layers\n",
      "[08/12/2025-18:59:34] [TRT] [V] After dead-layer removal: 13 layers\n",
      "[08/12/2025-18:59:34] [TRT] [V] Applying generic optimizations to the graph for inference.\n",
      "[08/12/2025-18:59:34] [TRT] [V] Running: ConstShuffleFusion on sequential/batch_normalization/batchnorm/sub\n",
      "[08/12/2025-18:59:34] [TRT] [V] ConstShuffleFusion: Fusing sequential/batch_normalization/batchnorm/sub with (Unnamed Layer* 3) [Shuffle]\n",
      "[08/12/2025-18:59:34] [TRT] [V] Running: ConstShuffleFusion on sequential/dense_1/BiasAdd/ReadVariableOp\n",
      "[08/12/2025-18:59:34] [TRT] [V] ConstShuffleFusion: Fusing sequential/dense_1/BiasAdd/ReadVariableOp with (Unnamed Layer* 9) [Shuffle]\n",
      "[08/12/2025-18:59:34] [TRT] [V] Running: ShuffleErasure on (Unnamed Layer* 12) [Shuffle]\n",
      "[08/12/2025-18:59:34] [TRT] [V] Removing (Unnamed Layer* 12) [Shuffle]\n",
      "[08/12/2025-18:59:34] [TRT] [V] After Myelin optimization: 10 layers\n",
      "[08/12/2025-18:59:34] [TRT] [V] Running: MatMulToConvTransform on sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Convert layer type of sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[08/12/2025-18:59:34] [TRT] [V] Running: MatMulToConvTransform on sequential/dense_1/MatMul;sequential/dense_1/BiasAdd\n",
      "[08/12/2025-18:59:34] [TRT] [V] Convert layer type of sequential/dense_1/MatMul;sequential/dense_1/BiasAdd from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[08/12/2025-18:59:34] [TRT] [V] Running: ConvReshapeBiasAddFusion on sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1\n",
      "[08/12/2025-18:59:34] [TRT] [V] Running: ConvReshapeBiasAddFusion on sequential/dense_1/MatMul;sequential/dense_1/BiasAdd\n",
      "[08/12/2025-18:59:34] [TRT] [V] Applying ScaleNodes fusions.\n",
      "[08/12/2025-18:59:34] [TRT] [V] After scale fusion: 8 layers\n",
      "[08/12/2025-18:59:34] [TRT] [V] Running: SqueezePushDownFork on reshape_after_sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1\n",
      "[08/12/2025-18:59:34] [TRT] [V] -----------SqueezePushDown kSQUEEZE_FORK case: sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 --> reshape_after_sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 --> Relu__5\n",
      "[08/12/2025-18:59:34] [TRT] [V] Running: ShuffleShuffleFusion on squeeze_after_Relu__5\n",
      "[08/12/2025-18:59:34] [TRT] [V] ShuffleShuffleFusion: Fusing squeeze_after_Relu__5 with reshape_before_sequential/dense_1/MatMul;sequential/dense_1/BiasAdd\n",
      "[08/12/2025-18:59:34] [TRT] [V] Running: ConvReluFusion on sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1\n",
      "[08/12/2025-18:59:34] [TRT] [V] ConvReluFusion: Fusing sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 with Relu__5\n",
      "[08/12/2025-18:59:34] [TRT] [V] Running: ShuffleErasure on squeeze_after_Relu__5 + reshape_before_sequential/dense_1/MatMul;sequential/dense_1/BiasAdd\n",
      "[08/12/2025-18:59:34] [TRT] [V] Removing squeeze_after_Relu__5 + reshape_before_sequential/dense_1/MatMul;sequential/dense_1/BiasAdd\n",
      "[08/12/2025-18:59:34] [TRT] [V] After dupe layer removal: 5 layers\n",
      "[08/12/2025-18:59:34] [TRT] [V] After final dead-layer removal: 5 layers\n",
      "[08/12/2025-18:59:34] [TRT] [V] After tensor merging: 5 layers\n",
      "[08/12/2025-18:59:35] [TRT] [V] After vertical fusions: 5 layers\n",
      "[08/12/2025-18:59:35] [TRT] [V] After dupe layer removal: 5 layers\n",
      "[08/12/2025-18:59:35] [TRT] [V] After final dead-layer removal: 5 layers\n",
      "[08/12/2025-18:59:35] [TRT] [V] After tensor merging: 5 layers\n",
      "[08/12/2025-18:59:35] [TRT] [V] After slice removal: 5 layers\n",
      "[08/12/2025-18:59:35] [TRT] [V] After concat removal: 5 layers\n",
      "[08/12/2025-18:59:35] [TRT] [V] Trying to split Reshape and strided tensor\n",
      "[08/12/2025-18:59:35] [TRT] [V] Graph construction and optimization completed in 0.197535 seconds.\n",
      "[08/12/2025-18:59:35] [TRT] [V] Trying to load shared library libcublas.so.11\n",
      "[08/12/2025-18:59:35] [TRT] [V] Loaded shared library libcublas.so.11\n",
      "[08/12/2025-18:59:35] [TRT] [V] Using cublas as plugin tactic source\n",
      "[08/12/2025-18:59:35] [TRT] [V] Using cublas as core library tactic source\n",
      "[08/12/2025-18:59:35] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +6, GPU +8, now: CPU 981, GPU 601 (MiB)\n",
      "[08/12/2025-18:59:35] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[08/12/2025-18:59:35] [TRT] [V] Constructing optimization profile number 0 [1/1].\n",
      "[08/12/2025-18:59:35] [TRT] [V] Reserving memory for host IO tensors. Host: 0 bytes\n",
      "[08/12/2025-18:59:35] [TRT] [V] =============== Computing reformatting costs: \n",
      "[08/12/2025-18:59:35] [TRT] [V] *************** Autotuning Reformat: Float(94,1,1,1) -> Float(94,1,94,94) ***************\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> reshape_before_sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1_out_tensor) (Reformat)\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00477866\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0112299\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00475463\n",
      "[08/12/2025-18:59:35] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00475463\n",
      "[08/12/2025-18:59:35] [TRT] [V] *************** Autotuning Reformat: Float(94,1,1,1) -> Float(24,1:4,24,24) ***************\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> reshape_before_sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1_out_tensor) (Reformat)\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00483803\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0111616\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00485287\n",
      "[08/12/2025-18:59:35] [TRT] [V] Fastest Tactic: 0x00000000000003e8 Time: 0.00483803\n",
      "[08/12/2025-18:59:35] [TRT] [V] =============== Computing reformatting costs: \n",
      "[08/12/2025-18:59:35] [TRT] [V] *************** Autotuning Reformat: Float(94,1,1,1) -> Float(94,1,94,94) ***************\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00474982\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0112526\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00478842\n",
      "[08/12/2025-18:59:35] [TRT] [V] Fastest Tactic: 0x00000000000003e8 Time: 0.00474982\n",
      "[08/12/2025-18:59:35] [TRT] [V] *************** Autotuning Reformat: Float(94,1,1,1) -> Float(24,1:4,24,24) ***************\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00481767\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.011173\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00484297\n",
      "[08/12/2025-18:59:35] [TRT] [V] Fastest Tactic: 0x00000000000003e8 Time: 0.00481767\n",
      "[08/12/2025-18:59:35] [TRT] [V] *************** Autotuning Reformat: Float(94,1,94,94) -> Float(94,1,1,1) ***************\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00480305\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0112412\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00477379\n",
      "[08/12/2025-18:59:35] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00477379\n",
      "[08/12/2025-18:59:35] [TRT] [V] *************** Autotuning Reformat: Float(94,1,94,94) -> Float(24,1:4,24,24) ***************\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.0048776\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.011264\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00485781\n",
      "[08/12/2025-18:59:35] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00485781\n",
      "[08/12/2025-18:59:35] [TRT] [V] *************** Autotuning Reformat: Float(24,1:4,24,24) -> Float(94,1,1,1) ***************\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00484297\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0112981\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00480792\n",
      "[08/12/2025-18:59:35] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00480792\n",
      "[08/12/2025-18:59:35] [TRT] [V] *************** Autotuning Reformat: Float(24,1:4,24,24) -> Float(94,1,94,94) ***************\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00482255\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0112299\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.0048776\n",
      "[08/12/2025-18:59:35] [TRT] [V] Fastest Tactic: 0x00000000000003e8 Time: 0.00482255\n",
      "[08/12/2025-18:59:35] [TRT] [V] =============== Computing reformatting costs: \n",
      "[08/12/2025-18:59:35] [TRT] [V] *************** Autotuning Reformat: Float(64,1,1,1) -> Float(64,1,64,64) ***************\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(Relu__5_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00480792\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0111099\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00477866\n",
      "[08/12/2025-18:59:35] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00477866\n",
      "[08/12/2025-18:59:35] [TRT] [V] *************** Autotuning Reformat: Float(64,1,1,1) -> Float(16,1:4,16,16) ***************\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(Relu__5_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00483803\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0111502\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.0048875\n",
      "[08/12/2025-18:59:35] [TRT] [V] Fastest Tactic: 0x00000000000003e8 Time: 0.00483803\n",
      "[08/12/2025-18:59:35] [TRT] [V] *************** Autotuning Reformat: Float(64,1,64,64) -> Float(64,1,1,1) ***************\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(Relu__5_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00482255\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0113209\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00477866\n",
      "[08/12/2025-18:59:35] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00477866\n",
      "[08/12/2025-18:59:35] [TRT] [V] *************** Autotuning Reformat: Float(64,1,64,64) -> Float(16,1:4,16,16) ***************\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(Relu__5_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00482743\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0109997\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00485781\n",
      "[08/12/2025-18:59:35] [TRT] [V] Fastest Tactic: 0x00000000000003e8 Time: 0.00482743\n",
      "[08/12/2025-18:59:35] [TRT] [V] *************** Autotuning Reformat: Float(16,1:4,16,16) -> Float(64,1,1,1) ***************\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(Relu__5_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00487266\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0113323\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.0048128\n",
      "[08/12/2025-18:59:35] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.0048128\n",
      "[08/12/2025-18:59:35] [TRT] [V] *************** Autotuning Reformat: Float(16,1:4,16,16) -> Float(64,1,64,64) ***************\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(Relu__5_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00487266\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0110218\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00485287\n",
      "[08/12/2025-18:59:35] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00485287\n",
      "[08/12/2025-18:59:35] [TRT] [V] =============== Computing reformatting costs: \n",
      "[08/12/2025-18:59:35] [TRT] [V] *************** Autotuning Reformat: Float(13,1,13,13) -> Float(13,1,1,1) ***************\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(sequential/dense_1/MatMul;sequential/dense_1/BiasAdd_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00471136\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0113664\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00469333\n",
      "[08/12/2025-18:59:35] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00469333\n",
      "[08/12/2025-18:59:35] [TRT] [V] *************** Autotuning Reformat: Float(4,1:4,4,4) -> Float(13,1,1,1) ***************\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(sequential/dense_1/MatMul;sequential/dense_1/BiasAdd_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00476404\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.011264\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00470655\n",
      "[08/12/2025-18:59:35] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00470655\n",
      "[08/12/2025-18:59:35] [TRT] [V] =============== Computing costs for \n",
      "[08/12/2025-18:59:35] [TRT] [V] *************** Autotuning format combination: Float(94,1) -> Float(94,1,1,1) ***************\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: reshape_before_sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 (Shuffle)\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00420693\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x0000000000000001 Time: 0.0153755\n",
      "[08/12/2025-18:59:35] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00420693\n",
      "[08/12/2025-18:59:35] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000\n",
      "[08/12/2025-18:59:35] [TRT] [V] =============== Computing costs for \n",
      "[08/12/2025-18:59:35] [TRT] [V] *************** Autotuning format combination: Float(94,1,1,1) -> Float(64,1,1,1) ***************\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 (CudaDepthwiseConvolution)\n",
      "[08/12/2025-18:59:35] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 (FusedConvActConvolution)\n",
      "[08/12/2025-18:59:35] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 (CudnnConvolution)\n",
      "[08/12/2025-18:59:35] [TRT] [V] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 (CublasConvolution)\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00869963\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x0000000000000001 Time: 0.00928237\n",
      "[08/12/2025-18:59:35] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00869963\n",
      "[08/12/2025-18:59:35] [TRT] [V] Unrecognized MMA instruction source format or shape: sm70_xmma_gemm_as_conv1x1_f32f32_f32_f32_tn_n_simt_small_batch_bias_relu\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5: 16 available tactics, 16 unparsable, 0 pruned, 16 remaining after tactic pruning.\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 (CaskGemmConvolution)\n",
      "[08/12/2025-18:59:35] [TRT] [V] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_relu_tn_v1 Tactic: 0x000000000002005d numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x000000000002005d Time: 0.00892856\n",
      "[08/12/2025-18:59:35] [TRT] [V] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_nn_v1 Tactic: 0x0000000000020088 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x0000000000020088 Time: 0.0119345\n",
      "[08/12/2025-18:59:35] [TRT] [V] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_tn_v1 Tactic: 0x00000000000200dc numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000200dc Time: 0.0156858\n",
      "[08/12/2025-18:59:35] [TRT] [V] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_nn_v1 Tactic: 0x000000000002014c numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x000000000002014c Time: 0.0111957\n",
      "[08/12/2025-18:59:35] [TRT] [V] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_nn_v1 Tactic: 0x0000000000020191 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x0000000000020191 Time: 0.0145883\n",
      "[08/12/2025-18:59:35] [TRT] [V] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_relu_nn_v1 Tactic: 0x00000000000201f0 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000201f0 Time: 0.00868212\n",
      "[08/12/2025-18:59:35] [TRT] [V] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_relu_nn_v1 Tactic: 0x00000000000201f5 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000201f5 Time: 0.0123002\n",
      "[08/12/2025-18:59:35] [TRT] [V] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_relu_tn_v1 Tactic: 0x000000000002023a numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x000000000002023a Time: 0.0099589\n",
      "[08/12/2025-18:59:35] [TRT] [V] Set Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize128x32x8_stage3_warpsize2x2x1_ffma_aligna4_alignc4 Tactic: 0x00000000000202a0 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000202a0 Time: 0.0120929\n",
      "[08/12/2025-18:59:35] [TRT] [V] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_tn_v1 Tactic: 0x00000000000202ed numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x00000000000202ed Time: 0.0111957\n",
      "[08/12/2025-18:59:35] [TRT] [V] Set Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4 Tactic: 0x0000000000020440 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x0000000000020440 Time: 0.00898246\n",
      "[08/12/2025-18:59:35] [TRT] [V] Set Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize64x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4 Tactic: 0x0000000000020443 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x0000000000020443 Time: 0.0110548\n",
      "[08/12/2025-18:59:35] [TRT] [V] Set Tactic Name: sm70_xmma_gemm_as_conv1x1_f32f32_f32_f32_tn_n_simt_small_batch_bias_relu Tactic: 0x000000000002047e numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x000000000002047e Time: 0.00679253\n",
      "[08/12/2025-18:59:35] [TRT] [V] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_tn_v1 Tactic: 0x0000000000020589 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x0000000000020589 Time: 0.0124903\n",
      "[08/12/2025-18:59:35] [TRT] [V] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_relu_tn_v1 Tactic: 0x0000000000020768 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x0000000000020768 Time: 0.0133803\n",
      "[08/12/2025-18:59:35] [TRT] [V] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_relu_nn_v1 Tactic: 0x000000000002077b numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x000000000002077b Time: 0.0096256\n",
      "[08/12/2025-18:59:35] [TRT] [V] Fastest Tactic: 0x000000000002047e Time: 0.00679253\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 (CaskFlattenConvolution)\n",
      "[08/12/2025-18:59:35] [TRT] [V] CaskFlattenConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 (CaskConvolution)\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x12dbf7d94ee3696d Time: 0.0248686\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x9d9fdb5fd9945f64\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x9d9fdb5fd9945f64 Time: 0.0134076\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x828d0ea88c66fce7\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x828d0ea88c66fce7 Time: 0.0166278\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xc0b05b61d128e46e\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0xc0b05b61d128e46e Time: 0.0233017\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0xbb8c3889c7eacd30 Time: 0.059392\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xb0bf940d5e0f9f45\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0xb0bf940d5e0f9f45 Time: 0.011355\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90f8f2915f87ed77\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x90f8f2915f87ed77 Time: 0.0110988\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0xa31d27de74b895ff Time: 0.0154376\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xe5603263b7f00303\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0xe5603263b7f00303 Time: 0.0248442\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x2ee10e11d6651675\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x2ee10e11d6651675 Time: 0.0393671\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x5aa723e0481da855 Time: 0.0236203\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x40a12e3938221818\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x40a12e3938221818 Time: 0.0217173\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9de226a0c44627c4\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x9de226a0c44627c4 Time: 0.0377363\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa9366041633a5135\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0xa9366041633a5135 Time: 0.0253318\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fc87d7eb370bb7a\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x1fc87d7eb370bb7a Time: 0.0150335\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xfff46c7893896eb1\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0xfff46c7893896eb1 Time: 0.0551985\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9cd5cdc35441c505\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x9cd5cdc35441c505 Time: 0.0226645\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x8e3884f0eaec3ecd\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x8e3884f0eaec3ecd Time: 0.023643\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm70_xmma_fprop_conv1x1_f32f32_f32_f32_nchwkcrs_nchw_simt_small_batch_bias_relu Tactic: 0xaa0953b1a73b0b9b\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0xaa0953b1a73b0b9b Time: 0.00680577\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0xd828f024626fa982 Time: 0.0206205\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xcb8a43f748d8a338\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0xcb8a43f748d8a338 Time: 0.0165953\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x865894c4635db7fd\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x865894c4635db7fd Time: 0.0152824\n",
      "[08/12/2025-18:59:35] [TRT] [V] Fastest Tactic: 0xaa0953b1a73b0b9b Time: 0.00680577\n",
      "[08/12/2025-18:59:35] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskGemmConvolution Tactic: 0x000000000002047e\n",
      "[08/12/2025-18:59:35] [TRT] [V] *************** Autotuning format combination: Float(94,1,94,94) -> Float(64,1,64,64) ***************\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 (CublasConvolution)\n",
      "[08/12/2025-18:59:35] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 (CaskFlattenConvolution)\n",
      "[08/12/2025-18:59:35] [TRT] [V] CaskFlattenConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 (CaskConvolution)\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fb90698107bb33a\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x1fb90698107bb33a Time: 0.00980831\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x7121ec1db3f80c67 Time: 0.0102814\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90898977fc8ce537\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x90898977fc8ce537 Time: 0.0133803\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd9eb6ca56ddc3a22\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0xd9eb6ca56ddc3a22 Time: 0.0137079\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x0a143be7a52f301a Time: 0.01056\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd55ee6fd0b56f808\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0xd55ee6fd0b56f808 Time: 0.0207611\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xbc0bba0ff1a92939\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0xbc0bba0ff1a92939 Time: 0.0350891\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x92ed3100c35fc43e Time: 0.0115936\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x55d80c17b1cd982d\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x55d80c17b1cd982d Time: 0.0139947\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x1da91d865428f237 Time: 0.0220373\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xc7b3afceb5fb03c0\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0xc7b3afceb5fb03c0 Time: 0.0205804\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x62835fce994f06dd Time: 0.0144992\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0xa6448a1e79f1ca6f Time: 0.0149148\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x35f26f9c09557d86\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x35f26f9c09557d86 Time: 0.0212053\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x4fd3c46622e98342 Time: 0.0131413\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x19b688348f983aa0 Time: 0.0139662\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x1022069e6f8d9aeb\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x1022069e6f8d9aeb Time: 0.0210773\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x8014228ec08b4d49 Time: 0.0375467\n",
      "[08/12/2025-18:59:35] [TRT] [V] Fastest Tactic: 0x1fb90698107bb33a Time: 0.00980831\n",
      "[08/12/2025-18:59:35] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x1fb90698107bb33a\n",
      "[08/12/2025-18:59:35] [TRT] [V] *************** Autotuning format combination: Float(24,1:4,24,24) -> Float(16,1:4,16,16) ***************\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 (CudaDepthwiseConvolution)\n",
      "[08/12/2025-18:59:35] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 (CublasConvolution)\n",
      "[08/12/2025-18:59:35] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 (CaskGemmConvolution)\n",
      "[08/12/2025-18:59:35] [TRT] [V] CaskGemmConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 (CaskFlattenConvolution)\n",
      "[08/12/2025-18:59:35] [TRT] [V] CaskFlattenConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 (CaskConvolution)\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fb90698107bb33a\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x1fb90698107bb33a Time: 0.00977188\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x7121ec1db3f80c67 Time: 0.0103021\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90898977fc8ce537\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x90898977fc8ce537 Time: 0.0134076\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd9eb6ca56ddc3a22\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0xd9eb6ca56ddc3a22 Time: 0.0137353\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x0a143be7a52f301a Time: 0.0105813\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd55ee6fd0b56f808\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0xd55ee6fd0b56f808 Time: 0.0207812\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xbc0bba0ff1a92939\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0xbc0bba0ff1a92939 Time: 0.0350208\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x92ed3100c35fc43e Time: 0.0116289\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x55d80c17b1cd982d\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x55d80c17b1cd982d Time: 0.0138951\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x1da91d865428f237 Time: 0.0219947\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xc7b3afceb5fb03c0\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0xc7b3afceb5fb03c0 Time: 0.0206406\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x62835fce994f06dd Time: 0.0143076\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0xa6448a1e79f1ca6f Time: 0.0149593\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x35f26f9c09557d86\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x35f26f9c09557d86 Time: 0.0212907\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x4fd3c46622e98342 Time: 0.0131807\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x19b688348f983aa0 Time: 0.0139378\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x1022069e6f8d9aeb\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x1022069e6f8d9aeb Time: 0.0210773\n",
      "[08/12/2025-18:59:35] [TRT] [V] sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49\n",
      "[08/12/2025-18:59:35] [TRT] [V] Tactic: 0x8014228ec08b4d49 Time: 0.0376225\n",
      "[08/12/2025-18:59:35] [TRT] [V] Fastest Tactic: 0x1fb90698107bb33a Time: 0.00977188\n",
      "[08/12/2025-18:59:35] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x1fb90698107bb33a\n",
      "[08/12/2025-18:59:35] [TRT] [V] =============== Computing costs for \n",
      "[08/12/2025-18:59:35] [TRT] [V] *************** Autotuning format combination: Float(64,1,1,1) -> Float(13,1,1,1) ***************\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: sequential/dense_1/MatMul;sequential/dense_1/BiasAdd (CudaDepthwiseConvolution)\n",
      "[08/12/2025-18:59:35] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: sequential/dense_1/MatMul;sequential/dense_1/BiasAdd (FusedConvActConvolution)\n",
      "[08/12/2025-18:59:35] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: sequential/dense_1/MatMul;sequential/dense_1/BiasAdd (CudnnConvolution)\n",
      "[08/12/2025-18:59:35] [TRT] [V] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-18:59:35] [TRT] [V] --------------- Timing Runner: sequential/dense_1/MatMul;sequential/dense_1/BiasAdd (CublasConvolution)\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.0117937\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x0000000000000001 Time: 0.0116524\n",
      "[08/12/2025-18:59:36] [TRT] [V] Fastest Tactic: 0x0000000000000001 Time: 0.0116524\n",
      "[08/12/2025-18:59:36] [TRT] [V] Unrecognized MMA instruction source format or shape: sm70_xmma_gemm_as_conv1x1_f32f32_f32_f32_tn_n_simt_small_batch_bias_relu\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd: 16 available tactics, 16 unparsable, 0 pruned, 16 remaining after tactic pruning.\n",
      "[08/12/2025-18:59:36] [TRT] [V] --------------- Timing Runner: sequential/dense_1/MatMul;sequential/dense_1/BiasAdd (CaskGemmConvolution)\n",
      "[08/12/2025-18:59:36] [TRT] [V] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_relu_tn_v1 Tactic: 0x000000000002005d numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x000000000002005d Time: 0.00820865\n",
      "[08/12/2025-18:59:36] [TRT] [V] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_nn_v1 Tactic: 0x0000000000020088 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x0000000000020088 Time: 0.010656\n",
      "[08/12/2025-18:59:36] [TRT] [V] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_tn_v1 Tactic: 0x00000000000200dc numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x00000000000200dc Time: 0.0134349\n",
      "[08/12/2025-18:59:36] [TRT] [V] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_nn_v1 Tactic: 0x000000000002014c numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x000000000002014c Time: 0.00997898\n",
      "[08/12/2025-18:59:36] [TRT] [V] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_nn_v1 Tactic: 0x0000000000020191 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x0000000000020191 Time: 0.0126167\n",
      "[08/12/2025-18:59:36] [TRT] [V] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_relu_nn_v1 Tactic: 0x00000000000201f0 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x00000000000201f0 Time: 0.00782685\n",
      "[08/12/2025-18:59:36] [TRT] [V] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_relu_nn_v1 Tactic: 0x00000000000201f5 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x00000000000201f5 Time: 0.010752\n",
      "[08/12/2025-18:59:36] [TRT] [V] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_relu_tn_v1 Tactic: 0x000000000002023a numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x000000000002023a Time: 0.00890162\n",
      "[08/12/2025-18:59:36] [TRT] [V] Set Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize128x32x8_stage3_warpsize2x2x1_ffma_aligna4_alignc4 Tactic: 0x00000000000202a0 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x00000000000202a0 Time: 0.0100593\n",
      "[08/12/2025-18:59:36] [TRT] [V] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_tn_v1 Tactic: 0x00000000000202ed numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x00000000000202ed Time: 0.0100593\n",
      "[08/12/2025-18:59:36] [TRT] [V] Set Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4 Tactic: 0x0000000000020440 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x0000000000020440 Time: 0.00736835\n",
      "[08/12/2025-18:59:36] [TRT] [V] Set Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize64x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4 Tactic: 0x0000000000020443 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x0000000000020443 Time: 0.0092634\n",
      "[08/12/2025-18:59:36] [TRT] [V] Set Tactic Name: sm70_xmma_gemm_as_conv1x1_f32f32_f32_f32_tn_n_simt_small_batch_bias_relu Tactic: 0x000000000002047e numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x000000000002047e Time: 0.00629857\n",
      "[08/12/2025-18:59:36] [TRT] [V] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_tn_v1 Tactic: 0x0000000000020589 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x0000000000020589 Time: 0.0110878\n",
      "[08/12/2025-18:59:36] [TRT] [V] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_relu_tn_v1 Tactic: 0x0000000000020768 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x0000000000020768 Time: 0.0115347\n",
      "[08/12/2025-18:59:36] [TRT] [V] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_relu_nn_v1 Tactic: 0x000000000002077b numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x000000000002077b Time: 0.00864711\n",
      "[08/12/2025-18:59:36] [TRT] [V] Fastest Tactic: 0x000000000002047e Time: 0.00629857\n",
      "[08/12/2025-18:59:36] [TRT] [V] --------------- Timing Runner: sequential/dense_1/MatMul;sequential/dense_1/BiasAdd (CaskFlattenConvolution)\n",
      "[08/12/2025-18:59:36] [TRT] [V] CaskFlattenConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-18:59:36] [TRT] [V] --------------- Timing Runner: sequential/dense_1/MatMul;sequential/dense_1/BiasAdd (CaskConvolution)\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x12dbf7d94ee3696d Time: 0.0212267\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x9d9fdb5fd9945f64\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x9d9fdb5fd9945f64 Time: 0.0116289\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x828d0ea88c66fce7\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x828d0ea88c66fce7 Time: 0.0139804\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xc0b05b61d128e46e\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0xc0b05b61d128e46e Time: 0.0196568\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0xbb8c3889c7eacd30 Time: 0.0467627\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xb0bf940d5e0f9f45\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0xb0bf940d5e0f9f45 Time: 0.00946252\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90f8f2915f87ed77\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x90f8f2915f87ed77 Time: 0.00911452\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0xa31d27de74b895ff Time: 0.0134349\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xe5603263b7f00303\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0xe5603263b7f00303 Time: 0.0210347\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x2ee10e11d6651675\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x2ee10e11d6651675 Time: 0.0326439\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x5aa723e0481da855 Time: 0.0199379\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x40a12e3938221818\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x40a12e3938221818 Time: 0.0176595\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9de226a0c44627c4\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x9de226a0c44627c4 Time: 0.0311544\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa9366041633a5135\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0xa9366041633a5135 Time: 0.0204398\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fc87d7eb370bb7a\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x1fc87d7eb370bb7a Time: 0.0128394\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xfff46c7893896eb1\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0xfff46c7893896eb1 Time: 0.0423253\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9cd5cdc35441c505\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x9cd5cdc35441c505 Time: 0.0189819\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x8e3884f0eaec3ecd\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x8e3884f0eaec3ecd Time: 0.0199178\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm70_xmma_fprop_conv1x1_f32f32_f32_f32_nchwkcrs_nchw_simt_small_batch_bias_relu Tactic: 0xaa0953b1a73b0b9b\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0xaa0953b1a73b0b9b Time: 0.00635009\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0xd828f024626fa982 Time: 0.0168789\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xcb8a43f748d8a338\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0xcb8a43f748d8a338 Time: 0.0131282\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x865894c4635db7fd\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x865894c4635db7fd Time: 0.0132464\n",
      "[08/12/2025-18:59:36] [TRT] [V] Fastest Tactic: 0xaa0953b1a73b0b9b Time: 0.00635009\n",
      "[08/12/2025-18:59:36] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskGemmConvolution Tactic: 0x000000000002047e\n",
      "[08/12/2025-18:59:36] [TRT] [V] *************** Autotuning format combination: Float(64,1,64,64) -> Float(13,1,13,13) ***************\n",
      "[08/12/2025-18:59:36] [TRT] [V] --------------- Timing Runner: sequential/dense_1/MatMul;sequential/dense_1/BiasAdd (CublasConvolution)\n",
      "[08/12/2025-18:59:36] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-18:59:36] [TRT] [V] --------------- Timing Runner: sequential/dense_1/MatMul;sequential/dense_1/BiasAdd (CaskFlattenConvolution)\n",
      "[08/12/2025-18:59:36] [TRT] [V] CaskFlattenConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-18:59:36] [TRT] [V] --------------- Timing Runner: sequential/dense_1/MatMul;sequential/dense_1/BiasAdd (CaskConvolution)\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fb90698107bb33a\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x1fb90698107bb33a Time: 0.0082253\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x7121ec1db3f80c67 Time: 0.0092529\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90898977fc8ce537\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x90898977fc8ce537 Time: 0.0116406\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd9eb6ca56ddc3a22\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0xd9eb6ca56ddc3a22 Time: 0.0118407\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x0a143be7a52f301a Time: 0.00919755\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd55ee6fd0b56f808\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0xd55ee6fd0b56f808 Time: 0.0175517\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xbc0bba0ff1a92939\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0xbc0bba0ff1a92939 Time: 0.0286436\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x92ed3100c35fc43e Time: 0.0100994\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x55d80c17b1cd982d\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x55d80c17b1cd982d Time: 0.0122149\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x1da91d865428f237 Time: 0.0185837\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xc7b3afceb5fb03c0\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0xc7b3afceb5fb03c0 Time: 0.017408\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x62835fce994f06dd Time: 0.012604\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0xa6448a1e79f1ca6f Time: 0.0126293\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x35f26f9c09557d86\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x35f26f9c09557d86 Time: 0.0181086\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x4fd3c46622e98342 Time: 0.0110108\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x19b688348f983aa0 Time: 0.0120564\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x1022069e6f8d9aeb\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x1022069e6f8d9aeb Time: 0.0178571\n",
      "[08/12/2025-18:59:36] [TRT] [V] sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x8014228ec08b4d49 Time: 0.0314027\n",
      "[08/12/2025-18:59:36] [TRT] [V] Fastest Tactic: 0x1fb90698107bb33a Time: 0.0082253\n",
      "[08/12/2025-18:59:36] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x1fb90698107bb33a\n",
      "[08/12/2025-18:59:36] [TRT] [V] *************** Autotuning format combination: Float(16,1:4,16,16) -> Float(4,1:4,4,4) ***************\n",
      "[08/12/2025-18:59:36] [TRT] [V] --------------- Timing Runner: sequential/dense_1/MatMul;sequential/dense_1/BiasAdd (CudaDepthwiseConvolution)\n",
      "[08/12/2025-18:59:36] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-18:59:36] [TRT] [V] --------------- Timing Runner: sequential/dense_1/MatMul;sequential/dense_1/BiasAdd (CublasConvolution)\n",
      "[08/12/2025-18:59:36] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-18:59:36] [TRT] [V] --------------- Timing Runner: sequential/dense_1/MatMul;sequential/dense_1/BiasAdd (CaskGemmConvolution)\n",
      "[08/12/2025-18:59:36] [TRT] [V] CaskGemmConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-18:59:36] [TRT] [V] --------------- Timing Runner: sequential/dense_1/MatMul;sequential/dense_1/BiasAdd (CaskFlattenConvolution)\n",
      "[08/12/2025-18:59:36] [TRT] [V] CaskFlattenConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-18:59:36] [TRT] [V] --------------- Timing Runner: sequential/dense_1/MatMul;sequential/dense_1/BiasAdd (CaskConvolution)\n",
      "[08/12/2025-18:59:36] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-18:59:36] [TRT] [V] =============== Computing costs for \n",
      "[08/12/2025-18:59:36] [TRT] [V] *************** Autotuning format combination: Float(13,1,1,1) -> Float(13,1) ***************\n",
      "[08/12/2025-18:59:36] [TRT] [V] --------------- Timing Runner: reshape_after_sequential/dense_1/MatMul;sequential/dense_1/BiasAdd (Shuffle)\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00418987\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x0000000000000001 Time: 0.0152824\n",
      "[08/12/2025-18:59:36] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00418987\n",
      "[08/12/2025-18:59:36] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000\n",
      "[08/12/2025-18:59:36] [TRT] [V] =============== Computing costs for \n",
      "[08/12/2025-18:59:36] [TRT] [V] *************** Autotuning format combination: Float(13,1) -> Float(13,1) ***************\n",
      "[08/12/2025-18:59:36] [TRT] [V] --------------- Timing Runner: StatefulPartitionedCall:0 (CudaSoftMax)\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.00554527\n",
      "[08/12/2025-18:59:36] [TRT] [V] Tactic: 0x00000000000003e9 Time: 0.00449194\n",
      "[08/12/2025-18:59:36] [TRT] [V] Fastest Tactic: 0x00000000000003e9 Time: 0.00449194\n",
      "[08/12/2025-18:59:36] [TRT] [V] --------------- Timing Runner: StatefulPartitionedCall:0 (CaskSoftMax)\n",
      "[08/12/2025-18:59:36] [TRT] [V] CaskSoftMax has no valid tactics for this config, skipping\n",
      "[08/12/2025-18:59:36] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CudaSoftMax Tactic: 0x00000000000003e9\n",
      "[08/12/2025-18:59:36] [TRT] [V] Formats and tactics selection completed in 1.57385 seconds.\n",
      "[08/12/2025-18:59:36] [TRT] [V] After reformat layers: 5 layers\n",
      "[08/12/2025-18:59:36] [TRT] [V] Total number of blocks in pre-optimized block assignment: 5\n",
      "[08/12/2025-18:59:36] [TRT] [I] Total Activation Memory: 1073745408\n",
      "[08/12/2025-18:59:36] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[08/12/2025-18:59:37] [TRT] [V] Set Tactic Name: sm70_xmma_gemm_as_conv1x1_f32f32_f32_f32_tn_n_simt_small_batch_bias_relu Tactic: 0x000000000002047e numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:37] [TRT] [V] Set Tactic Name: sm70_xmma_gemm_as_conv1x1_f32f32_f32_f32_tn_n_simt_small_batch_bias_relu Tactic: 0x000000000002047e numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-18:59:37] [TRT] [V] Layer: sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Host Persistent: 6752 Device Persistent: 0 Scratch Memory: 0\n",
      "[08/12/2025-18:59:37] [TRT] [V] Layer: sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Host Persistent: 6752 Device Persistent: 0 Scratch Memory: 0\n",
      "[08/12/2025-18:59:37] [TRT] [V] Skipped printing memory information for 3 layers with 0 memory size i.e. Host Persistent + Device Persistent + Scratch Memory == 0.\n",
      "[08/12/2025-18:59:37] [TRT] [I] Total Host Persistent Memory: 13504\n",
      "[08/12/2025-18:59:37] [TRT] [I] Total Device Persistent Memory: 0\n",
      "[08/12/2025-18:59:37] [TRT] [I] Total Scratch Memory: 0\n",
      "[08/12/2025-18:59:37] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 4 MiB\n",
      "[08/12/2025-18:59:37] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 4 steps to complete.\n",
      "[08/12/2025-18:59:37] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.011402ms to assign 2 blocks to 4 nodes requiring 2560 bytes.\n",
      "[08/12/2025-18:59:37] [TRT] [V] Total number of blocks in optimized block assignment: 2\n",
      "[08/12/2025-18:59:37] [TRT] [I] Total Activation Memory: 2560\n",
      "[08/12/2025-18:59:37] [TRT] [V] Finalize: sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5 Set kernel index: 0\n",
      "[08/12/2025-18:59:37] [TRT] [V] Finalize: sequential/dense_1/MatMul;sequential/dense_1/BiasAdd Set kernel index: 0\n",
      "[08/12/2025-18:59:37] [TRT] [V] Total number of generated kernels selected for the engine: 1\n",
      "[08/12/2025-18:59:37] [TRT] [V] Kernel: 0 CASK_STATIC\n",
      "[08/12/2025-18:59:37] [TRT] [V] Disabling unused tactic source: CUBLAS, CUBLAS_LT\n",
      "[08/12/2025-18:59:37] [TRT] [V] Engine generation completed in 2.01772 seconds.\n",
      "[08/12/2025-18:59:37] [TRT] [V] Deleting timing cache: 24 entries, served 0 hits since creation.\n",
      "[08/12/2025-18:59:37] [TRT] [V] Engine Layer Information:\n",
      "Layer(NoOp): reshape_before_sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1, Tactic: 0x0000000000000000, serving_default_input_1:0 (Float[-1,94]) -> reshape_before_sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1_out_tensor (Float[-1,94,1,1])\n",
      "Layer(CaskGemmConvolution): sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1 + Relu__5, Tactic: 0x000000000002047e, reshape_before_sequential/dense/MatMul;sequential/batch_normalization/batchnorm/mul_1;sequential/re_lu/Relu;sequential/batch_normalization/batchnorm/add_1_out_tensor (Float[-1,94,1,1]) -> Relu__5_out_tensor (Float[-1,64,1,1])\n",
      "Layer(CaskGemmConvolution): sequential/dense_1/MatMul;sequential/dense_1/BiasAdd, Tactic: 0x000000000002047e, Relu__5_out_tensor (Float[-1,64,1,1]) -> sequential/dense_1/MatMul;sequential/dense_1/BiasAdd_out_tensor (Float[-1,13,1,1])\n",
      "Layer(NoOp): reshape_after_sequential/dense_1/MatMul;sequential/dense_1/BiasAdd, Tactic: 0x0000000000000000, sequential/dense_1/MatMul;sequential/dense_1/BiasAdd_out_tensor (Float[-1,13,1,1]) -> Add__11:0 (Float[-1,13])\n",
      "Layer(CudaSoftMax): StatefulPartitionedCall:0, Tactic: 0x00000000000003e9, Add__11:0 (Float[-1,13]) -> StatefulPartitionedCall:0 (Float[-1,13])\n",
      "[08/12/2025-18:59:37] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +4, now: CPU 0, GPU 4 (MiB)\n",
      "✅ Saved engine: ./DL Models/best_FCNN_model.trt\n",
      "[08/12/2025-18:59:37] [TRT] [I] The logger passed into createInferRuntime differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.\n",
      "\n",
      "[08/12/2025-18:59:37] [TRT] [I] Loaded engine size: 0 MiB\n",
      "[08/12/2025-18:59:37] [TRT] [V] Deserialization required 8049 microseconds.\n",
      "Engine load OK: True\n",
      "[08/12/2025-18:59:37] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)\n"
     ]
    }
   ],
   "source": [
    "import os, onnx, tensorrt as trt\n",
    "\n",
    "onnx_path   = \"./DL Models/best_FCNN_model.onnx\"   # your float (non-quantized) ONNX\n",
    "engine_path = \"./DL Models/best_FCNN_model.trt\"    # will save here\n",
    "\n",
    "# ---- 0) Validate ONNX ----\n",
    "m = onnx.load(onnx_path)\n",
    "onnx.checker.check_model(m)\n",
    "print(\"ONNX checker: OK\")\n",
    "\n",
    "# ---- 1) Builder / Network (explicit batch) / Config / Parser ----\n",
    "logger = trt.Logger(trt.Logger.VERBOSE)\n",
    "EXPL = 1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "\n",
    "builder = trt.Builder(logger)\n",
    "network = builder.create_network(EXPL)\n",
    "config  = builder.create_builder_config()\n",
    "\n",
    "# workspace (adjust if needed)\n",
    "config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30)  # 1 GiB\n",
    "\n",
    "# Keep FP32 only\n",
    "if hasattr(trt.BuilderFlag, \"FP16\"):\n",
    "    config.clear_flag(trt.BuilderFlag.FP16)\n",
    "# Some builds support TF32 flag; clear it if present\n",
    "if hasattr(trt.BuilderFlag, \"TF32\"):\n",
    "    config.clear_flag(trt.BuilderFlag.TF32)\n",
    "\n",
    "# Force safer kernel choices (optional but helps)\n",
    "if hasattr(trt.BuilderFlag, \"STRICT_TYPES\"):\n",
    "    config.set_flag(trt.BuilderFlag.STRICT_TYPES)\n",
    "\n",
    "# Restrict tactics to GEMM (avoid cuDNN conv/depthwise)\n",
    "try:\n",
    "    mask = 0\n",
    "    if hasattr(trt.TacticSource, \"CUBLAS\"):\n",
    "        mask |= int(trt.TacticSource.CUBLAS)\n",
    "    if hasattr(trt.TacticSource, \"CUBLAS_LT\"):\n",
    "        mask |= int(trt.TacticSource.CUBLAS_LT)\n",
    "    if mask and hasattr(config, \"set_tactic_sources\"):\n",
    "        config.set_tactic_sources(mask)\n",
    "        print(\"Tactic sources limited to cuBLAS/cuBLASLt.\")\n",
    "except Exception as e:\n",
    "    print(\"Skipping tactic source restriction:\", e)\n",
    "\n",
    "parser = trt.OnnxParser(network, logger)\n",
    "with open(onnx_path, \"rb\") as f:\n",
    "    blob = f.read()\n",
    "if not parser.parse(blob):\n",
    "    print(\"❌ ONNX parse failed:\")\n",
    "    for i in range(parser.num_errors):\n",
    "        print(parser.get_error(i))\n",
    "    raise SystemExit(1)\n",
    "\n",
    "# ---- 2) Print inputs exactly as TRT sees them ----\n",
    "print(\"Network inputs:\")\n",
    "for i in range(network.num_inputs):\n",
    "    inp = network.get_input(i)\n",
    "    print(f\"  {i}: name='{inp.name}', shape={list(inp.shape)}, dtype={inp.dtype}\")\n",
    "\n",
    "# ---- 3) Optimization profile: keep shapes small & safe ----\n",
    "profile_needed = False\n",
    "profile = builder.create_optimization_profile()\n",
    "for i in range(network.num_inputs):\n",
    "    inp = network.get_input(i)\n",
    "    shape = list(inp.shape)\n",
    "    if any(d == -1 for d in shape):\n",
    "        profile_needed = True\n",
    "        # Your input is [-1, 94], so vary only batch dim\n",
    "        min_shape = [1, 94]\n",
    "        opt_shape = [4, 94]\n",
    "        max_shape = [8, 94]\n",
    "        profile.set_shape(inp.name, min_shape, opt_shape, max_shape)\n",
    "        print(f\"Profile for '{inp.name}': min={min_shape}, opt={opt_shape}, max={max_shape}\")\n",
    "\n",
    "if profile_needed:\n",
    "    config.add_optimization_profile(profile)\n",
    "\n",
    "# ---- 4) Build & save ----\n",
    "serialized = builder.build_serialized_network(network, config)\n",
    "if serialized is None:\n",
    "    raise RuntimeError(\"Failed to build TensorRT engine.\")\n",
    "os.makedirs(os.path.dirname(engine_path) or \".\", exist_ok=True)\n",
    "with open(engine_path, \"wb\") as f:\n",
    "    f.write(serialized)\n",
    "print(f\"✅ Saved engine: {engine_path}\")\n",
    "\n",
    "# ---- 5) Quick load sanity check ----\n",
    "runtime = trt.Runtime(logger)\n",
    "with open(engine_path, \"rb\") as f:\n",
    "    engine = runtime.deserialize_cuda_engine(f.read())\n",
    "print(\"Engine load OK:\", engine is not None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd78b0e3-f8bb-4f6d-be9f-9a177ef11639",
   "metadata": {},
   "source": [
    "--------\n",
    "## AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f44f97e2-4936-4a38-a44b-3d6adb1a6d93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX checker: OK\n",
      "Tactic sources limited to cuBLAS/cuBLASLt.\n",
      "[08/12/2025-19:08:19] [TRT] [I] The logger passed into createInferBuilder differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.\n",
      "\n",
      "[08/12/2025-19:08:19] [TRT] [I] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 1113, GPU 599 (MiB)\n",
      "[08/12/2025-19:08:19] [TRT] [V] CUDA lazy loading is enabled.\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::BatchedNMSDynamic_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::BatchedNMS_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::BatchTilePlugin_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::Clip_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::CoordConvAC version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::CropAndResizeDynamic version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::CropAndResize version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::DecodeBbox3DPlugin version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::DetectionLayer_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::EfficientNMS_Explicit_TF_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::EfficientNMS_Implicit_TF_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::EfficientNMS_ONNX_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::EfficientNMS_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::FlattenConcat_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::fMHA_V2 version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::fMHCA version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::GenerateDetection_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::GridAnchor_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::GridAnchorRect_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::GroupNorm version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::InstanceNormalization_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::InstanceNormalization_TRT version 2\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::LayerNorm version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::LReLU_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::MultilevelCropAndResize_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::MultilevelProposeROI_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::MultiscaleDeformableAttnPlugin_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::NMSDynamic_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::NMS_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::Normalize_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::PillarScatterPlugin version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::PriorBox_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::ProposalDynamic version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::ProposalLayer_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::Proposal version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::PyramidROIAlign_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::Region_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::Reorg_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::ResizeNearest_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::ROIAlign_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::RPROI_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::ScatterND version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::SeqLen2Spatial version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::SpecialSlice_TRT version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::SplitGeLU version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::Split version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Plugin creator already registered - ::VoxelGeneratorPlugin version 1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Adding network input: serving_default_encoder_input:0 with dtype: float32, dimensions: (-1, 94)\n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering tensor: serving_default_encoder_input:0 for ONNX tensor: serving_default_encoder_input:0\n",
      "[08/12/2025-19:08:19] [TRT] [V] Importing initializer: const_fold_opt__34\n",
      "[08/12/2025-19:08:19] [TRT] [V] Importing initializer: const_fold_opt__33\n",
      "[08/12/2025-19:08:19] [TRT] [V] Importing initializer: const_fold_opt__32\n",
      "[08/12/2025-19:08:19] [TRT] [V] Importing initializer: const_fold_opt__31\n",
      "[08/12/2025-19:08:19] [TRT] [V] Importing initializer: const_fold_opt__30\n",
      "[08/12/2025-19:08:19] [TRT] [V] Importing initializer: AutoEncoderClassifier/reconstruction_out/BiasAdd/ReadVariableOp\n",
      "[08/12/2025-19:08:19] [TRT] [V] Importing initializer: AutoEncoderClassifier/latent_batchnorm/batchnorm/sub\n",
      "[08/12/2025-19:08:19] [TRT] [V] Importing initializer: AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/sub\n",
      "[08/12/2025-19:08:19] [TRT] [V] Importing initializer: AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/sub\n",
      "[08/12/2025-19:08:19] [TRT] [V] Importing initializer: AutoEncoderClassifier/classification_out/BiasAdd/ReadVariableOp\n",
      "[08/12/2025-19:08:19] [TRT] [V] Parsing node: AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 [MatMul]\n",
      "[08/12/2025-19:08:19] [TRT] [V] Searching for input: serving_default_encoder_input:0\n",
      "[08/12/2025-19:08:19] [TRT] [V] Searching for input: const_fold_opt__32\n",
      "[08/12/2025-19:08:19] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 [MatMul] inputs: [serving_default_encoder_input:0 -> (-1, 94)[FLOAT]], [const_fold_opt__32 -> (94, 55)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering layer: const_fold_opt__32 for ONNX node: const_fold_opt__32\n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering layer: AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 for ONNX node: AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering tensor: AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 for ONNX tensor: AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1\n",
      "[08/12/2025-19:08:19] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 [MatMul] outputs: [AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 -> (-1, 55)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Parsing node: Add__10 [Add]\n",
      "[08/12/2025-19:08:19] [TRT] [V] Searching for input: AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Searching for input: AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/sub\n",
      "[08/12/2025-19:08:19] [TRT] [V] Add__10 [Add] inputs: [AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 -> (-1, 55)[FLOAT]], [AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/sub -> (55)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering layer: AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/sub for ONNX node: AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/sub\n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering layer: Add__10 for ONNX node: Add__10\n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering tensor: Add__10:0 for ONNX tensor: Add__10:0\n",
      "[08/12/2025-19:08:19] [TRT] [V] Add__10 [Add] outputs: [Add__10:0 -> (-1, 55)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Parsing node: Relu__7 [Relu]\n",
      "[08/12/2025-19:08:19] [TRT] [V] Searching for input: Add__10:0\n",
      "[08/12/2025-19:08:19] [TRT] [V] Relu__7 [Relu] inputs: [Add__10:0 -> (-1, 55)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering layer: Relu__7 for ONNX node: Relu__7\n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering tensor: Relu__7:0 for ONNX tensor: Relu__7:0\n",
      "[08/12/2025-19:08:19] [TRT] [V] Relu__7 [Relu] outputs: [Relu__7:0 -> (-1, 55)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Parsing node: AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 [MatMul]\n",
      "[08/12/2025-19:08:19] [TRT] [V] Searching for input: Relu__7:0\n",
      "[08/12/2025-19:08:19] [TRT] [V] Searching for input: const_fold_opt__34\n",
      "[08/12/2025-19:08:19] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 [MatMul] inputs: [Relu__7:0 -> (-1, 55)[FLOAT]], [const_fold_opt__34 -> (55, 36)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering layer: const_fold_opt__34 for ONNX node: const_fold_opt__34\n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering layer: AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 for ONNX node: AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering tensor: AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 for ONNX tensor: AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1\n",
      "[08/12/2025-19:08:19] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 [MatMul] outputs: [AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 -> (-1, 36)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Parsing node: Add__15 [Add]\n",
      "[08/12/2025-19:08:19] [TRT] [V] Searching for input: AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Searching for input: AutoEncoderClassifier/latent_batchnorm/batchnorm/sub\n",
      "[08/12/2025-19:08:19] [TRT] [V] Add__15 [Add] inputs: [AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 -> (-1, 36)[FLOAT]], [AutoEncoderClassifier/latent_batchnorm/batchnorm/sub -> (36)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering layer: AutoEncoderClassifier/latent_batchnorm/batchnorm/sub for ONNX node: AutoEncoderClassifier/latent_batchnorm/batchnorm/sub\n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering layer: Add__15 for ONNX node: Add__15\n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering tensor: Add__15:0 for ONNX tensor: Add__15:0\n",
      "[08/12/2025-19:08:19] [TRT] [V] Add__15 [Add] outputs: [Add__15:0 -> (-1, 36)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Parsing node: Relu__12 [Relu]\n",
      "[08/12/2025-19:08:19] [TRT] [V] Searching for input: Add__15:0\n",
      "[08/12/2025-19:08:19] [TRT] [V] Relu__12 [Relu] inputs: [Add__15:0 -> (-1, 36)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering layer: Relu__12 for ONNX node: Relu__12\n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering tensor: Relu__12:0 for ONNX tensor: Relu__12:0\n",
      "[08/12/2025-19:08:19] [TRT] [V] Relu__12 [Relu] outputs: [Relu__12:0 -> (-1, 36)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Parsing node: AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 [MatMul]\n",
      "[08/12/2025-19:08:19] [TRT] [V] Searching for input: Relu__12:0\n",
      "[08/12/2025-19:08:19] [TRT] [V] Searching for input: const_fold_opt__31\n",
      "[08/12/2025-19:08:19] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 [MatMul] inputs: [Relu__12:0 -> (-1, 36)[FLOAT]], [const_fold_opt__31 -> (36, 55)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering layer: const_fold_opt__31 for ONNX node: const_fold_opt__31\n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering layer: AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 for ONNX node: AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering tensor: AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 for ONNX tensor: AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1\n",
      "[08/12/2025-19:08:19] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 [MatMul] outputs: [AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 -> (-1, 55)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Parsing node: Add__23 [Add]\n",
      "[08/12/2025-19:08:19] [TRT] [V] Searching for input: AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Searching for input: AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/sub\n",
      "[08/12/2025-19:08:19] [TRT] [V] Add__23 [Add] inputs: [AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 -> (-1, 55)[FLOAT]], [AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/sub -> (55)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering layer: AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/sub for ONNX node: AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/sub\n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering layer: Add__23 for ONNX node: Add__23\n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering tensor: Add__23:0 for ONNX tensor: Add__23:0\n",
      "[08/12/2025-19:08:19] [TRT] [V] Add__23 [Add] outputs: [Add__23:0 -> (-1, 55)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Parsing node: Relu__20 [Relu]\n",
      "[08/12/2025-19:08:19] [TRT] [V] Searching for input: Add__23:0\n",
      "[08/12/2025-19:08:19] [TRT] [V] Relu__20 [Relu] inputs: [Add__23:0 -> (-1, 55)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering layer: Relu__20 for ONNX node: Relu__20\n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering tensor: Relu__20:0 for ONNX tensor: Relu__20:0\n",
      "[08/12/2025-19:08:19] [TRT] [V] Relu__20 [Relu] outputs: [Relu__20:0 -> (-1, 55)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Parsing node: StatefulPartitionedCall:1 [MatMul]\n",
      "[08/12/2025-19:08:19] [TRT] [V] Searching for input: Relu__20:0\n",
      "[08/12/2025-19:08:19] [TRT] [V] Searching for input: const_fold_opt__30\n",
      "[08/12/2025-19:08:19] [TRT] [V] StatefulPartitionedCall:1 [MatMul] inputs: [Relu__20:0 -> (-1, 55)[FLOAT]], [const_fold_opt__30 -> (55, 94)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering layer: const_fold_opt__30 for ONNX node: const_fold_opt__30\n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering layer: StatefulPartitionedCall:1 for ONNX node: StatefulPartitionedCall:1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering tensor: StatefulPartitionedCall:1_raw_output___5:0 for ONNX tensor: StatefulPartitionedCall:1_raw_output___5:0\n",
      "[08/12/2025-19:08:19] [TRT] [V] StatefulPartitionedCall:1 [MatMul] outputs: [StatefulPartitionedCall:1_raw_output___5:0 -> (-1, 94)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Parsing node: Add__28 [Add]\n",
      "[08/12/2025-19:08:19] [TRT] [V] Searching for input: StatefulPartitionedCall:1_raw_output___5:0\n",
      "[08/12/2025-19:08:19] [TRT] [V] Searching for input: AutoEncoderClassifier/reconstruction_out/BiasAdd/ReadVariableOp\n",
      "[08/12/2025-19:08:19] [TRT] [V] Add__28 [Add] inputs: [StatefulPartitionedCall:1_raw_output___5:0 -> (-1, 94)[FLOAT]], [AutoEncoderClassifier/reconstruction_out/BiasAdd/ReadVariableOp -> (94)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering layer: AutoEncoderClassifier/reconstruction_out/BiasAdd/ReadVariableOp for ONNX node: AutoEncoderClassifier/reconstruction_out/BiasAdd/ReadVariableOp\n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering layer: Add__28 for ONNX node: Add__28\n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering tensor: Add__28:0 for ONNX tensor: Add__28:0\n",
      "[08/12/2025-19:08:19] [TRT] [V] Add__28 [Add] outputs: [Add__28:0 -> (-1, 94)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Parsing node: Relu__25 [Relu]\n",
      "[08/12/2025-19:08:19] [TRT] [V] Searching for input: Add__28:0\n",
      "[08/12/2025-19:08:19] [TRT] [V] Relu__25 [Relu] inputs: [Add__28:0 -> (-1, 94)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering layer: Relu__25 for ONNX node: Relu__25\n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering tensor: StatefulPartitionedCall:1_0 for ONNX tensor: StatefulPartitionedCall:1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Relu__25 [Relu] outputs: [StatefulPartitionedCall:1 -> (-1, 94)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Parsing node: AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd [MatMul]\n",
      "[08/12/2025-19:08:19] [TRT] [V] Searching for input: Relu__12:0\n",
      "[08/12/2025-19:08:19] [TRT] [V] Searching for input: const_fold_opt__33\n",
      "[08/12/2025-19:08:19] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd [MatMul] inputs: [Relu__12:0 -> (-1, 36)[FLOAT]], [const_fold_opt__33 -> (36, 13)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering layer: const_fold_opt__33 for ONNX node: const_fold_opt__33\n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering layer: AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd for ONNX node: AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd\n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering tensor: AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd for ONNX tensor: AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd\n",
      "[08/12/2025-19:08:19] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd [MatMul] outputs: [AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd -> (-1, 13)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Parsing node: Add__18 [Add]\n",
      "[08/12/2025-19:08:19] [TRT] [V] Searching for input: AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd\n",
      "[08/12/2025-19:08:19] [TRT] [V] Searching for input: AutoEncoderClassifier/classification_out/BiasAdd/ReadVariableOp\n",
      "[08/12/2025-19:08:19] [TRT] [V] Add__18 [Add] inputs: [AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd -> (-1, 13)[FLOAT]], [AutoEncoderClassifier/classification_out/BiasAdd/ReadVariableOp -> (13)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering layer: AutoEncoderClassifier/classification_out/BiasAdd/ReadVariableOp for ONNX node: AutoEncoderClassifier/classification_out/BiasAdd/ReadVariableOp\n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering layer: Add__18 for ONNX node: Add__18\n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering tensor: Add__18:0 for ONNX tensor: Add__18:0\n",
      "[08/12/2025-19:08:19] [TRT] [V] Add__18 [Add] outputs: [Add__18:0 -> (-1, 13)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Parsing node: StatefulPartitionedCall:0 [Softmax]\n",
      "[08/12/2025-19:08:19] [TRT] [V] Searching for input: Add__18:0\n",
      "[08/12/2025-19:08:19] [TRT] [V] StatefulPartitionedCall:0 [Softmax] inputs: [Add__18:0 -> (-1, 13)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering layer: StatefulPartitionedCall:0 for ONNX node: StatefulPartitionedCall:0\n",
      "[08/12/2025-19:08:19] [TRT] [V] Registering tensor: StatefulPartitionedCall:0_1 for ONNX tensor: StatefulPartitionedCall:0\n",
      "[08/12/2025-19:08:19] [TRT] [V] StatefulPartitionedCall:0 [Softmax] outputs: [StatefulPartitionedCall:0 -> (-1, 13)[FLOAT]], \n",
      "[08/12/2025-19:08:19] [TRT] [V] Marking StatefulPartitionedCall:0_1 as output: StatefulPartitionedCall:0\n",
      "Network inputs:\n",
      "  0: name='serving_default_encoder_input:0', shape=[-1, 94], dtype=DataType.FLOAT\n",
      "Profile for 'serving_default_encoder_input:0': min=[1, 94], opt=[4, 94], max=[8, 94]\n",
      "[08/12/2025-19:08:19] [TRT] [V] Marking StatefulPartitionedCall:1_0 as output: StatefulPartitionedCall:1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Original: 31 layers\n",
      "[08/12/2025-19:08:19] [TRT] [V] After dead-layer removal: 31 layers\n",
      "[08/12/2025-19:08:19] [TRT] [V] Applying generic optimizations to the graph for inference.\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: ConstShuffleFusion on AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/sub\n",
      "[08/12/2025-19:08:19] [TRT] [V] ConstShuffleFusion: Fusing AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/sub with (Unnamed Layer* 3) [Shuffle]\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: ConstShuffleFusion on AutoEncoderClassifier/latent_batchnorm/batchnorm/sub\n",
      "[08/12/2025-19:08:19] [TRT] [V] ConstShuffleFusion: Fusing AutoEncoderClassifier/latent_batchnorm/batchnorm/sub with (Unnamed Layer* 9) [Shuffle]\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: ConstShuffleFusion on AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/sub\n",
      "[08/12/2025-19:08:19] [TRT] [V] ConstShuffleFusion: Fusing AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/sub with (Unnamed Layer* 15) [Shuffle]\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: ConstShuffleFusion on AutoEncoderClassifier/reconstruction_out/BiasAdd/ReadVariableOp\n",
      "[08/12/2025-19:08:19] [TRT] [V] ConstShuffleFusion: Fusing AutoEncoderClassifier/reconstruction_out/BiasAdd/ReadVariableOp with (Unnamed Layer* 21) [Shuffle]\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: ConstShuffleFusion on AutoEncoderClassifier/classification_out/BiasAdd/ReadVariableOp\n",
      "[08/12/2025-19:08:19] [TRT] [V] ConstShuffleFusion: Fusing AutoEncoderClassifier/classification_out/BiasAdd/ReadVariableOp with (Unnamed Layer* 27) [Shuffle]\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: ShuffleErasure on (Unnamed Layer* 30) [Shuffle]\n",
      "[08/12/2025-19:08:19] [TRT] [V] Removing (Unnamed Layer* 30) [Shuffle]\n",
      "[08/12/2025-19:08:19] [TRT] [V] After Myelin optimization: 25 layers\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: MatMulToConvTransform on AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Convert layer type of AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: MatMulToConvTransform on AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Convert layer type of AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: MatMulToConvTransform on AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Convert layer type of AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: MatMulToConvTransform on AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd\n",
      "[08/12/2025-19:08:19] [TRT] [V] Convert layer type of AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: MatMulToConvTransform on StatefulPartitionedCall:1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Convert layer type of StatefulPartitionedCall:1 from MATRIX_MULTIPLY to CONVOLUTION\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: ConvReshapeBiasAddFusion on AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: ConvReshapeBiasAddFusion on AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: ConvReshapeBiasAddFusion on AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: ConvReshapeBiasAddFusion on AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: ConvReshapeBiasAddFusion on StatefulPartitionedCall:1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Applying ScaleNodes fusions.\n",
      "[08/12/2025-19:08:19] [TRT] [V] After scale fusion: 20 layers\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: SqueezePushDownFork on reshape_after_AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1\n",
      "[08/12/2025-19:08:19] [TRT] [V] -----------SqueezePushDown kSQUEEZE_FORK case: AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 --> reshape_after_AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 --> Relu__7\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: SqueezePushDownFork on reshape_after_AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1\n",
      "[08/12/2025-19:08:19] [TRT] [V] -----------SqueezePushDown kSQUEEZE_FORK case: AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 --> reshape_after_AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 --> Relu__12\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: SqueezePushDownFork on reshape_after_AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1\n",
      "[08/12/2025-19:08:19] [TRT] [V] -----------SqueezePushDown kSQUEEZE_FORK case: AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 --> reshape_after_AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 --> Relu__20\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: ShuffleShuffleFusion on squeeze_after_Relu__7\n",
      "[08/12/2025-19:08:19] [TRT] [V] ShuffleShuffleFusion: Fusing squeeze_after_Relu__7 with reshape_before_AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: ShuffleShuffleFusion on squeeze_after_Relu__20\n",
      "[08/12/2025-19:08:19] [TRT] [V] ShuffleShuffleFusion: Fusing squeeze_after_Relu__20 with reshape_before_StatefulPartitionedCall:1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: ConvReluFusion on AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1\n",
      "[08/12/2025-19:08:19] [TRT] [V] ConvReluFusion: Fusing AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 with Relu__7\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: ShuffleErasure on squeeze_after_Relu__7 + reshape_before_AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Removing squeeze_after_Relu__7 + reshape_before_AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: ConvReluFusion on AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1\n",
      "[08/12/2025-19:08:19] [TRT] [V] ConvReluFusion: Fusing AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 with Relu__12\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: ConvReluFusion on AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1\n",
      "[08/12/2025-19:08:19] [TRT] [V] ConvReluFusion: Fusing AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 with Relu__20\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: ShuffleErasure on squeeze_after_Relu__20 + reshape_before_StatefulPartitionedCall:1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Removing squeeze_after_Relu__20 + reshape_before_StatefulPartitionedCall:1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: ActivationToPointwiseConversion on Relu__25\n",
      "[08/12/2025-19:08:19] [TRT] [V] Swap the layer type of Relu__25 from ACTIVATION to POINTWISE\n",
      "[08/12/2025-19:08:19] [TRT] [V] Replacing input 0 of AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd with reshape_before_AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1_out_tensor (output of reshape_before_AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1)\n",
      "[08/12/2025-19:08:19] [TRT] [V] After dupe layer removal: 13 layers\n",
      "[08/12/2025-19:08:19] [TRT] [V] After final dead-layer removal: 12 layers\n",
      "[08/12/2025-19:08:19] [TRT] [V] After tensor merging: 12 layers\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: ShuffleShuffleFusion on squeeze_after_Relu__12\n",
      "[08/12/2025-19:08:19] [TRT] [V] ShuffleShuffleFusion: Fusing squeeze_after_Relu__12 with reshape_before_AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Running: ShuffleErasure on squeeze_after_Relu__12 + reshape_before_AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1\n",
      "[08/12/2025-19:08:19] [TRT] [V] Removing squeeze_after_Relu__12 + reshape_before_AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1\n",
      "[08/12/2025-19:08:19] [TRT] [V] After vertical fusions: 10 layers\n",
      "[08/12/2025-19:08:19] [TRT] [V] After dupe layer removal: 10 layers\n",
      "[08/12/2025-19:08:19] [TRT] [V] After final dead-layer removal: 10 layers\n",
      "[08/12/2025-19:08:19] [TRT] [V] After tensor merging: 10 layers\n",
      "[08/12/2025-19:08:19] [TRT] [V] After slice removal: 10 layers\n",
      "[08/12/2025-19:08:19] [TRT] [V] After concat removal: 10 layers\n",
      "[08/12/2025-19:08:19] [TRT] [V] Trying to split Reshape and strided tensor\n",
      "[08/12/2025-19:08:19] [TRT] [V] Graph construction and optimization completed in 0.489633 seconds.\n",
      "[08/12/2025-19:08:19] [TRT] [V] Trying to load shared library libcublas.so.11\n",
      "[08/12/2025-19:08:19] [TRT] [V] Loaded shared library libcublas.so.11\n",
      "[08/12/2025-19:08:20] [TRT] [V] Using cublas as plugin tactic source\n",
      "[08/12/2025-19:08:20] [TRT] [V] Using cublas as core library tactic source\n",
      "[08/12/2025-19:08:20] [TRT] [I] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 1113, GPU 607 (MiB)\n",
      "[08/12/2025-19:08:20] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[08/12/2025-19:08:20] [TRT] [V] Constructing optimization profile number 0 [1/1].\n",
      "[08/12/2025-19:08:20] [TRT] [V] Reserving memory for host IO tensors. Host: 0 bytes\n",
      "[08/12/2025-19:08:20] [TRT] [V] =============== Computing reformatting costs: \n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(94,1,1,1) -> Float(94,1,94,94) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> reshape_before_AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1_out_tensor) (Reformat)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00481767\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0112868\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.0047402\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.0047402\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(94,1,1,1) -> Float(24,1:4,24,24) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> reshape_before_AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1_out_tensor) (Reformat)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00479817\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0111502\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00476404\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00476404\n",
      "[08/12/2025-19:08:20] [TRT] [V] =============== Computing reformatting costs: \n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(94,1,1,1) -> Float(94,1,94,94) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00477866\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.011264\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00471136\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00471136\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(94,1,1,1) -> Float(24,1:4,24,24) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00478354\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0110878\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00478354\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x00000000000003e8 Time: 0.00478354\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(94,1,94,94) -> Float(94,1,1,1) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00479329\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.011264\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00475943\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00475943\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(94,1,94,94) -> Float(24,1:4,24,24) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00479329\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0111502\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00472578\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00472578\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(24,1:4,24,24) -> Float(94,1,1,1) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00482743\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0112299\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00479817\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00479817\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(24,1:4,24,24) -> Float(94,1,94,94) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(reshape_before_AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00483803\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0121905\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00480305\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00480305\n",
      "[08/12/2025-19:08:20] [TRT] [V] =============== Computing reformatting costs: \n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(55,1,1,1) -> Float(55,1,55,55) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(Relu__7_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.0047354\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0109997\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00473059\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00473059\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(55,1,1,1) -> Float(14,1:4,14,14) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(Relu__7_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00483803\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0110768\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.0048128\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.0048128\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(55,1,55,55) -> Float(55,1,1,1) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(Relu__7_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00474982\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.011264\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00477379\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x00000000000003e8 Time: 0.00474982\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(55,1,55,55) -> Float(14,1:4,14,14) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(Relu__7_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00479817\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0109887\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00480305\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x00000000000003e8 Time: 0.00479817\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(14,1:4,14,14) -> Float(55,1,1,1) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(Relu__7_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00480792\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0112868\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00480305\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00480305\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(14,1:4,14,14) -> Float(55,1,55,55) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(Relu__7_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00481767\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0110218\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00482255\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x00000000000003e8 Time: 0.00481767\n",
      "[08/12/2025-19:08:20] [TRT] [V] =============== Computing reformatting costs: \n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(36,1,1,1) -> Float(36,1,36,36) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> Relu__12_out_tensor) (Reformat)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00474982\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0110438\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00477866\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x00000000000003e8 Time: 0.00474982\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(36,1,1,1) -> Float(9,1:4,9,9) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> Relu__12_out_tensor) (Reformat)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.0048323\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0110438\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00481767\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00481767\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(36,1,36,36) -> Float(36,1,1,1) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> Relu__12_out_tensor) (Reformat)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00476404\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0112185\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00476404\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x00000000000003e8 Time: 0.00476404\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(36,1,36,36) -> Float(9,1:4,9,9) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> Relu__12_out_tensor) (Reformat)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00480792\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0110438\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00480792\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x00000000000003e8 Time: 0.00480792\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(9,1:4,9,9) -> Float(36,1,1,1) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> Relu__12_out_tensor) (Reformat)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00479817\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0112754\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00480305\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x00000000000003e8 Time: 0.00479817\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(9,1:4,9,9) -> Float(36,1,36,36) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(<in> -> Relu__12_out_tensor) (Reformat)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.0048128\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0110768\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00478354\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00478354\n",
      "[08/12/2025-19:08:20] [TRT] [V] =============== Computing reformatting costs: \n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(36,1,1,1) -> Float(36,1,36,36) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(Relu__12_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00477379\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0110548\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00479329\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x00000000000003e8 Time: 0.00477379\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(36,1,1,1) -> Float(9,1:4,9,9) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(Relu__12_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00480305\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0110218\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00480305\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x00000000000003e8 Time: 0.00480305\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(36,1,36,36) -> Float(36,1,1,1) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(Relu__12_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00478354\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0112754\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.0047354\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.0047354\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(36,1,36,36) -> Float(9,1:4,9,9) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(Relu__12_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.0048128\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0110878\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00479817\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00479817\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(9,1:4,9,9) -> Float(36,1,1,1) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(Relu__12_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00480305\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0112412\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00478842\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00478842\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(9,1:4,9,9) -> Float(36,1,36,36) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(Relu__12_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00480792\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0110658\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00480792\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x00000000000003e8 Time: 0.00480792\n",
      "[08/12/2025-19:08:20] [TRT] [V] =============== Computing reformatting costs: \n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(36,1,1,1) -> Float(36,1,36,36) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(36,1,1,1) -> Float(9,1:4,9,9) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(36,1,36,36) -> Float(36,1,1,1) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(36,1,36,36) -> Float(9,1:4,9,9) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(9,1:4,9,9) -> Float(36,1,1,1) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(9,1:4,9,9) -> Float(36,1,36,36) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] =============== Computing reformatting costs: \n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(13,1,13,13) -> Float(13,1,1,1) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.00467437\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0112754\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00468385\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x00000000000003e8 Time: 0.00467437\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(4,1:4,4,4) -> Float(13,1,1,1) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: Optimizer Reformat(AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd_out_tensor -> <out>) (Reformat)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003e8 Time: 0.0047354\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.0112981\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00472578\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00472578\n",
      "[08/12/2025-19:08:20] [TRT] [V] =============== Computing reformatting costs: \n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(55,1,1,1) -> Float(55,1,55,55) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(55,1,1,1) -> Float(14,1:4,14,14) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(55,1,55,55) -> Float(55,1,1,1) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(55,1,55,55) -> Float(14,1:4,14,14) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(14,1:4,14,14) -> Float(55,1,1,1) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(14,1:4,14,14) -> Float(55,1,55,55) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] =============== Computing reformatting costs: \n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(94,1,94,94) -> Float(94,1,1,1) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning Reformat: Float(24,1:4,24,24) -> Float(94,1,1,1) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] =============== Computing costs for \n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning format combination: Float(94,1) -> Float(94,1,1,1) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: reshape_before_AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 (Shuffle)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00414656\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000001 Time: 0.0151225\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00414656\n",
      "[08/12/2025-19:08:20] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000\n",
      "[08/12/2025-19:08:20] [TRT] [V] =============== Computing costs for \n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning format combination: Float(94,1,1,1) -> Float(55,1,1,1) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 (CudaDepthwiseConvolution)\n",
      "[08/12/2025-19:08:20] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 (FusedConvActConvolution)\n",
      "[08/12/2025-19:08:20] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 (CudnnConvolution)\n",
      "[08/12/2025-19:08:20] [TRT] [V] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 (CublasConvolution)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00865586\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000001 Time: 0.00919755\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00865586\n",
      "[08/12/2025-19:08:20] [TRT] [V] Unrecognized MMA instruction source format or shape: sm70_xmma_gemm_as_conv1x1_f32f32_f32_f32_tn_n_simt_small_batch_bias_relu\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7: 16 available tactics, 16 unparsable, 0 pruned, 16 remaining after tactic pruning.\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 (CaskGemmConvolution)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_relu_tn_v1 Tactic: 0x000000000002005d numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x000000000002005d Time: 0.00896449\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_nn_v1 Tactic: 0x0000000000020088 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000020088 Time: 0.0118643\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_tn_v1 Tactic: 0x00000000000200dc numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000200dc Time: 0.0157479\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_nn_v1 Tactic: 0x000000000002014c numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x000000000002014c Time: 0.0111161\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_nn_v1 Tactic: 0x0000000000020191 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000020191 Time: 0.0144992\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_relu_nn_v1 Tactic: 0x00000000000201f0 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000201f0 Time: 0.00868212\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_relu_nn_v1 Tactic: 0x00000000000201f5 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000201f5 Time: 0.0123124\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_relu_tn_v1 Tactic: 0x000000000002023a numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x000000000002023a Time: 0.00996894\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize128x32x8_stage3_warpsize2x2x1_ffma_aligna4_alignc4 Tactic: 0x00000000000202a0 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000202a0 Time: 0.0121173\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_tn_v1 Tactic: 0x00000000000202ed numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000202ed Time: 0.0111388\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4 Tactic: 0x0000000000020440 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000020440 Time: 0.00893755\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize64x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4 Tactic: 0x0000000000020443 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000020443 Time: 0.0109997\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: sm70_xmma_gemm_as_conv1x1_f32f32_f32_f32_tn_n_simt_small_batch_bias_relu Tactic: 0x000000000002047e numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x000000000002047e Time: 0.0066125\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_tn_v1 Tactic: 0x0000000000020589 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000020589 Time: 0.0124271\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_relu_tn_v1 Tactic: 0x0000000000020768 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000020768 Time: 0.0133251\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_relu_nn_v1 Tactic: 0x000000000002077b numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x000000000002077b Time: 0.00961585\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x000000000002047e Time: 0.0066125\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 (CaskFlattenConvolution)\n",
      "[08/12/2025-19:08:20] [TRT] [V] CaskFlattenConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 (CaskConvolution)\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x12dbf7d94ee3696d Time: 0.0249905\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x9d9fdb5fd9945f64\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x9d9fdb5fd9945f64 Time: 0.0132857\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x828d0ea88c66fce7\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x828d0ea88c66fce7 Time: 0.016449\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xc0b05b61d128e46e\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xc0b05b61d128e46e Time: 0.0233244\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xbb8c3889c7eacd30 Time: 0.059392\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xb0bf940d5e0f9f45\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xb0bf940d5e0f9f45 Time: 0.0113436\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90f8f2915f87ed77\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x90f8f2915f87ed77 Time: 0.0109447\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xa31d27de74b895ff Time: 0.0154841\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xe5603263b7f00303\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xe5603263b7f00303 Time: 0.0247467\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x2ee10e11d6651675\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x2ee10e11d6651675 Time: 0.0391775\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x5aa723e0481da855 Time: 0.0234155\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x40a12e3938221818\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x40a12e3938221818 Time: 0.0217173\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9de226a0c44627c4\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x9de226a0c44627c4 Time: 0.0376225\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa9366041633a5135\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xa9366041633a5135 Time: 0.0253318\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fc87d7eb370bb7a\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x1fc87d7eb370bb7a Time: 0.0150187\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xfff46c7893896eb1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xfff46c7893896eb1 Time: 0.055101\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9cd5cdc35441c505\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x9cd5cdc35441c505 Time: 0.022528\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x8e3884f0eaec3ecd\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x8e3884f0eaec3ecd Time: 0.0235748\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm70_xmma_fprop_conv1x1_f32f32_f32_f32_nchwkcrs_nchw_simt_small_batch_bias_relu Tactic: 0xaa0953b1a73b0b9b\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xaa0953b1a73b0b9b Time: 0.00666965\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xd828f024626fa982 Time: 0.0206808\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xcb8a43f748d8a338\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xcb8a43f748d8a338 Time: 0.016514\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x865894c4635db7fd\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x865894c4635db7fd Time: 0.0152824\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0xaa0953b1a73b0b9b Time: 0.00666965\n",
      "[08/12/2025-19:08:20] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskGemmConvolution Tactic: 0x000000000002047e\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning format combination: Float(94,1,94,94) -> Float(55,1,55,55) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 (CublasConvolution)\n",
      "[08/12/2025-19:08:20] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 (CaskFlattenConvolution)\n",
      "[08/12/2025-19:08:20] [TRT] [V] CaskFlattenConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 (CaskConvolution)\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fb90698107bb33a\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x1fb90698107bb33a Time: 0.00982839\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x7121ec1db3f80c67 Time: 0.0103021\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90898977fc8ce537\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x90898977fc8ce537 Time: 0.0134349\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd9eb6ca56ddc3a22\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xd9eb6ca56ddc3a22 Time: 0.0138172\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0a143be7a52f301a Time: 0.0105813\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd55ee6fd0b56f808\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xd55ee6fd0b56f808 Time: 0.020741\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xbc0bba0ff1a92939\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xbc0bba0ff1a92939 Time: 0.0349867\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x92ed3100c35fc43e Time: 0.0116406\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x55d80c17b1cd982d\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x55d80c17b1cd982d Time: 0.0140089\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x1da91d865428f237 Time: 0.0219733\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xc7b3afceb5fb03c0\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xc7b3afceb5fb03c0 Time: 0.0207009\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x62835fce994f06dd Time: 0.0144071\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xa6448a1e79f1ca6f Time: 0.0149593\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x35f26f9c09557d86\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x35f26f9c09557d86 Time: 0.021312\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x4fd3c46622e98342 Time: 0.0132464\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x19b688348f983aa0 Time: 0.013952\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x1022069e6f8d9aeb\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x1022069e6f8d9aeb Time: 0.021056\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x8014228ec08b4d49 Time: 0.0375846\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x1fb90698107bb33a Time: 0.00982839\n",
      "[08/12/2025-19:08:20] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x1fb90698107bb33a\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning format combination: Float(24,1:4,24,24) -> Float(14,1:4,14,14) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 (CudaDepthwiseConvolution)\n",
      "[08/12/2025-19:08:20] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 (CublasConvolution)\n",
      "[08/12/2025-19:08:20] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 (CaskGemmConvolution)\n",
      "[08/12/2025-19:08:20] [TRT] [V] CaskGemmConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 (CaskFlattenConvolution)\n",
      "[08/12/2025-19:08:20] [TRT] [V] CaskFlattenConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 (CaskConvolution)\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fb90698107bb33a\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x1fb90698107bb33a Time: 0.00980114\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x7121ec1db3f80c67 Time: 0.0103021\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90898977fc8ce537\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x90898977fc8ce537 Time: 0.0133666\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd9eb6ca56ddc3a22\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xd9eb6ca56ddc3a22 Time: 0.0137216\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0a143be7a52f301a Time: 0.0105387\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd55ee6fd0b56f808\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xd55ee6fd0b56f808 Time: 0.0207611\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xbc0bba0ff1a92939\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xbc0bba0ff1a92939 Time: 0.0349525\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x92ed3100c35fc43e Time: 0.0116171\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x55d80c17b1cd982d\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x55d80c17b1cd982d Time: 0.0139947\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x1da91d865428f237 Time: 0.0221013\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xc7b3afceb5fb03c0\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xc7b3afceb5fb03c0 Time: 0.0207009\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x62835fce994f06dd Time: 0.0143644\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xa6448a1e79f1ca6f Time: 0.0149741\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x35f26f9c09557d86\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x35f26f9c09557d86 Time: 0.0212907\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x4fd3c46622e98342 Time: 0.0132464\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x19b688348f983aa0 Time: 0.0139236\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x1022069e6f8d9aeb\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x1022069e6f8d9aeb Time: 0.021056\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x8014228ec08b4d49 Time: 0.0376604\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x1fb90698107bb33a Time: 0.00980114\n",
      "[08/12/2025-19:08:20] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x1fb90698107bb33a\n",
      "[08/12/2025-19:08:20] [TRT] [V] =============== Computing costs for \n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning format combination: Float(55,1,1,1) -> Float(36,1,1,1) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 (CudaDepthwiseConvolution)\n",
      "[08/12/2025-19:08:20] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 (FusedConvActConvolution)\n",
      "[08/12/2025-19:08:20] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 (CudnnConvolution)\n",
      "[08/12/2025-19:08:20] [TRT] [V] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 (CublasConvolution)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.0119467\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000000001 Time: 0.0118643\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x0000000000000001 Time: 0.0118643\n",
      "[08/12/2025-19:08:20] [TRT] [V] Unrecognized MMA instruction source format or shape: sm70_xmma_gemm_as_conv1x1_f32f32_f32_f32_tn_n_simt_small_batch_bias_relu\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12: 16 available tactics, 16 unparsable, 0 pruned, 16 remaining after tactic pruning.\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 (CaskGemmConvolution)\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_relu_tn_v1 Tactic: 0x000000000002005d numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x000000000002005d Time: 0.00820033\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_nn_v1 Tactic: 0x0000000000020088 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000020088 Time: 0.0110658\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_tn_v1 Tactic: 0x00000000000200dc numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000200dc Time: 0.0139804\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_nn_v1 Tactic: 0x000000000002014c numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x000000000002014c Time: 0.01056\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_nn_v1 Tactic: 0x0000000000020191 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000020191 Time: 0.013207\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_relu_nn_v1 Tactic: 0x00000000000201f0 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000201f0 Time: 0.00813373\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_relu_nn_v1 Tactic: 0x00000000000201f5 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000201f5 Time: 0.0108016\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_relu_tn_v1 Tactic: 0x000000000002023a numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x000000000002023a Time: 0.00920677\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize128x32x8_stage3_warpsize2x2x1_ffma_aligna4_alignc4 Tactic: 0x00000000000202a0 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000202a0 Time: 0.00943407\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_tn_v1 Tactic: 0x00000000000202ed numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x00000000000202ed Time: 0.0105813\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4 Tactic: 0x0000000000020440 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000020440 Time: 0.00771879\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize64x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4 Tactic: 0x0000000000020443 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000020443 Time: 0.00911452\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: sm70_xmma_gemm_as_conv1x1_f32f32_f32_f32_tn_n_simt_small_batch_bias_relu Tactic: 0x000000000002047e numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x000000000002047e Time: 0.00651159\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_tn_v1 Tactic: 0x0000000000020589 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000020589 Time: 0.0115347\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_relu_tn_v1 Tactic: 0x0000000000020768 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0000000000020768 Time: 0.0116289\n",
      "[08/12/2025-19:08:20] [TRT] [V] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_relu_nn_v1 Tactic: 0x000000000002077b numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x000000000002077b Time: 0.00888365\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0x000000000002047e Time: 0.00651159\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 (CaskFlattenConvolution)\n",
      "[08/12/2025-19:08:20] [TRT] [V] CaskFlattenConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 (CaskConvolution)\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x12dbf7d94ee3696d Time: 0.0203796\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x9d9fdb5fd9945f64\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x9d9fdb5fd9945f64 Time: 0.0111161\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x828d0ea88c66fce7\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x828d0ea88c66fce7 Time: 0.0134076\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xc0b05b61d128e46e\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xc0b05b61d128e46e Time: 0.0188113\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xbb8c3889c7eacd30 Time: 0.043392\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xb0bf940d5e0f9f45\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xb0bf940d5e0f9f45 Time: 0.00972312\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90f8f2915f87ed77\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x90f8f2915f87ed77 Time: 0.009472\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xa31d27de74b895ff Time: 0.0128394\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xe5603263b7f00303\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xe5603263b7f00303 Time: 0.0201989\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x2ee10e11d6651675\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x2ee10e11d6651675 Time: 0.0305959\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x5aa723e0481da855 Time: 0.0191147\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x40a12e3938221818\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x40a12e3938221818 Time: 0.0167253\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9de226a0c44627c4\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x9de226a0c44627c4 Time: 0.0293831\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa9366041633a5135\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xa9366041633a5135 Time: 0.0193612\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fc87d7eb370bb7a\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x1fc87d7eb370bb7a Time: 0.0123891\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xfff46c7893896eb1\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xfff46c7893896eb1 Time: 0.0392533\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9cd5cdc35441c505\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x9cd5cdc35441c505 Time: 0.0181446\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x8e3884f0eaec3ecd\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x8e3884f0eaec3ecd Time: 0.0189819\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm70_xmma_fprop_conv1x1_f32f32_f32_f32_nchwkcrs_nchw_simt_small_batch_bias_relu Tactic: 0xaa0953b1a73b0b9b\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xaa0953b1a73b0b9b Time: 0.00653785\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xd828f024626fa982 Time: 0.0160102\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xcb8a43f748d8a338\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xcb8a43f748d8a338 Time: 0.0129313\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x865894c4635db7fd\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x865894c4635db7fd Time: 0.0127052\n",
      "[08/12/2025-19:08:20] [TRT] [V] Fastest Tactic: 0xaa0953b1a73b0b9b Time: 0.00653785\n",
      "[08/12/2025-19:08:20] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskGemmConvolution Tactic: 0x000000000002047e\n",
      "[08/12/2025-19:08:20] [TRT] [V] *************** Autotuning format combination: Float(55,1,55,55) -> Float(36,1,36,36) ***************\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 (CublasConvolution)\n",
      "[08/12/2025-19:08:20] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 (CaskFlattenConvolution)\n",
      "[08/12/2025-19:08:20] [TRT] [V] CaskFlattenConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:20] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 (CaskConvolution)\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fb90698107bb33a\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x1fb90698107bb33a Time: 0.00876089\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x7121ec1db3f80c67 Time: 0.00908685\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90898977fc8ce537\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x90898977fc8ce537 Time: 0.0110988\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd9eb6ca56ddc3a22\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xd9eb6ca56ddc3a22 Time: 0.0111275\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x0a143be7a52f301a Time: 0.00894653\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd55ee6fd0b56f808\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xd55ee6fd0b56f808 Time: 0.0168107\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xbc0bba0ff1a92939\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xbc0bba0ff1a92939 Time: 0.0270441\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x92ed3100c35fc43e Time: 0.00966461\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x55d80c17b1cd982d\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x55d80c17b1cd982d Time: 0.0116524\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x1da91d865428f237 Time: 0.0178392\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xc7b3afceb5fb03c0\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xc7b3afceb5fb03c0 Time: 0.0166441\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x62835fce994f06dd Time: 0.0121417\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0xa6448a1e79f1ca6f Time: 0.0120076\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x35f26f9c09557d86\n",
      "[08/12/2025-19:08:20] [TRT] [V] Tactic: 0x35f26f9c09557d86 Time: 0.0173227\n",
      "[08/12/2025-19:08:20] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x4fd3c46622e98342 Time: 0.0103538\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x19b688348f983aa0 Time: 0.0115583\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x1022069e6f8d9aeb\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x1022069e6f8d9aeb Time: 0.017152\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x8014228ec08b4d49 Time: 0.0298098\n",
      "[08/12/2025-19:08:21] [TRT] [V] Fastest Tactic: 0x1fb90698107bb33a Time: 0.00876089\n",
      "[08/12/2025-19:08:21] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x1fb90698107bb33a\n",
      "[08/12/2025-19:08:21] [TRT] [V] *************** Autotuning format combination: Float(14,1:4,14,14) -> Float(9,1:4,9,9) ***************\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 (CudaDepthwiseConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 (CublasConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 (CaskGemmConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CaskGemmConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 (CaskFlattenConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CaskFlattenConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 (CaskConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fb90698107bb33a\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x1fb90698107bb33a Time: 0.00873464\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x7121ec1db3f80c67 Time: 0.00901305\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90898977fc8ce537\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x90898977fc8ce537 Time: 0.0111099\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd9eb6ca56ddc3a22\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xd9eb6ca56ddc3a22 Time: 0.0109887\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0a143be7a52f301a Time: 0.00896449\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd55ee6fd0b56f808\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xd55ee6fd0b56f808 Time: 0.0168789\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xbc0bba0ff1a92939\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xbc0bba0ff1a92939 Time: 0.0269916\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x92ed3100c35fc43e Time: 0.00967436\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x55d80c17b1cd982d\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x55d80c17b1cd982d Time: 0.0116406\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x1da91d865428f237 Time: 0.0178392\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xc7b3afceb5fb03c0\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xc7b3afceb5fb03c0 Time: 0.0167083\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x62835fce994f06dd Time: 0.0121051\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xa6448a1e79f1ca6f Time: 0.0118643\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x35f26f9c09557d86\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x35f26f9c09557d86 Time: 0.0173227\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x4fd3c46622e98342 Time: 0.0102193\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x19b688348f983aa0 Time: 0.0116171\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x1022069e6f8d9aeb\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x1022069e6f8d9aeb Time: 0.0170837\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x8014228ec08b4d49 Time: 0.0297813\n",
      "[08/12/2025-19:08:21] [TRT] [V] Fastest Tactic: 0x1fb90698107bb33a Time: 0.00873464\n",
      "[08/12/2025-19:08:21] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x1fb90698107bb33a\n",
      "[08/12/2025-19:08:21] [TRT] [V] =============== Computing costs for \n",
      "[08/12/2025-19:08:21] [TRT] [V] *************** Autotuning format combination: Float(36,1,1,1) -> Float(55,1,1,1) ***************\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 (CudaDepthwiseConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 (FusedConvActConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 (CudnnConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 (CublasConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00841387\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000000001 Time: 0.00853333\n",
      "[08/12/2025-19:08:21] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00841387\n",
      "[08/12/2025-19:08:21] [TRT] [V] Unrecognized MMA instruction source format or shape: sm70_xmma_gemm_as_conv1x1_f32f32_f32_f32_tn_n_simt_small_batch_bias_relu\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20: 16 available tactics, 16 unparsable, 0 pruned, 16 remaining after tactic pruning.\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 (CaskGemmConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_relu_tn_v1 Tactic: 0x000000000002005d numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x000000000002005d Time: 0.00821698\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_nn_v1 Tactic: 0x0000000000020088 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000020088 Time: 0.0110988\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_tn_v1 Tactic: 0x00000000000200dc numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x00000000000200dc Time: 0.0139947\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_nn_v1 Tactic: 0x000000000002014c numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x000000000002014c Time: 0.0106453\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_nn_v1 Tactic: 0x0000000000020191 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000020191 Time: 0.0132595\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_relu_nn_v1 Tactic: 0x00000000000201f0 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x00000000000201f0 Time: 0.00813373\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_relu_nn_v1 Tactic: 0x00000000000201f5 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x00000000000201f5 Time: 0.0108236\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_relu_tn_v1 Tactic: 0x000000000002023a numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x000000000002023a Time: 0.0091791\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize128x32x8_stage3_warpsize2x2x1_ffma_aligna4_alignc4 Tactic: 0x00000000000202a0 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x00000000000202a0 Time: 0.00855959\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_tn_v1 Tactic: 0x00000000000202ed numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x00000000000202ed Time: 0.01056\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4 Tactic: 0x0000000000020440 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000020440 Time: 0.00739803\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize64x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4 Tactic: 0x0000000000020443 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000020443 Time: 0.00836267\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: sm70_xmma_gemm_as_conv1x1_f32f32_f32_f32_tn_n_simt_small_batch_bias_relu Tactic: 0x000000000002047e numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x000000000002047e Time: 0.00635653\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_tn_v1 Tactic: 0x0000000000020589 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000020589 Time: 0.0114005\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_relu_tn_v1 Tactic: 0x0000000000020768 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000020768 Time: 0.0115936\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_relu_nn_v1 Tactic: 0x000000000002077b numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x000000000002077b Time: 0.00887467\n",
      "[08/12/2025-19:08:21] [TRT] [V] Fastest Tactic: 0x000000000002047e Time: 0.00635653\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 (CaskFlattenConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CaskFlattenConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 (CaskConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x12dbf7d94ee3696d Time: 0.0185039\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x9d9fdb5fd9945f64\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x9d9fdb5fd9945f64 Time: 0.010271\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x828d0ea88c66fce7\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x828d0ea88c66fce7 Time: 0.0123639\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xc0b05b61d128e46e\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xc0b05b61d128e46e Time: 0.0172885\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xbb8c3889c7eacd30 Time: 0.037395\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xb0bf940d5e0f9f45\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xb0bf940d5e0f9f45 Time: 0.00918832\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90f8f2915f87ed77\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x90f8f2915f87ed77 Time: 0.00881179\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xa31d27de74b895ff Time: 0.0119223\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xe5603263b7f00303\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xe5603263b7f00303 Time: 0.0183601\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x2ee10e11d6651675\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x2ee10e11d6651675 Time: 0.0275167\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x5aa723e0481da855 Time: 0.0173909\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x40a12e3938221818\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x40a12e3938221818 Time: 0.014707\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9de226a0c44627c4\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x9de226a0c44627c4 Time: 0.0259938\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa9366041633a5135\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xa9366041633a5135 Time: 0.0167595\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fc87d7eb370bb7a\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x1fc87d7eb370bb7a Time: 0.0113323\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xfff46c7893896eb1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xfff46c7893896eb1 Time: 0.0331404\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9cd5cdc35441c505\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x9cd5cdc35441c505 Time: 0.0165465\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x8e3884f0eaec3ecd\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x8e3884f0eaec3ecd Time: 0.0170667\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm70_xmma_fprop_conv1x1_f32f32_f32_f32_nchwkcrs_nchw_simt_small_batch_bias_relu Tactic: 0xaa0953b1a73b0b9b\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xaa0953b1a73b0b9b Time: 0.0062641\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xd828f024626fa982 Time: 0.0138308\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xcb8a43f748d8a338\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xcb8a43f748d8a338 Time: 0.0114005\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x865894c4635db7fd\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x865894c4635db7fd Time: 0.011829\n",
      "[08/12/2025-19:08:21] [TRT] [V] Fastest Tactic: 0xaa0953b1a73b0b9b Time: 0.0062641\n",
      "[08/12/2025-19:08:21] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xaa0953b1a73b0b9b\n",
      "[08/12/2025-19:08:21] [TRT] [V] *************** Autotuning format combination: Float(36,1,36,36) -> Float(55,1,55,55) ***************\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 (CublasConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 (CaskFlattenConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CaskFlattenConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 (CaskConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fb90698107bb33a\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x1fb90698107bb33a Time: 0.0082586\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x7121ec1db3f80c67 Time: 0.00851627\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90898977fc8ce537\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x90898977fc8ce537 Time: 0.0102917\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd9eb6ca56ddc3a22\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xd9eb6ca56ddc3a22 Time: 0.0103124\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0a143be7a52f301a Time: 0.0083712\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd55ee6fd0b56f808\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xd55ee6fd0b56f808 Time: 0.0152669\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xbc0bba0ff1a92939\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xbc0bba0ff1a92939 Time: 0.0241371\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x92ed3100c35fc43e Time: 0.00902227\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x55d80c17b1cd982d\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x55d80c17b1cd982d Time: 0.0108786\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x1da91d865428f237 Time: 0.016319\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xc7b3afceb5fb03c0\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xc7b3afceb5fb03c0 Time: 0.0152824\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x62835fce994f06dd Time: 0.0113664\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xa6448a1e79f1ca6f Time: 0.0110328\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x35f26f9c09557d86\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x35f26f9c09557d86 Time: 0.0157944\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x4fd3c46622e98342 Time: 0.00945303\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x19b688348f983aa0 Time: 0.0107307\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x1022069e6f8d9aeb\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x1022069e6f8d9aeb Time: 0.0155462\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x8014228ec08b4d49 Time: 0.0268603\n",
      "[08/12/2025-19:08:21] [TRT] [V] Fastest Tactic: 0x1fb90698107bb33a Time: 0.0082586\n",
      "[08/12/2025-19:08:21] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x1fb90698107bb33a\n",
      "[08/12/2025-19:08:21] [TRT] [V] *************** Autotuning format combination: Float(9,1:4,9,9) -> Float(14,1:4,14,14) ***************\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 (CudaDepthwiseConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 (CublasConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 (CaskGemmConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CaskGemmConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 (CaskFlattenConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CaskFlattenConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 (CaskConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] =============== Computing costs for \n",
      "[08/12/2025-19:08:21] [TRT] [V] *************** Autotuning format combination: Float(36,1,1,1) -> Float(13,1,1,1) ***************\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd (CudaDepthwiseConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd (FusedConvActConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd (CudnnConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd (CublasConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.0108456\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000000001 Time: 0.0108346\n",
      "[08/12/2025-19:08:21] [TRT] [V] Fastest Tactic: 0x0000000000000001 Time: 0.0108346\n",
      "[08/12/2025-19:08:21] [TRT] [V] Unrecognized MMA instruction source format or shape: sm70_xmma_gemm_as_conv1x1_f32f32_f32_f32_tn_n_simt_small_batch_bias_relu\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd: 16 available tactics, 16 unparsable, 0 pruned, 16 remaining after tactic pruning.\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd (CaskGemmConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_relu_tn_v1 Tactic: 0x000000000002005d numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x000000000002005d Time: 0.00814205\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_nn_v1 Tactic: 0x0000000000020088 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000020088 Time: 0.0108456\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_tn_v1 Tactic: 0x00000000000200dc numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x00000000000200dc Time: 0.0135851\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_nn_v1 Tactic: 0x000000000002014c numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x000000000002014c Time: 0.0100392\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_nn_v1 Tactic: 0x0000000000020191 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000020191 Time: 0.0129444\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_relu_nn_v1 Tactic: 0x00000000000201f0 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x00000000000201f0 Time: 0.00816703\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_relu_nn_v1 Tactic: 0x00000000000201f5 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x00000000000201f5 Time: 0.0107905\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_relu_tn_v1 Tactic: 0x000000000002023a numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x000000000002023a Time: 0.00900042\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize128x32x8_stage3_warpsize2x2x1_ffma_aligna4_alignc4 Tactic: 0x00000000000202a0 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x00000000000202a0 Time: 0.008448\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_tn_v1 Tactic: 0x00000000000202ed numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x00000000000202ed Time: 0.0100091\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4 Tactic: 0x0000000000020440 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000020440 Time: 0.00713895\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize64x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4 Tactic: 0x0000000000020443 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000020443 Time: 0.00818368\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: sm70_xmma_gemm_as_conv1x1_f32f32_f32_f32_tn_n_simt_small_batch_bias_relu Tactic: 0x000000000002047e numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x000000000002047e Time: 0.00629213\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_tn_v1 Tactic: 0x0000000000020589 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000020589 Time: 0.0110658\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_relu_tn_v1 Tactic: 0x0000000000020768 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000020768 Time: 0.0115347\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_relu_nn_v1 Tactic: 0x000000000002077b numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x000000000002077b Time: 0.00862086\n",
      "[08/12/2025-19:08:21] [TRT] [V] Fastest Tactic: 0x000000000002047e Time: 0.00629213\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd (CaskFlattenConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CaskFlattenConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd (CaskConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x12dbf7d94ee3696d Time: 0.018414\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x9d9fdb5fd9945f64\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x9d9fdb5fd9945f64 Time: 0.0101986\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x828d0ea88c66fce7\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x828d0ea88c66fce7 Time: 0.0121295\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xc0b05b61d128e46e\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xc0b05b61d128e46e Time: 0.0171349\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xbb8c3889c7eacd30 Time: 0.0371295\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xb0bf940d5e0f9f45\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xb0bf940d5e0f9f45 Time: 0.00901305\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90f8f2915f87ed77\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x90f8f2915f87ed77 Time: 0.00873464\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xa31d27de74b895ff Time: 0.0118407\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xe5603263b7f00303\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xe5603263b7f00303 Time: 0.0181446\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x2ee10e11d6651675\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x2ee10e11d6651675 Time: 0.0272279\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x5aa723e0481da855 Time: 0.0173397\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x40a12e3938221818\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x40a12e3938221818 Time: 0.0144498\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9de226a0c44627c4\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x9de226a0c44627c4 Time: 0.0259413\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa9366041633a5135\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xa9366041633a5135 Time: 0.0164978\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fc87d7eb370bb7a\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x1fc87d7eb370bb7a Time: 0.0112526\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xfff46c7893896eb1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xfff46c7893896eb1 Time: 0.0328301\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9cd5cdc35441c505\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x9cd5cdc35441c505 Time: 0.016319\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x8e3884f0eaec3ecd\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x8e3884f0eaec3ecd Time: 0.0170667\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm70_xmma_fprop_conv1x1_f32f32_f32_f32_nchwkcrs_nchw_simt_small_batch_bias_relu Tactic: 0xaa0953b1a73b0b9b\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xaa0953b1a73b0b9b Time: 0.00627674\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xd828f024626fa982 Time: 0.0139804\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xcb8a43f748d8a338\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xcb8a43f748d8a338 Time: 0.0111616\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x865894c4635db7fd\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x865894c4635db7fd Time: 0.0116406\n",
      "[08/12/2025-19:08:21] [TRT] [V] Fastest Tactic: 0xaa0953b1a73b0b9b Time: 0.00627674\n",
      "[08/12/2025-19:08:21] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xaa0953b1a73b0b9b\n",
      "[08/12/2025-19:08:21] [TRT] [V] *************** Autotuning format combination: Float(36,1,36,36) -> Float(13,1,13,13) ***************\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd (CublasConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd (CaskFlattenConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CaskFlattenConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd (CaskConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fb90698107bb33a\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x1fb90698107bb33a Time: 0.00806197\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x7121ec1db3f80c67 Time: 0.0084736\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90898977fc8ce537\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x90898977fc8ce537 Time: 0.0102193\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd9eb6ca56ddc3a22\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xd9eb6ca56ddc3a22 Time: 0.010209\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0a143be7a52f301a Time: 0.00816703\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd55ee6fd0b56f808\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xd55ee6fd0b56f808 Time: 0.0150187\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xbc0bba0ff1a92939\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xbc0bba0ff1a92939 Time: 0.0238933\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x92ed3100c35fc43e Time: 0.00894653\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x55d80c17b1cd982d\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x55d80c17b1cd982d Time: 0.0108236\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x1da91d865428f237 Time: 0.0161239\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xc7b3afceb5fb03c0\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xc7b3afceb5fb03c0 Time: 0.015078\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x62835fce994f06dd Time: 0.0112868\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xa6448a1e79f1ca6f Time: 0.0107685\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x35f26f9c09557d86\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x35f26f9c09557d86 Time: 0.0156703\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x4fd3c46622e98342 Time: 0.00919755\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x19b688348f983aa0 Time: 0.0105493\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x1022069e6f8d9aeb\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x1022069e6f8d9aeb Time: 0.0154996\n",
      "[08/12/2025-19:08:21] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x8014228ec08b4d49 Time: 0.0267028\n",
      "[08/12/2025-19:08:21] [TRT] [V] Fastest Tactic: 0x1fb90698107bb33a Time: 0.00806197\n",
      "[08/12/2025-19:08:21] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x1fb90698107bb33a\n",
      "[08/12/2025-19:08:21] [TRT] [V] *************** Autotuning format combination: Float(9,1:4,9,9) -> Float(4,1:4,4,4) ***************\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd (CudaDepthwiseConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd (CublasConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd (CaskGemmConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CaskGemmConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd (CaskFlattenConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CaskFlattenConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd (CaskConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CaskConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] =============== Computing costs for \n",
      "[08/12/2025-19:08:21] [TRT] [V] *************** Autotuning format combination: Float(13,1,1,1) -> Float(13,1) ***************\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: reshape_after_AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd (Shuffle)\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00395143\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000000001 Time: 0.0152824\n",
      "[08/12/2025-19:08:21] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00395143\n",
      "[08/12/2025-19:08:21] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000\n",
      "[08/12/2025-19:08:21] [TRT] [V] =============== Computing costs for \n",
      "[08/12/2025-19:08:21] [TRT] [V] *************** Autotuning format combination: Float(13,1) -> Float(13,1) ***************\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: StatefulPartitionedCall:0 (CudaSoftMax)\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x00000000000003ea Time: 0.00553967\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x00000000000003e9 Time: 0.00446919\n",
      "[08/12/2025-19:08:21] [TRT] [V] Fastest Tactic: 0x00000000000003e9 Time: 0.00446919\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: StatefulPartitionedCall:0 (CaskSoftMax)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CaskSoftMax has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CudaSoftMax Tactic: 0x00000000000003e9\n",
      "[08/12/2025-19:08:21] [TRT] [V] =============== Computing costs for \n",
      "[08/12/2025-19:08:21] [TRT] [V] *************** Autotuning format combination: Float(55,1,1,1) -> Float(94,1,1,1) ***************\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: StatefulPartitionedCall:1 (CudaDepthwiseConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: StatefulPartitionedCall:1 (FusedConvActConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] FusedConvActConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: StatefulPartitionedCall:1 (CudnnConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CudnnConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: StatefulPartitionedCall:1 (CublasConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00876089\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000000001 Time: 0.00905917\n",
      "[08/12/2025-19:08:21] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00876089\n",
      "[08/12/2025-19:08:21] [TRT] [V] Unrecognized MMA instruction source format or shape: sm70_xmma_gemm_as_conv1x1_f32f32_f32_f32_tn_n_simt_small_batch_bias_relu\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1: 16 available tactics, 16 unparsable, 0 pruned, 16 remaining after tactic pruning.\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: StatefulPartitionedCall:1 (CaskGemmConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_relu_tn_v1 Tactic: 0x000000000002005d numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x000000000002005d Time: 0.0082253\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_nn_v1 Tactic: 0x0000000000020088 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000020088 Time: 0.0111161\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_tn_v1 Tactic: 0x00000000000200dc numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x00000000000200dc Time: 0.0139236\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_nn_v1 Tactic: 0x000000000002014c numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x000000000002014c Time: 0.01056\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_nn_v1 Tactic: 0x0000000000020191 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000020191 Time: 0.0132201\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_relu_nn_v1 Tactic: 0x00000000000201f0 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x00000000000201f0 Time: 0.00813373\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_relu_nn_v1 Tactic: 0x00000000000201f5 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x00000000000201f5 Time: 0.0109667\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_relu_tn_v1 Tactic: 0x000000000002023a numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x000000000002023a Time: 0.00914219\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize128x32x8_stage3_warpsize2x2x1_ffma_aligna4_alignc4 Tactic: 0x00000000000202a0 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x00000000000202a0 Time: 0.00944355\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_32x32_sliced1x4_tn_v1 Tactic: 0x00000000000202ed numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x00000000000202ed Time: 0.010592\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4 Tactic: 0x0000000000020440 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000020440 Time: 0.00774206\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize64x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4 Tactic: 0x0000000000020443 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000020443 Time: 0.00907762\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: sm70_xmma_gemm_as_conv1x1_f32f32_f32_f32_tn_n_simt_small_batch_bias_relu Tactic: 0x000000000002047e numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x000000000002047e Time: 0.00656565\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_tn_v1 Tactic: 0x0000000000020589 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000020589 Time: 0.0115936\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_128x32_sliced1x4_relu_tn_v1 Tactic: 0x0000000000020768 numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000020768 Time: 0.0116289\n",
      "[08/12/2025-19:08:21] [TRT] [V] Set Tactic Name: ampere_sgemm_64x32_sliced1x4_relu_nn_v1 Tactic: 0x000000000002077b numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x000000000002077b Time: 0.00892856\n",
      "[08/12/2025-19:08:21] [TRT] [V] Fastest Tactic: 0x000000000002047e Time: 0.00656565\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: StatefulPartitionedCall:1 (CaskFlattenConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CaskFlattenConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: StatefulPartitionedCall:1 (CaskConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x12dbf7d94ee3696d Time: 0.0202391\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x9d9fdb5fd9945f64\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x9d9fdb5fd9945f64 Time: 0.0111388\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x828d0ea88c66fce7\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x828d0ea88c66fce7 Time: 0.0134485\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xc0b05b61d128e46e\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xc0b05b61d128e46e Time: 0.0189819\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xbb8c3889c7eacd30 Time: 0.043776\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xb0bf940d5e0f9f45\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xb0bf940d5e0f9f45 Time: 0.00978164\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90f8f2915f87ed77\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x90f8f2915f87ed77 Time: 0.00949096\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xa31d27de74b895ff Time: 0.0129707\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xe5603263b7f00303\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xe5603263b7f00303 Time: 0.0202391\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x2ee10e11d6651675\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x2ee10e11d6651675 Time: 0.0308131\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x5aa723e0481da855 Time: 0.0191526\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x40a12e3938221818\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x40a12e3938221818 Time: 0.0166116\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9de226a0c44627c4\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x9de226a0c44627c4 Time: 0.0293547\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa9366041633a5135\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xa9366041633a5135 Time: 0.0193612\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fc87d7eb370bb7a\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x1fc87d7eb370bb7a Time: 0.0123891\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xfff46c7893896eb1\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xfff46c7893896eb1 Time: 0.0393671\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9cd5cdc35441c505\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x9cd5cdc35441c505 Time: 0.0183242\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x8e3884f0eaec3ecd\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x8e3884f0eaec3ecd Time: 0.0190578\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm70_xmma_fprop_conv1x1_f32f32_f32_f32_nchwkcrs_nchw_simt_small_batch_bias_relu Tactic: 0xaa0953b1a73b0b9b\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xaa0953b1a73b0b9b Time: 0.00653888\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xd828f024626fa982 Time: 0.0159777\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xcb8a43f748d8a338\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xcb8a43f748d8a338 Time: 0.0128919\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x865894c4635db7fd\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x865894c4635db7fd Time: 0.0128788\n",
      "[08/12/2025-19:08:21] [TRT] [V] Fastest Tactic: 0xaa0953b1a73b0b9b Time: 0.00653888\n",
      "[08/12/2025-19:08:21] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xaa0953b1a73b0b9b\n",
      "[08/12/2025-19:08:21] [TRT] [V] *************** Autotuning format combination: Float(55,1,55,55) -> Float(94,1,94,94) ***************\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: StatefulPartitionedCall:1 (CublasConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: StatefulPartitionedCall:1 (CaskFlattenConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CaskFlattenConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: StatefulPartitionedCall:1 (CaskConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fb90698107bb33a\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x1fb90698107bb33a Time: 0.00862961\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x7121ec1db3f80c67 Time: 0.00905917\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90898977fc8ce537\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x90898977fc8ce537 Time: 0.0110988\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd9eb6ca56ddc3a22\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xd9eb6ca56ddc3a22 Time: 0.0111275\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0a143be7a52f301a Time: 0.00900042\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd55ee6fd0b56f808\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xd55ee6fd0b56f808 Time: 0.0169643\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xbc0bba0ff1a92939\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xbc0bba0ff1a92939 Time: 0.0271754\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x92ed3100c35fc43e Time: 0.00963535\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x55d80c17b1cd982d\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x55d80c17b1cd982d Time: 0.0118172\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x1da91d865428f237 Time: 0.017911\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xc7b3afceb5fb03c0\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xc7b3afceb5fb03c0 Time: 0.0167936\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x62835fce994f06dd Time: 0.0121661\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xa6448a1e79f1ca6f Time: 0.0119589\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x35f26f9c09557d86\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x35f26f9c09557d86 Time: 0.017408\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x4fd3c46622e98342 Time: 0.0102814\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x19b688348f983aa0 Time: 0.0115465\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x1022069e6f8d9aeb\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x1022069e6f8d9aeb Time: 0.0171349\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x8014228ec08b4d49 Time: 0.0298382\n",
      "[08/12/2025-19:08:21] [TRT] [V] Fastest Tactic: 0x1fb90698107bb33a Time: 0.00862961\n",
      "[08/12/2025-19:08:21] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x1fb90698107bb33a\n",
      "[08/12/2025-19:08:21] [TRT] [V] *************** Autotuning format combination: Float(14,1:4,14,14) -> Float(24,1:4,24,24) ***************\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: StatefulPartitionedCall:1 (CudaDepthwiseConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CudaDepthwiseConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: StatefulPartitionedCall:1 (CublasConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CublasConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: StatefulPartitionedCall:1 (CaskGemmConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CaskGemmConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: StatefulPartitionedCall:1 (CaskFlattenConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] CaskFlattenConvolution has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: StatefulPartitionedCall:1 (CaskConvolution)\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fb90698107bb33a\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x1fb90698107bb33a Time: 0.00854187\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x7121ec1db3f80c67 Time: 0.00908685\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90898977fc8ce537\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x90898977fc8ce537 Time: 0.0111275\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd9eb6ca56ddc3a22\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xd9eb6ca56ddc3a22 Time: 0.0110878\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0a143be7a52f301a Time: 0.00894653\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd55ee6fd0b56f808\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xd55ee6fd0b56f808 Time: 0.0168448\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xbc0bba0ff1a92939\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xbc0bba0ff1a92939 Time: 0.0271229\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x92ed3100c35fc43e Time: 0.00960609\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x55d80c17b1cd982d\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x55d80c17b1cd982d Time: 0.0116289\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x1da91d865428f237 Time: 0.0178392\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xc7b3afceb5fb03c0\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xc7b3afceb5fb03c0 Time: 0.0167253\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x62835fce994f06dd Time: 0.0122392\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0xa6448a1e79f1ca6f Time: 0.0119345\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x35f26f9c09557d86\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x35f26f9c09557d86 Time: 0.0173909\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x4fd3c46622e98342 Time: 0.0102297\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x19b688348f983aa0 Time: 0.0115229\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x1022069e6f8d9aeb\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x1022069e6f8d9aeb Time: 0.0171179\n",
      "[08/12/2025-19:08:21] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x8014228ec08b4d49 Time: 0.0298382\n",
      "[08/12/2025-19:08:21] [TRT] [V] Fastest Tactic: 0x1fb90698107bb33a Time: 0.00854187\n",
      "[08/12/2025-19:08:21] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x1fb90698107bb33a\n",
      "[08/12/2025-19:08:21] [TRT] [V] =============== Computing costs for \n",
      "[08/12/2025-19:08:21] [TRT] [V] *************** Autotuning format combination: Float(94,1,1,1) -> Float(94,1) ***************\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: reshape_after_StatefulPartitionedCall:1 (Shuffle)\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00418986\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000000001 Time: 0.0152669\n",
      "[08/12/2025-19:08:21] [TRT] [V] Fastest Tactic: 0x0000000000000000 Time: 0.00418986\n",
      "[08/12/2025-19:08:21] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: Shuffle Tactic: 0x0000000000000000\n",
      "[08/12/2025-19:08:21] [TRT] [V] =============== Computing costs for \n",
      "[08/12/2025-19:08:21] [TRT] [V] *************** Autotuning format combination: Float(94,1) -> Float(94,1) ***************\n",
      "[08/12/2025-19:08:21] [TRT] [V] --------------- Timing Runner: PWN(Relu__25) (PointWiseV2)\n",
      "[08/12/2025-19:08:21] [TRT] [V] Tactic: 0x0000000000000000 Time: 0.00440589\n",
      "[08/12/2025-19:08:22] [TRT] [V] Tactic: 0x0000000000000001 Time: 0.0044965\n",
      "[08/12/2025-19:08:22] [TRT] [V] Tactic: 0x0000000000000002 Time: 0.00446009\n",
      "[08/12/2025-19:08:22] [TRT] [V] Tactic: 0x0000000000000003 Time: 0.00481767\n",
      "[08/12/2025-19:08:22] [TRT] [V] Tactic: 0x0000000000000004 Time: 0.00448284\n",
      "[08/12/2025-19:08:22] [TRT] [V] Tactic: 0x0000000000000005 Time: 0.00440589\n",
      "[08/12/2025-19:08:23] [TRT] [V] Tactic: 0x0000000000000006 Time: 0.0055061\n",
      "[08/12/2025-19:08:23] [TRT] [V] Tactic: 0x0000000000000007 Time: 0.00477379\n",
      "[08/12/2025-19:08:23] [TRT] [V] Tactic: 0x0000000000000008 Time: 0.00451575\n",
      "[08/12/2025-19:08:23] [TRT] [V] Tactic: 0x0000000000000009 Time: 0.00446009\n",
      "[08/12/2025-19:08:23] [TRT] [V] Tactic: 0x000000000000001c Time: 0.00437527\n",
      "[08/12/2025-19:08:23] [TRT] [V] Fastest Tactic: 0x000000000000001c Time: 0.00437527\n",
      "[08/12/2025-19:08:23] [TRT] [V] --------------- Timing Runner: PWN(Relu__25) (PointWise)\n",
      "[08/12/2025-19:08:23] [TRT] [V] PointWise has no valid tactics for this config, skipping\n",
      "[08/12/2025-19:08:23] [TRT] [V] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0x000000000000001c\n",
      "[08/12/2025-19:08:23] [TRT] [V] Formats and tactics selection completed in 3.64081 seconds.\n",
      "[08/12/2025-19:08:23] [TRT] [V] After reformat layers: 10 layers\n",
      "[08/12/2025-19:08:23] [TRT] [V] Total number of blocks in pre-optimized block assignment: 9\n",
      "[08/12/2025-19:08:23] [TRT] [I] Total Activation Memory: 1073752576\n",
      "[08/12/2025-19:08:23] [TRT] [I] Detected 1 inputs and 2 output network tensors.\n",
      "[08/12/2025-19:08:23] [TRT] [V] Set Tactic Name: sm70_xmma_gemm_as_conv1x1_f32f32_f32_f32_tn_n_simt_small_batch_bias_relu Tactic: 0x000000000002047e numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:23] [TRT] [V] Set Tactic Name: sm70_xmma_gemm_as_conv1x1_f32f32_f32_f32_tn_n_simt_small_batch_bias_relu Tactic: 0x000000000002047e numSplitK: 1 numBuffers: 0 numKernels: 1\n",
      "[08/12/2025-19:08:23] [TRT] [V] AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set Tactic Name: sm70_xmma_fprop_conv1x1_f32f32_f32_f32_nchwkcrs_nchw_simt_small_batch_bias_relu Tactic: 0xaa0953b1a73b0b9b\n",
      "[08/12/2025-19:08:23] [TRT] [V] AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set Tactic Name: sm70_xmma_fprop_conv1x1_f32f32_f32_f32_nchwkcrs_nchw_simt_small_batch_bias_relu Tactic: 0xaa0953b1a73b0b9b\n",
      "[08/12/2025-19:08:23] [TRT] [V] StatefulPartitionedCall:1 Set Tactic Name: sm70_xmma_fprop_conv1x1_f32f32_f32_f32_nchwkcrs_nchw_simt_small_batch_bias_relu Tactic: 0xaa0953b1a73b0b9b\n",
      "[08/12/2025-19:08:23] [TRT] [V] Layer: AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Host Persistent: 6752 Device Persistent: 0 Scratch Memory: 0\n",
      "[08/12/2025-19:08:23] [TRT] [V] Layer: AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Host Persistent: 6752 Device Persistent: 0 Scratch Memory: 0\n",
      "[08/12/2025-19:08:23] [TRT] [V] Layer: AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Host Persistent: 2880 Device Persistent: 0 Scratch Memory: 0\n",
      "[08/12/2025-19:08:23] [TRT] [V] Layer: AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Host Persistent: 2880 Device Persistent: 0 Scratch Memory: 0\n",
      "[08/12/2025-19:08:23] [TRT] [V] Layer: StatefulPartitionedCall:1 Host Persistent: 2880 Device Persistent: 0 Scratch Memory: 0\n",
      "[08/12/2025-19:08:23] [TRT] [V] Layer: PWN(Relu__25) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0\n",
      "[08/12/2025-19:08:23] [TRT] [V] Skipped printing memory information for 4 layers with 0 memory size i.e. Host Persistent + Device Persistent + Scratch Memory == 0.\n",
      "[08/12/2025-19:08:23] [TRT] [I] Total Host Persistent Memory: 22400\n",
      "[08/12/2025-19:08:23] [TRT] [I] Total Device Persistent Memory: 0\n",
      "[08/12/2025-19:08:23] [TRT] [I] Total Scratch Memory: 0\n",
      "[08/12/2025-19:08:23] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 4 MiB\n",
      "[08/12/2025-19:08:23] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 8 steps to complete.\n",
      "[08/12/2025-19:08:23] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.025538ms to assign 3 blocks to 8 nodes requiring 5632 bytes.\n",
      "[08/12/2025-19:08:23] [TRT] [V] Total number of blocks in optimized block assignment: 3\n",
      "[08/12/2025-19:08:23] [TRT] [I] Total Activation Memory: 5632\n",
      "[08/12/2025-19:08:23] [TRT] [V] Finalize: AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7 Set kernel index: 0\n",
      "[08/12/2025-19:08:23] [TRT] [V] Finalize: AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12 Set kernel index: 0\n",
      "[08/12/2025-19:08:23] [TRT] [V] Finalize: AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20 Set kernel index: 1\n",
      "[08/12/2025-19:08:23] [TRT] [V] Finalize: AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd Set kernel index: 1\n",
      "[08/12/2025-19:08:23] [TRT] [V] Finalize: StatefulPartitionedCall:1 Set kernel index: 1\n",
      "[08/12/2025-19:08:23] [TRT] [V] Finalize: PWN(Relu__25) Set kernel index: 2\n",
      "[08/12/2025-19:08:23] [TRT] [V] Total number of generated kernels selected for the engine: 3\n",
      "[08/12/2025-19:08:23] [TRT] [V] Kernel: 0 CASK_STATIC\n",
      "[08/12/2025-19:08:23] [TRT] [V] Kernel: 1 CASK_STATIC\n",
      "[08/12/2025-19:08:23] [TRT] [V] Kernel: 2 TRT_SERIALIZABLE:generatedNativePointwise\n",
      "[08/12/2025-19:08:23] [TRT] [V] Disabling unused tactic source: CUBLAS, CUBLAS_LT\n",
      "[08/12/2025-19:08:23] [TRT] [V] Engine generation completed in 4.17341 seconds.\n",
      "[08/12/2025-19:08:23] [TRT] [V] Deleting timing cache: 46 entries, served 14 hits since creation.\n",
      "[08/12/2025-19:08:23] [TRT] [V] Engine Layer Information:\n",
      "Layer(NoOp): reshape_before_AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1, Tactic: 0x0000000000000000, serving_default_encoder_input:0 (Float[-1,94]) -> reshape_before_AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1_out_tensor (Float[-1,94,1,1])\n",
      "Layer(CaskGemmConvolution): AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1 + Relu__7, Tactic: 0x000000000002047e, reshape_before_AutoEncoderClassifier/encoder_dense_0/MatMul;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/encoder_relu_0/Relu;AutoEncoderClassifier/encoder_batchnorm_0/batchnorm/add_1_out_tensor (Float[-1,94,1,1]) -> Relu__7_out_tensor (Float[-1,55,1,1])\n",
      "Layer(CaskGemmConvolution): AutoEncoderClassifier/latent_dense/MatMul;AutoEncoderClassifier/latent_batchnorm/batchnorm/mul_1;AutoEncoderClassifier/latent_relu/Relu;AutoEncoderClassifier/latent_batchnorm/batchnorm/add_1 + Relu__12, Tactic: 0x000000000002047e, Relu__7_out_tensor (Float[-1,55,1,1]) -> Relu__12_out_tensor (Float[-1,36,1,1])\n",
      "Layer(CaskConvolution): AutoEncoderClassifier/decoder_dense_0/MatMul;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/mul_1;AutoEncoderClassifier/decoder_relu_0/Relu;AutoEncoderClassifier/decoder_batchnorm_0/batchnorm/add_1 + Relu__20, Tactic: 0xaa0953b1a73b0b9b, Relu__12_out_tensor (Float[-1,36,1,1]) -> Relu__20_out_tensor (Float[-1,55,1,1])\n",
      "Layer(CaskConvolution): AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd, Tactic: 0xaa0953b1a73b0b9b, Relu__12_out_tensor (Float[-1,36,1,1]) -> AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd_out_tensor (Float[-1,13,1,1])\n",
      "Layer(NoOp): reshape_after_AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd, Tactic: 0x0000000000000000, AutoEncoderClassifier/classification_out/MatMul;AutoEncoderClassifier/classification_out/BiasAdd_out_tensor (Float[-1,13,1,1]) -> Add__18:0 (Float[-1,13])\n",
      "Layer(CudaSoftMax): StatefulPartitionedCall:0, Tactic: 0x00000000000003e9, Add__18:0 (Float[-1,13]) -> StatefulPartitionedCall:0 (Float[-1,13])\n",
      "Layer(CaskConvolution): StatefulPartitionedCall:1, Tactic: 0xaa0953b1a73b0b9b, Relu__20_out_tensor (Float[-1,55,1,1]) -> StatefulPartitionedCall:1_out_tensor (Float[-1,94,1,1])\n",
      "Layer(NoOp): reshape_after_StatefulPartitionedCall:1, Tactic: 0x0000000000000000, StatefulPartitionedCall:1_out_tensor (Float[-1,94,1,1]) -> Add__28:0 (Float[-1,94])\n",
      "Layer(PointWiseV2): PWN(Relu__25), Tactic: 0x000000000000001c, Add__28:0 (Float[-1,94]) -> StatefulPartitionedCall:1 (Float[-1,94])\n",
      "[08/12/2025-19:08:23] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +4, now: CPU 0, GPU 4 (MiB)\n",
      "✅ Saved engine: ./DL Models/best_AE_model.trt\n",
      "[08/12/2025-19:08:23] [TRT] [I] The logger passed into createInferRuntime differs from one already provided for an existing builder, runtime, or refitter. Uses of the global logger, returned by nvinfer1::getLogger(), will return the existing value.\n",
      "\n",
      "[08/12/2025-19:08:23] [TRT] [I] Loaded engine size: 1 MiB\n",
      "[08/12/2025-19:08:24] [TRT] [V] Deserialization required 9279 microseconds.\n",
      "Engine load OK: True\n",
      "[08/12/2025-19:08:24] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)\n"
     ]
    }
   ],
   "source": [
    "import os, onnx, tensorrt as trt\n",
    "\n",
    "onnx_path   = \"./DL Models/best_AE_model.onnx\"   # your float (non-quantized) ONNX\n",
    "engine_path = \"./DL Models/best_AE_model.trt\"    # will save here\n",
    "\n",
    "# ---- 0) Validate ONNX ----\n",
    "m = onnx.load(onnx_path)\n",
    "onnx.checker.check_model(m)\n",
    "print(\"ONNX checker: OK\")\n",
    "\n",
    "# ---- 1) Builder / Network (explicit batch) / Config / Parser ----\n",
    "logger = trt.Logger(trt.Logger.VERBOSE)\n",
    "EXPL = 1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "\n",
    "builder = trt.Builder(logger)\n",
    "network = builder.create_network(EXPL)\n",
    "config  = builder.create_builder_config()\n",
    "\n",
    "# workspace (adjust if needed)\n",
    "config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30)  # 1 GiB\n",
    "\n",
    "# Keep FP32 only\n",
    "if hasattr(trt.BuilderFlag, \"FP16\"):\n",
    "    config.clear_flag(trt.BuilderFlag.FP16)\n",
    "# Some builds support TF32 flag; clear it if present\n",
    "if hasattr(trt.BuilderFlag, \"TF32\"):\n",
    "    config.clear_flag(trt.BuilderFlag.TF32)\n",
    "\n",
    "# Force safer kernel choices (optional but helps)\n",
    "if hasattr(trt.BuilderFlag, \"STRICT_TYPES\"):\n",
    "    config.set_flag(trt.BuilderFlag.STRICT_TYPES)\n",
    "\n",
    "# Restrict tactics to GEMM (avoid cuDNN conv/depthwise)\n",
    "try:\n",
    "    mask = 0\n",
    "    if hasattr(trt.TacticSource, \"CUBLAS\"):\n",
    "        mask |= int(trt.TacticSource.CUBLAS)\n",
    "    if hasattr(trt.TacticSource, \"CUBLAS_LT\"):\n",
    "        mask |= int(trt.TacticSource.CUBLAS_LT)\n",
    "    if mask and hasattr(config, \"set_tactic_sources\"):\n",
    "        config.set_tactic_sources(mask)\n",
    "        print(\"Tactic sources limited to cuBLAS/cuBLASLt.\")\n",
    "except Exception as e:\n",
    "    print(\"Skipping tactic source restriction:\", e)\n",
    "\n",
    "parser = trt.OnnxParser(network, logger)\n",
    "with open(onnx_path, \"rb\") as f:\n",
    "    blob = f.read()\n",
    "if not parser.parse(blob):\n",
    "    print(\"❌ ONNX parse failed:\")\n",
    "    for i in range(parser.num_errors):\n",
    "        print(parser.get_error(i))\n",
    "    raise SystemExit(1)\n",
    "\n",
    "# ---- 2) Print inputs exactly as TRT sees them ----\n",
    "print(\"Network inputs:\")\n",
    "for i in range(network.num_inputs):\n",
    "    inp = network.get_input(i)\n",
    "    print(f\"  {i}: name='{inp.name}', shape={list(inp.shape)}, dtype={inp.dtype}\")\n",
    "\n",
    "# ---- 3) Optimization profile: keep shapes small & safe ----\n",
    "profile_needed = False\n",
    "profile = builder.create_optimization_profile()\n",
    "for i in range(network.num_inputs):\n",
    "    inp = network.get_input(i)\n",
    "    shape = list(inp.shape)\n",
    "    if any(d == -1 for d in shape):\n",
    "        profile_needed = True\n",
    "        # Your input is [-1, 94], so vary only batch dim\n",
    "        min_shape = [1, 94]\n",
    "        opt_shape = [4, 94]\n",
    "        max_shape = [8, 94]\n",
    "        profile.set_shape(inp.name, min_shape, opt_shape, max_shape)\n",
    "        print(f\"Profile for '{inp.name}': min={min_shape}, opt={opt_shape}, max={max_shape}\")\n",
    "\n",
    "if profile_needed:\n",
    "    config.add_optimization_profile(profile)\n",
    "\n",
    "# ---- 4) Build & save ----\n",
    "serialized = builder.build_serialized_network(network, config)\n",
    "if serialized is None:\n",
    "    raise RuntimeError(\"Failed to build TensorRT engine.\")\n",
    "os.makedirs(os.path.dirname(engine_path) or \".\", exist_ok=True)\n",
    "with open(engine_path, \"wb\") as f:\n",
    "    f.write(serialized)\n",
    "print(f\"✅ Saved engine: {engine_path}\")\n",
    "\n",
    "# ---- 5) Quick load sanity check ----\n",
    "runtime = trt.Runtime(logger)\n",
    "with open(engine_path, \"rb\") as f:\n",
    "    engine = runtime.deserialize_cuda_engine(f.read())\n",
    "print(\"Engine load OK:\", engine is not None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ae475-7ec8-4e4b-8bca-1a14bbf782ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fdd4f73-436d-43ce-87db-f248f9a95ea1",
   "metadata": {},
   "source": [
    "--------\n",
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bf041fc-71e3-4696-b9fe-c1f0b6ce42cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=1: max|ORT-TRT| = 1.863e-09\n",
      "N=4: max|ORT-TRT| = 1.192e-07\n",
      "N=8: max|ORT-TRT| = 2.384e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rteam8/anaconda3/envs/tuninggpu310/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:121: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_1815217/270268522.py:18: DeprecationWarning: Use set_input_shape instead.\n",
      "  context.set_binding_shape(0, x.shape)\n",
      "/tmp/ipykernel_1815217/270268522.py:20: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  out_shape = tuple(context.get_binding_shape(1))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, onnxruntime as ort, tensorrt as trt, pycuda.driver as cuda, pycuda.autoinit\n",
    "\n",
    "onnx_path   = \"./DL Models/best_FCNN_model.onnx\"   # your float (non-quantized) ONNX\n",
    "engine_path = \"./DL Models/best_FCNN_model.trt\"    # will save here\n",
    "\n",
    "# ORT session\n",
    "sess = ort.InferenceSession(onnx_path, providers=[\"CUDAExecutionProvider\",\"CPUExecutionProvider\"])\n",
    "inp_name = sess.get_inputs()[0].name\n",
    "\n",
    "# TRT runtime\n",
    "logger = trt.Logger(trt.Logger.WARNING)\n",
    "runtime = trt.Runtime(logger)\n",
    "with open(engine_path, \"rb\") as f: engine = runtime.deserialize_cuda_engine(f.read())\n",
    "context = engine.create_execution_context()\n",
    "\n",
    "def trt_infer(x: np.ndarray):\n",
    "    # x shape: [N,94], float32\n",
    "    context.set_binding_shape(0, x.shape)\n",
    "    d_in  = cuda.mem_alloc(x.nbytes)\n",
    "    out_shape = tuple(context.get_binding_shape(1))\n",
    "    y = np.empty(out_shape, dtype=np.float32)\n",
    "    d_out = cuda.mem_alloc(y.nbytes)\n",
    "    stream = cuda.Stream()\n",
    "    cuda.memcpy_htod_async(d_in, x, stream)\n",
    "    context.execute_async_v2([int(d_in), int(d_out)], stream.handle)\n",
    "    cuda.memcpy_dtoh_async(y, d_out, stream); stream.synchronize()\n",
    "    return y\n",
    "\n",
    "for N in (1,4,8):\n",
    "    x = np.random.rand(N,94).astype(np.float32)\n",
    "    y_ort = sess.run(None, {inp_name: x})[0]\n",
    "    y_trt = trt_infer(x)\n",
    "    max_abs = np.max(np.abs(y_ort - y_trt))\n",
    "    print(f\"N={N}: max|ORT-TRT| = {max_abs:.3e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ba621f9-cb41-4d94-889f-e78d86d8b217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=1: max|ORT-TRT| = 9.313e-09\n",
      "N=4: max|ORT-TRT| = 1.788e-07\n",
      "N=8: max|ORT-TRT| = 6.557e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1815217/1428560804.py:22: DeprecationWarning: Use get_tensor_mode instead.\n",
      "  input_bindings  = [i for i in range(engine.num_bindings) if engine.binding_is_input(i)]\n",
      "/tmp/ipykernel_1815217/1428560804.py:23: DeprecationWarning: Use get_tensor_mode instead.\n",
      "  output_bindings = [i for i in range(engine.num_bindings) if not engine.binding_is_input(i)]\n",
      "/tmp/ipykernel_1815217/1428560804.py:29: DeprecationWarning: Use set_input_shape instead.\n",
      "  context.set_binding_shape(in_idx, (1, D))\n",
      "/tmp/ipykernel_1815217/1428560804.py:30: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  out_shapes = {i: tuple(context.get_binding_shape(i)) for i in output_bindings}\n",
      "/tmp/ipykernel_1815217/1428560804.py:32: DeprecationWarning: Use get_tensor_name instead.\n",
      "  binding_names = {i: engine.get_binding_name(i) for i in range(engine.num_bindings)}\n",
      "/tmp/ipykernel_1815217/1428560804.py:36: DeprecationWarning: Use get_tensor_name instead.\n",
      "  out_idx_cls = engine.get_binding_index(CLASS_OUTPUT_NAME)\n",
      "/tmp/ipykernel_1815217/1428560804.py:51: DeprecationWarning: Use set_input_shape instead.\n",
      "  context.set_binding_shape(in_idx, tuple(x.shape))\n",
      "/tmp/ipykernel_1815217/1428560804.py:60: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  shp = tuple(context.get_binding_shape(oi))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, onnxruntime as ort, tensorrt as trt, pycuda.driver as cuda, pycuda.autoinit\n",
    "\n",
    "onnx_path   = \"./DL Models/best_AE_model.onnx\"\n",
    "engine_path = \"./DL Models/best_AE_model.trt\"\n",
    "\n",
    "CLASSES = 13   # classifier classes\n",
    "D = 94         # input feature dim\n",
    "CLASS_OUTPUT_NAME = \"StatefulPartitionedCall:0\"  # set to exact TRT output name if you know it (e.g. \"StatefulPartitionedCall:0\")\n",
    "\n",
    "# ORT (CPU is fine if CUDA EP missing)\n",
    "sess = ort.InferenceSession(onnx_path, providers=[\"CPUExecutionProvider\"])\n",
    "inp_name_ort = sess.get_inputs()[0].name\n",
    "\n",
    "# TensorRT\n",
    "logger  = trt.Logger(trt.Logger.WARNING)\n",
    "runtime = trt.Runtime(logger)\n",
    "with open(engine_path, \"rb\") as f:\n",
    "    engine = runtime.deserialize_cuda_engine(f.read())\n",
    "context = engine.create_execution_context()\n",
    "\n",
    "# ---- Discover binding indices (v2 API) ----\n",
    "input_bindings  = [i for i in range(engine.num_bindings) if engine.binding_is_input(i)]\n",
    "output_bindings = [i for i in range(engine.num_bindings) if not engine.binding_is_input(i)]\n",
    "assert len(input_bindings) >= 1, \"No inputs in engine\"\n",
    "assert len(output_bindings) >= 1, \"No outputs in engine\"\n",
    "in_idx = input_bindings[0]\n",
    "\n",
    "# Probe: set a shape so TRT can report output shapes\n",
    "context.set_binding_shape(in_idx, (1, D))\n",
    "out_shapes = {i: tuple(context.get_binding_shape(i)) for i in output_bindings}\n",
    "# Map binding index -> name (useful for debugging / name selection)\n",
    "binding_names = {i: engine.get_binding_name(i) for i in range(engine.num_bindings)}\n",
    "\n",
    "# Choose classifier output\n",
    "if CLASS_OUTPUT_NAME is not None:\n",
    "    out_idx_cls = engine.get_binding_index(CLASS_OUTPUT_NAME)\n",
    "    assert out_idx_cls in output_bindings, f\"{CLASS_OUTPUT_NAME} not an output. Outputs: {[binding_names[i] for i in output_bindings]}\"\n",
    "else:\n",
    "    # prefer 2D outputs with last dim == CLASSES\n",
    "    candidates = [i for i, shp in out_shapes.items() if len(shp) == 2 and shp[-1] == CLASSES]\n",
    "    if not candidates:\n",
    "        # fallback: largest 2D second dim not equal to D (avoid reconstructions)\n",
    "        two_d = [i for i, shp in out_shapes.items() if len(shp) == 2 and shp[1] not in (D, -1)]\n",
    "        candidates = sorted(two_d, key=lambda j: out_shapes[j][1], reverse=True)\n",
    "        assert candidates, f\"Could not identify classifier output. Output shapes: {out_shapes}, names: {binding_names}\"\n",
    "    out_idx_cls = candidates[0]\n",
    "\n",
    "def trt_infer(x: np.ndarray) -> np.ndarray:\n",
    "    x = x.astype(np.float32, copy=False)\n",
    "    # Set actual batch shape\n",
    "    context.set_binding_shape(in_idx, tuple(x.shape))\n",
    "\n",
    "    # Allocate input\n",
    "    d_in = cuda.mem_alloc(x.nbytes)\n",
    "\n",
    "    # Allocate ALL outputs (bind them all)\n",
    "    d_out_bufs = {}\n",
    "    host_outs  = {}\n",
    "    for oi in output_bindings:\n",
    "        shp = tuple(context.get_binding_shape(oi))\n",
    "        # Some engines return FP16; we can still allocate float32 host and copy (TRT will cast)\n",
    "        host = np.empty(shp, dtype=np.float32)\n",
    "        dev  = cuda.mem_alloc(host.nbytes)\n",
    "        host_outs[oi]  = host\n",
    "        d_out_bufs[oi] = dev\n",
    "\n",
    "    # Build bindings array (size = num_bindings)\n",
    "    bindings = [0] * engine.num_bindings\n",
    "    bindings[in_idx] = int(d_in)\n",
    "    for oi, dev in d_out_bufs.items():\n",
    "        bindings[oi] = int(dev)\n",
    "\n",
    "    stream = cuda.Stream()\n",
    "    cuda.memcpy_htod_async(d_in, x, stream)\n",
    "    ok = context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)\n",
    "    if not ok:\n",
    "        raise RuntimeError(\"execute_async_v2 failed\")\n",
    "    for oi, host in host_outs.items():\n",
    "        cuda.memcpy_dtoh_async(host, d_out_bufs[oi], stream)\n",
    "    stream.synchronize()\n",
    "\n",
    "    # Return only the classifier output\n",
    "    y = host_outs[out_idx_cls]\n",
    "    # If logits, softmax to compare with ORT probabilities\n",
    "    if not np.allclose(y.sum(axis=1, keepdims=True), 1.0, rtol=1e-3, atol=1e-5):\n",
    "        y = np.exp(y - y.max(axis=1, keepdims=True)); y /= y.sum(axis=1, keepdims=True)\n",
    "    return y\n",
    "\n",
    "# --- quick parity vs ORT ---\n",
    "for N in (1, 4, 8):\n",
    "    x = np.random.rand(N, D).astype(np.float32)\n",
    "    y_ort = sess.run(None, {inp_name_ort: x})[0]\n",
    "    y_trt = trt_infer(x)\n",
    "    max_abs = float(np.max(np.abs(y_ort - y_trt)))\n",
    "    print(f\"N={N}: max|ORT-TRT| = {max_abs:.3e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67a56782-f2d5-425b-b0fb-d62bf605a579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1815217/524230382.py:42: DeprecationWarning: Use get_tensor_mode instead.\n",
      "  input_bindings  = [i for i in range(engine.num_bindings) if engine.binding_is_input(i)]\n",
      "/tmp/ipykernel_1815217/524230382.py:43: DeprecationWarning: Use get_tensor_mode instead.\n",
      "  output_bindings = [i for i in range(engine.num_bindings) if not engine.binding_is_input(i)]\n",
      "/tmp/ipykernel_1815217/524230382.py:50: DeprecationWarning: Use set_input_shape instead.\n",
      "  context.set_binding_shape(in_idx, (b, D))\n",
      "/tmp/ipykernel_1815217/524230382.py:56: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  shp = tuple(context.get_binding_shape(oi))\n",
      "/tmp/ipykernel_1815217/524230382.py:90: DeprecationWarning: Use set_input_shape instead.\n",
      "  context.set_binding_shape(in_idx, (xb.shape[0], D))\n",
      "/tmp/ipykernel_1815217/524230382.py:96: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  shp = tuple(context.get_binding_shape(oi))\n",
      "/tmp/ipykernel_1815217/524230382.py:124: DeprecationWarning: Use set_input_shape instead.\n",
      "  context.set_binding_shape(in_idx, (b, D))\n",
      "/tmp/ipykernel_1815217/524230382.py:130: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  shp = tuple(context.get_binding_shape(oi))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08/12/2025-19:38:16] [TRT] [E] 3: [executionContext.cpp::validateInputBindings::1838] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::validateInputBindings::1838, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [64,94] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 8, minimum dimension in profile is 1, but supplied dimension is 64.\n",
      ")\n",
      "[08/12/2025-19:38:16] [TRT] [E] 3: [executionContext.cpp::resolveSlots::2509] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::resolveSlots::2509, condition: allInputDimensionsSpecified(routine)\n",
      ")\n",
      "[08/12/2025-19:38:16] [TRT] [E] 3: [executionContext.cpp::validateInputBindings::1838] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::validateInputBindings::1838, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [32,94] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 8, minimum dimension in profile is 1, but supplied dimension is 32.\n",
      ")\n",
      "[08/12/2025-19:38:16] [TRT] [E] 3: [executionContext.cpp::resolveSlots::2509] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::resolveSlots::2509, condition: allInputDimensionsSpecified(routine)\n",
      ")\n",
      "[08/12/2025-19:38:16] [TRT] [E] 3: [executionContext.cpp::validateInputBindings::1838] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::validateInputBindings::1838, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [16,94] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 8, minimum dimension in profile is 1, but supplied dimension is 16.\n",
      ")\n",
      "[08/12/2025-19:38:16] [TRT] [E] 3: [executionContext.cpp::resolveSlots::2509] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::resolveSlots::2509, condition: allInputDimensionsSpecified(routine)\n",
      ")\n",
      "Discovered max usable batch: 8\n",
      "Selected classifier output binding index: 1  |  max|TRT-ORT|=2.384e-07\n",
      "Test Balanced Accuracy: 0.7269\n",
      "Test Accuracy: 0.9684\n",
      "Test Macro F1 Score: 0.7263\n",
      "Test Precision (Macro): 0.7745\n",
      "Test Recall (Macro): 0.7269\n",
      "Test ROC AUC Score: 0.9980\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.81      0.31      0.45      1550\n",
      "     Class 1       0.98      1.00      0.99     17368\n",
      "     Class 2       0.90      0.43      0.58       107\n",
      "     Class 3       1.00      1.00      1.00     18932\n",
      "     Class 4       1.00      1.00      1.00       829\n",
      "     Class 5       0.14      0.29      0.19         7\n",
      "     Class 6       0.00      0.00      0.00         6\n",
      "     Class 7       1.00      0.94      0.97       400\n",
      "     Class 8       0.99      0.99      0.99       200\n",
      "     Class 9       0.51      0.93      0.66       518\n",
      "    Class 10       1.00      1.00      1.00       402\n",
      "    Class 11       0.82      0.95      0.88      1622\n",
      "    Class 12       0.91      0.61      0.73        51\n",
      "\n",
      "    accuracy                           0.97     41992\n",
      "   macro avg       0.77      0.73      0.73     41992\n",
      "weighted avg       0.97      0.97      0.96     41992\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  487   273     5     0     0    12     0     0     1   463     0   307\n",
      "      2]\n",
      " [    3 17340     0     0     0     0     0     0     0     3     0    22\n",
      "      0]\n",
      " [   59     1    46     0     0     0     0     0     0     0     0     1\n",
      "      0]\n",
      " [    0     0     0 18932     0     0     0     0     0     0     0     0\n",
      "      0]\n",
      " [    0     3     0     0   826     0     0     0     0     0     0     0\n",
      "      0]\n",
      " [    5     0     0     0     0     2     0     0     0     0     0     0\n",
      "      0]\n",
      " [    1     5     0     0     0     0     0     0     0     0     0     0\n",
      "      0]\n",
      " [    0    23     0     0     0     0     0   377     0     0     0     0\n",
      "      0]\n",
      " [    0     1     0     0     0     0     0     0   199     0     0     0\n",
      "      0]\n",
      " [   30     1     0     0     0     0     0     0     0   482     0     5\n",
      "      0]\n",
      " [    1     0     0     0     0     0     0     0     0     0   401     0\n",
      "      0]\n",
      " [   12    64     0     0     0     0     0     0     0     2     0  1543\n",
      "      1]\n",
      " [    1    10     0     0     0     0     0     0     0     0     0     9\n",
      "     31]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rteam8/anaconda3/envs/tuninggpu310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/rteam8/anaconda3/envs/tuninggpu310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/rteam8/anaconda3/envs/tuninggpu310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score, accuracy_score, f1_score,\n",
    "    precision_score, recall_score, roc_auc_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import onnxruntime as ort\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit  # single CUDA context\n",
    "\n",
    "# ===== config =====\n",
    "onnx_path  = \"./DL Models/best_FCNN_model.onnx\"   # ONNX for reference\n",
    "engine_path = \"./DL Models/best_FCNN_model.trt\"   # TRT engine\n",
    "CLASSES = 13\n",
    "\n",
    "X = X_test_transformed\n",
    "if hasattr(X, \"toarray\"):\n",
    "    X = X.toarray()\n",
    "X = X.astype(np.float32, copy=False)\n",
    "N, D = X.shape\n",
    "\n",
    "# ===== ORT session (CPU EP is fine) =====\n",
    "sess = ort.InferenceSession(onnx_path, providers=[\"CPUExecutionProvider\"])\n",
    "inp_ort = sess.get_inputs()[0].name\n",
    "\n",
    "def softmax(z):\n",
    "    z = z - z.max(axis=1, keepdims=True)\n",
    "    e = np.exp(z)\n",
    "    return e / e.sum(axis=1, keepdims=True)\n",
    "\n",
    "# ===== TRT load (v2 API) =====\n",
    "logger  = trt.Logger(trt.Logger.WARNING)\n",
    "runtime = trt.Runtime(logger)\n",
    "with open(engine_path, \"rb\") as f:\n",
    "    engine = runtime.deserialize_cuda_engine(f.read())\n",
    "context = engine.create_execution_context()\n",
    "\n",
    "# ---- bindings ----\n",
    "input_bindings  = [i for i in range(engine.num_bindings) if engine.binding_is_input(i)]\n",
    "output_bindings = [i for i in range(engine.num_bindings) if not engine.binding_is_input(i)]\n",
    "assert len(input_bindings)==1 and len(output_bindings)>=1\n",
    "in_idx = input_bindings[0]\n",
    "\n",
    "# ---- find a valid max batch by probing (no OptProfileSelector in this TRT) ----\n",
    "def try_batch(b):\n",
    "    try:\n",
    "        context.set_binding_shape(in_idx, (b, D))\n",
    "        d_in = cuda.mem_alloc(b * D * 4)\n",
    "        bindings = [0]*engine.num_bindings\n",
    "        bindings[in_idx] = int(d_in)\n",
    "        outs = []\n",
    "        for oi in output_bindings:\n",
    "            shp = tuple(context.get_binding_shape(oi))\n",
    "            if -1 in shp:\n",
    "                return False\n",
    "            host = np.empty(shp, dtype=np.float32)\n",
    "            dev  = cuda.mem_alloc(host.nbytes)\n",
    "            outs.append((host, dev, oi))\n",
    "            bindings[oi] = int(dev)\n",
    "        stream = cuda.Stream()\n",
    "        cuda.memcpy_htod_async(d_in, np.zeros((b, D), np.float32), stream)\n",
    "        ok = context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)\n",
    "        for host, dev, _ in outs:\n",
    "            cuda.memcpy_dtoh_async(host, dev, stream)\n",
    "        stream.synchronize()\n",
    "        return bool(ok)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "for candidate in (64, 32, 16, 8, 4, 2, 1):\n",
    "    if try_batch(candidate):\n",
    "        max_batch = candidate\n",
    "        break\n",
    "else:\n",
    "    raise RuntimeError(\"Could not find a valid batch size for this engine/profile\")\n",
    "\n",
    "print(f\"Discovered max usable batch: {max_batch}\")\n",
    "\n",
    "# ---- pick the CORRECT classifier output by ONNX/TRT parity (once) ----\n",
    "B = min(max_batch, max(1, min(N, 8)))       # small probe batch within profile\n",
    "samples = X[:B]\n",
    "y_ort = sess.run(None, {inp_ort: samples})[0]\n",
    "if not np.allclose(y_ort.sum(axis=1, keepdims=True), 1.0, rtol=1e-3, atol=1e-5):\n",
    "    y_ort = softmax(y_ort)\n",
    "\n",
    "def trt_forward_all(xb):\n",
    "    context.set_binding_shape(in_idx, (xb.shape[0], D))\n",
    "    d_in = cuda.mem_alloc(xb.nbytes)\n",
    "    bindings = [0]*engine.num_bindings\n",
    "    bindings[in_idx] = int(d_in)\n",
    "    host_outs, dev_outs = [], []\n",
    "    for oi in output_bindings:\n",
    "        shp = tuple(context.get_binding_shape(oi))\n",
    "        h = np.empty(shp, dtype=np.float32)\n",
    "        d = cuda.mem_alloc(h.nbytes)\n",
    "        host_outs.append(h); dev_outs.append(d)\n",
    "        bindings[oi] = int(d)\n",
    "    stream = cuda.Stream()\n",
    "    cuda.memcpy_htod_async(d_in, xb, stream)\n",
    "    context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)\n",
    "    for h,d in zip(host_outs, dev_outs):\n",
    "        cuda.memcpy_dtoh_async(h, d, stream)\n",
    "    stream.synchronize()\n",
    "    outs = []\n",
    "    for y in host_outs:\n",
    "        if not np.allclose(y.sum(axis=1, keepdims=True), 1.0, rtol=1e-3, atol=1e-5):\n",
    "            y = softmax(y)\n",
    "        outs.append(y.astype(np.float32, copy=False))\n",
    "    return outs\n",
    "\n",
    "trt_outs = trt_forward_all(samples)\n",
    "diffs = [float(np.max(np.abs(y - y_ort))) for y in trt_outs]\n",
    "out_idx_cls = output_bindings[int(np.argmin(diffs))]\n",
    "print(f\"Selected classifier output binding index: {out_idx_cls}  |  max|TRT-ORT|={min(diffs):.3e}\")\n",
    "\n",
    "# ---- batched inference respecting profile, using the selected output ----\n",
    "def trt_infer_batch(xb: np.ndarray) -> np.ndarray:\n",
    "    b = xb.shape[0]\n",
    "    if b > max_batch:\n",
    "        raise ValueError(f\"Batch {b} exceeds discovered max {max_batch}\")\n",
    "    context.set_binding_shape(in_idx, (b, D))\n",
    "\n",
    "    d_in = cuda.mem_alloc(xb.nbytes)\n",
    "    # allocate & bind ALL outputs\n",
    "    host_outs, dev_outs = {}, {}\n",
    "    for oi in output_bindings:\n",
    "        shp = tuple(context.get_binding_shape(oi))\n",
    "        host_outs[oi] = np.empty(shp, dtype=np.float32)\n",
    "        dev_outs[oi]  = cuda.mem_alloc(host_outs[oi].nbytes)\n",
    "\n",
    "    bindings = [0]*engine.num_bindings\n",
    "    bindings[in_idx] = int(d_in)\n",
    "    for oi in output_bindings:\n",
    "        bindings[oi] = int(dev_outs[oi])\n",
    "\n",
    "    stream = cuda.Stream()\n",
    "    cuda.memcpy_htod_async(d_in, xb, stream)\n",
    "    ok = context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)\n",
    "    if not ok:\n",
    "        raise RuntimeError(\"execute_async_v2 failed\")\n",
    "    for oi in output_bindings:\n",
    "        cuda.memcpy_dtoh_async(host_outs[oi], dev_outs[oi], stream)\n",
    "    stream.synchronize()\n",
    "\n",
    "    y = host_outs[out_idx_cls]\n",
    "    # Only softmax if not already probabilities\n",
    "    if not np.allclose(y.sum(axis=1, keepdims=True), 1.0, rtol=1e-3, atol=1e-5):\n",
    "        y = softmax(y)\n",
    "    return y\n",
    "\n",
    "probs = []\n",
    "start = 0\n",
    "while start < N:\n",
    "    end = min(start + max_batch, N)\n",
    "    probs.append(trt_infer_batch(X[start:end]))\n",
    "    start = end\n",
    "\n",
    "Y_pred_proba = np.vstack(probs)\n",
    "Y_pred = np.argmax(Y_pred_proba, axis=1).astype(int)\n",
    "\n",
    "# ===== metrics =====\n",
    "test_bal_acc = balanced_accuracy_score(Y_test, Y_pred)\n",
    "test_accuracy = accuracy_score(Y_test, Y_pred)\n",
    "test_macro_f1 = f1_score(Y_test, Y_pred, average='macro')\n",
    "test_precision = precision_score(Y_test, Y_pred, average='macro', zero_division=0)\n",
    "test_recall = recall_score(Y_test, Y_pred, average='macro', zero_division=0)\n",
    "\n",
    "Y_test_bin = label_binarize(Y_test, classes=np.arange(CLASSES))\n",
    "test_auc = roc_auc_score(Y_test_bin, Y_pred_proba, average='macro', multi_class='ovo')\n",
    "\n",
    "print(f\"Test Balanced Accuracy: {test_bal_acc:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Macro F1 Score: {test_macro_f1:.4f}\")\n",
    "print(f\"Test Precision (Macro): {test_precision:.4f}\")\n",
    "print(f\"Test Recall (Macro): {test_recall:.4f}\")\n",
    "print(f\"Test ROC AUC Score: {test_auc:.4f}\")\n",
    "\n",
    "class_labels = [f\"Class {i}\" for i in range(CLASSES)]\n",
    "print(\"\\nClassification Report:\\n\", classification_report(Y_test, Y_pred, target_names=class_labels))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(Y_test, Y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfb98f6d-df26-4314-a25d-ba6979b19ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08/12/2025-19:31:38] [TRT] [E] 3: [executionContext.cpp::validateInputBindings::1838] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::validateInputBindings::1838, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [64,94] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 8, minimum dimension in profile is 1, but supplied dimension is 64.\n",
      ")\n",
      "[08/12/2025-19:31:39] [TRT] [E] 3: [executionContext.cpp::resolveSlots::2509] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::resolveSlots::2509, condition: allInputDimensionsSpecified(routine)\n",
      ")\n",
      "[08/12/2025-19:31:39] [TRT] [E] 3: [executionContext.cpp::validateInputBindings::1838] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::validateInputBindings::1838, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [32,94] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 8, minimum dimension in profile is 1, but supplied dimension is 32.\n",
      ")\n",
      "[08/12/2025-19:31:39] [TRT] [E] 3: [executionContext.cpp::resolveSlots::2509] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::resolveSlots::2509, condition: allInputDimensionsSpecified(routine)\n",
      ")\n",
      "[08/12/2025-19:31:39] [TRT] [E] 3: [executionContext.cpp::validateInputBindings::1838] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::validateInputBindings::1838, condition: profileMaxDims.d[i] >= dimensions.d[i]. Supplied binding dimension [16,94] for bindings[0] exceed min ~ max range at index 0, maximum dimension in profile is 8, minimum dimension in profile is 1, but supplied dimension is 16.\n",
      ")\n",
      "[08/12/2025-19:31:39] [TRT] [E] 3: [executionContext.cpp::resolveSlots::2509] Error Code 3: API Usage Error (Parameter check failed at: runtime/api/executionContext.cpp::resolveSlots::2509, condition: allInputDimensionsSpecified(routine)\n",
      ")\n",
      "Using batch 8\n",
      "Max |TRT-ORT| per TRT output: [2.384185791015625e-07]\n",
      "=> Use TRT output binding index: 1 (diff= 2.384185791015625e-07 )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1812081/3099825647.py:21: DeprecationWarning: Use get_tensor_mode instead.\n",
      "  inputs  = [i for i in range(engine.num_bindings) if engine.binding_is_input(i)]\n",
      "/tmp/ipykernel_1812081/3099825647.py:22: DeprecationWarning: Use get_tensor_mode instead.\n",
      "  outputs = [i for i in range(engine.num_bindings) if not engine.binding_is_input(i)]\n",
      "/tmp/ipykernel_1812081/3099825647.py:29: DeprecationWarning: Use set_input_shape instead.\n",
      "  context.set_binding_shape(in_idx, (b, D))\n",
      "/tmp/ipykernel_1812081/3099825647.py:30: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  shp = [tuple(context.get_binding_shape(o)) for o in outputs]\n",
      "/tmp/ipykernel_1812081/3099825647.py:47: DeprecationWarning: Use set_input_shape instead.\n",
      "  context.set_binding_shape(in_idx, (xb.shape[0], D))\n",
      "/tmp/ipykernel_1812081/3099825647.py:53: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  shp = tuple(context.get_binding_shape(oi))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, onnxruntime as ort, tensorrt as trt, pycuda.driver as cuda, pycuda.autoinit\n",
    "\n",
    "onnx_path   = \"./DL Models/best_FCNN_model.onnx\"\n",
    "engine_path = \"./DL Models/best_FCNN_model.trt\"\n",
    "CLASSES = 13\n",
    "X = X_test_transformed.toarray() if hasattr(X_test_transformed, \"toarray\") else X_test_transformed\n",
    "X = X.astype(np.float32, copy=False)\n",
    "N, D = X.shape\n",
    "\n",
    "# ORT reference\n",
    "sess = ort.InferenceSession(onnx_path, providers=[\"CPUExecutionProvider\"])\n",
    "inp_ort = sess.get_inputs()[0].name\n",
    "\n",
    "# TRT v2\n",
    "logger  = trt.Logger(trt.Logger.WARNING)\n",
    "runtime = trt.Runtime(logger)\n",
    "with open(engine_path, \"rb\") as f: engine = runtime.deserialize_cuda_engine(f.read())\n",
    "context = engine.create_execution_context()\n",
    "\n",
    "# bindings\n",
    "inputs  = [i for i in range(engine.num_bindings) if engine.binding_is_input(i)]\n",
    "outputs = [i for i in range(engine.num_bindings) if not engine.binding_is_input(i)]\n",
    "assert len(inputs)==1 and len(outputs)>=1\n",
    "in_idx = inputs[0]\n",
    "\n",
    "# find a valid batch (probe 8→1)\n",
    "def ok_batch(b):\n",
    "    try:\n",
    "        context.set_binding_shape(in_idx, (b, D))\n",
    "        shp = [tuple(context.get_binding_shape(o)) for o in outputs]\n",
    "        return all(-1 not in s for s in shp)\n",
    "    except Exception:\n",
    "        return False\n",
    "for b in (64,32,16,8,4,2,1):\n",
    "    if ok_batch(b):\n",
    "        B = b; break\n",
    "else:\n",
    "    raise RuntimeError(\"no valid batch\")\n",
    "print(\"Using batch\", B)\n",
    "\n",
    "def softmax(z):\n",
    "    z = z - z.max(axis=1, keepdims=True)\n",
    "    e = np.exp(z)\n",
    "    return e / e.sum(axis=1, keepdims=True)\n",
    "\n",
    "def trt_forward(xb):\n",
    "    context.set_binding_shape(in_idx, (xb.shape[0], D))\n",
    "    d_in = cuda.mem_alloc(xb.nbytes)\n",
    "    bindings = [0]*engine.num_bindings\n",
    "    bindings[in_idx] = int(d_in)\n",
    "    host_outs, dev_outs = [], []\n",
    "    for oi in outputs:\n",
    "        shp = tuple(context.get_binding_shape(oi))\n",
    "        h = np.empty(shp, dtype=np.float32)\n",
    "        d = cuda.mem_alloc(h.nbytes)\n",
    "        host_outs.append(h); dev_outs.append(d)\n",
    "        bindings[oi] = int(d)\n",
    "\n",
    "    stream = cuda.Stream()\n",
    "    cuda.memcpy_htod_async(d_in, xb, stream)\n",
    "    context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)\n",
    "    for h,d in zip(host_outs, dev_outs):\n",
    "        cuda.memcpy_dtoh_async(h, d, stream)\n",
    "    stream.synchronize()\n",
    "    # softmax if needed\n",
    "    outs = []\n",
    "    for y in host_outs:\n",
    "        if not np.allclose(y.sum(axis=1, keepdims=True), 1.0, rtol=1e-3, atol=1e-5):\n",
    "            y = softmax(y)\n",
    "        outs.append(y.astype(np.float32, copy=False))\n",
    "    return outs  # list len = number of outputs\n",
    "\n",
    "# compare on a few batches\n",
    "samples = X[:B]\n",
    "y_ort = sess.run(None, {inp_ort: samples})[0]\n",
    "if not np.allclose(y_ort.sum(axis=1, keepdims=True), 1.0, rtol=1e-3, atol=1e-5):\n",
    "    y_ort = softmax(y_ort)\n",
    "\n",
    "trt_outs = trt_forward(samples)\n",
    "diffs = [float(np.max(np.abs(y - y_ort))) for y in trt_outs]\n",
    "print(\"Max |TRT-ORT| per TRT output:\", diffs)\n",
    "\n",
    "best_idx = int(np.argmin(diffs))\n",
    "print(\"=> Use TRT output binding index:\", outputs[best_idx], \"(diff=\", diffs[best_idx], \")\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
